{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brishtiteveja/3DEO_Coding_Challenge/blob/master/BanglaLLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkTeasOKJ4Ha",
        "outputId": "1f9c7f88-cce7-41bb-b4e9-5f6d4d8cc6dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount google drive for data projects\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Beginning\n"
      ],
      "metadata": {
        "id": "eooPD2jvFRCT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUQARDlIKZuD",
        "outputId": "435d1320-bd9e-4c32-ca53-e0830dfcfeef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Projects\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/My\\ Drive/Projects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPL11_AqKykY",
        "outputId": "ef75cef4-6e50-484b-d53a-fc183844f1a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Projects/bangla-llama\n"
          ]
        }
      ],
      "source": [
        "# git clone bangla llama here\n",
        "#git clone https://github.com/brishtiteveja/bangla-llama.git\n",
        "%cd bangla-llama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZrfaYEiLf4z",
        "outputId": "88f46788-e5ce-4652-f4ba-7bb995968591"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "assets\tCITATION.cff  data  download_culturax.sh  LICENSE  README.md  requirements.txt\tscripts\n"
          ]
        }
      ],
      "source": [
        "!ls ../bangla-llama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QXbRcMGfNkX5",
        "outputId": "532c94d6-b077-4d01-9e6e-41395d555279"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting absl-py==2.0.0\n",
            "  Downloading absl_py-2.0.0-py3-none-any.whl (130 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/130.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m92.2/130.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: absl-py\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.4.0\n",
            "    Uninstalling absl-py-1.4.0:\n",
            "      Successfully uninstalled absl-py-1.4.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-metadata 1.14.0 requires absl-py<2.0.0,>=0.9, but you have absl-py 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed absl-py-2.0.0\n",
            "Collecting accelerate==0.21.0\n",
            "  Downloading accelerate-0.21.0-py3-none-any.whl (244 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.21.0) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.21.0) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.21.0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.21.0) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.21.0) (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.21.0) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate==0.21.0) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.21.0\n",
            "Collecting aiofiles==23.2.1\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: aiofiles\n",
            "Successfully installed aiofiles-23.2.1\n",
            "Collecting aiohttp==3.8.6\n",
            "  Downloading aiohttp-3.8.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.6) (23.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.6) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.6) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.6) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.6) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.6) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.6) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp==3.8.6) (3.6)\n",
            "Installing collected packages: aiohttp\n",
            "  Attempting uninstall: aiohttp\n",
            "    Found existing installation: aiohttp 3.9.1\n",
            "    Uninstalling aiohttp-3.9.1:\n",
            "      Successfully uninstalled aiohttp-3.9.1\n",
            "Successfully installed aiohttp-3.8.6\n",
            "Requirement already satisfied: aiosignal==1.3.1 in /usr/local/lib/python3.10/dist-packages (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from aiosignal==1.3.1) (1.4.1)\n",
            "Requirement already satisfied: albumentations==1.3.1 in /usr/local/lib/python3.10/dist-packages (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1) (1.11.4)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1) (0.19.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1) (6.0.1)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1) (0.0.4)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1) (4.9.0.80)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations==1.3.1) (1.2.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations==1.3.1) (4.5.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.1) (3.2.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.1) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.1) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.1) (2023.12.9)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.1) (1.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.1) (23.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.3.1) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.3.1) (3.2.0)\n",
            "Collecting alembic==1.12.0\n",
            "  Downloading alembic-1.12.0-py3-none-any.whl (226 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.0/226.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: SQLAlchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from alembic==1.12.0) (2.0.24)\n",
            "Collecting Mako (from alembic==1.12.0)\n",
            "  Downloading Mako-1.3.0-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic==1.12.0) (4.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.3.0->alembic==1.12.0) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic==1.12.0) (2.1.3)\n",
            "Installing collected packages: Mako, alembic\n",
            "Successfully installed Mako-1.3.0 alembic-1.12.0\n",
            "Collecting altair==5.1.2\n",
            "  Downloading altair-5.1.2-py3-none-any.whl (516 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m516.2/516.2 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair==5.1.2) (3.1.3)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair==5.1.2) (4.19.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from altair==5.1.2) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from altair==5.1.2) (23.2)\n",
            "Requirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.10/dist-packages (from altair==5.1.2) (1.5.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair==5.1.2) (0.12.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from altair==5.1.2) (4.5.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair==5.1.2) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair==5.1.2) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair==5.1.2) (0.32.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair==5.1.2) (0.17.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25->altair==5.1.2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25->altair==5.1.2) (2023.3.post1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair==5.1.2) (2.1.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=0.25->altair==5.1.2) (1.16.0)\n",
            "Installing collected packages: altair\n",
            "  Attempting uninstall: altair\n",
            "    Found existing installation: altair 4.2.2\n",
            "    Uninstalling altair-4.2.2:\n",
            "      Successfully uninstalled altair-4.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed altair-5.1.2\n",
            "Requirement already satisfied: anyio==3.7.1 in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio==3.7.1) (3.6)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio==3.7.1) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio==3.7.1) (1.2.0)\n",
            "Collecting arrow==1.3.0\n",
            "  Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from arrow==1.3.0) (2.8.2)\n",
            "Collecting types-python-dateutil>=2.8.10 (from arrow==1.3.0)\n",
            "  Downloading types_python_dateutil-2.8.19.20240106-py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7.0->arrow==1.3.0) (1.16.0)\n",
            "Installing collected packages: types-python-dateutil, arrow\n",
            "Successfully installed arrow-1.3.0 types-python-dateutil-2.8.19.20240106\n",
            "Requirement already satisfied: async-timeout==4.0.3 in /usr/local/lib/python3.10/dist-packages (4.0.3)\n",
            "Collecting attrs==23.1.0\n",
            "  Downloading attrs-23.1.0-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: attrs\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 23.2.0\n",
            "    Uninstalling attrs-23.2.0:\n",
            "      Successfully uninstalled attrs-23.2.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed attrs-23.1.0\n",
            "Collecting autotrain-advanced==0.6.37\n",
            "  Downloading autotrain_advanced-0.6.37-py3-none-any.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.4/130.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: albumentations==1.3.1 in /usr/local/lib/python3.10/dist-packages (from autotrain-advanced==0.6.37) (1.3.1)\n",
            "Collecting codecarbon==2.2.3 (from autotrain-advanced==0.6.37)\n",
            "  Downloading codecarbon-2.2.3-py3-none-any.whl (174 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.1/174.1 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets[vision]~=2.14.0 (from autotrain-advanced==0.6.37)\n",
            "  Downloading datasets-2.14.7-py3-none-any.whl (520 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m520.4/520.4 kB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting evaluate==0.3.0 (from autotrain-advanced==0.6.37)\n",
            "  Downloading evaluate-0.3.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ipadic==1.0.0 (from autotrain-advanced==0.6.37)\n",
            "  Downloading ipadic-1.0.0.tar.gz (13.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m83.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jiwer==3.0.2 (from autotrain-advanced==0.6.37)\n",
            "  Downloading jiwer-3.0.2-py3-none-any.whl (21 kB)\n",
            "Collecting joblib==1.3.1 (from autotrain-advanced==0.6.37)\n",
            "  Downloading joblib-1.3.1-py3-none-any.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting loguru==0.7.0 (from autotrain-advanced==0.6.37)\n",
            "  Downloading loguru-0.7.0-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.4 in /usr/local/lib/python3.10/dist-packages (from autotrain-advanced==0.6.37) (1.5.3)\n",
            "Collecting optuna==3.3.0 (from autotrain-advanced==0.6.37)\n",
            "  Downloading optuna-3.3.0-py3-none-any.whl (404 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.2/404.2 kB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Pillow==10.0.0 (from autotrain-advanced==0.6.37)\n",
            "  Downloading Pillow-10.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m94.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf==4.23.4 (from autotrain-advanced==0.6.37)\n",
            "  Downloading protobuf-4.23.4-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.5/304.5 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic==1.10.11 (from autotrain-advanced==0.6.37)\n",
            "  Downloading pydantic-1.10.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m101.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sacremoses==0.0.53 (from autotrain-advanced==0.6.37)\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting scikit-learn==1.3.0 (from autotrain-advanced==0.6.37)\n",
            "  Downloading scikit_learn-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m109.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece==0.1.99 (from autotrain-advanced==0.6.37)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m81.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm==4.65.0 (from autotrain-advanced==0.6.37)\n",
            "  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting werkzeug==2.3.6 (from autotrain-advanced==0.6.37)\n",
            "  Downloading Werkzeug-2.3.6-py3-none-any.whl (242 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xgboost==1.7.6 (from autotrain-advanced==0.6.37)\n",
            "  Downloading xgboost-1.7.6-py3-none-manylinux2014_x86_64.whl (200.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.3/200.3 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from autotrain-advanced==0.6.37) (0.20.2)\n",
            "Requirement already satisfied: requests==2.31.0 in /usr/local/lib/python3.10/dist-packages (from autotrain-advanced==0.6.37) (2.31.0)\n",
            "Collecting gradio==3.41.0 (from autotrain-advanced==0.6.37)\n",
            "  Downloading gradio-3.41.0-py3-none-any.whl (20.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.1/20.1 MB\u001b[0m \u001b[31m84.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops==0.6.1 (from autotrain-advanced==0.6.37)\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting invisible-watermark==0.2.0 (from autotrain-advanced==0.6.37)\n",
            "  Downloading invisible_watermark-0.2.0-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging==23.1 (from autotrain-advanced==0.6.37)\n",
            "  Downloading packaging-23.1-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from autotrain-advanced==0.6.37) (2.15.1)\n",
            "Collecting peft (from autotrain-advanced==0.6.37)\n",
            "  Downloading peft-0.7.1-py3-none-any.whl (168 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.3/168.3 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trl (from autotrain-advanced==0.6.37)\n",
            "  Downloading trl-0.7.10-py3-none-any.whl (150 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.9/150.9 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken (from autotrain-advanced==0.6.37)\n",
            "  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m90.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from autotrain-advanced==0.6.37) (4.35.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from autotrain-advanced==0.6.37) (0.21.0)\n",
            "Collecting diffusers==0.21.4 (from autotrain-advanced==0.6.37)\n",
            "  Downloading diffusers-0.21.4-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m80.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bitsandbytes (from autotrain-advanced==0.6.37)\n",
            "  Downloading bitsandbytes-0.42.0-py3-none-any.whl (105.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1->autotrain-advanced==0.6.37) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1->autotrain-advanced==0.6.37) (1.11.4)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1->autotrain-advanced==0.6.37) (0.19.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1->autotrain-advanced==0.6.37) (6.0.1)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1->autotrain-advanced==0.6.37) (0.0.4)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1->autotrain-advanced==0.6.37) (4.9.0.80)\n",
            "Requirement already satisfied: arrow in /usr/local/lib/python3.10/dist-packages (from codecarbon==2.2.3->autotrain-advanced==0.6.37) (1.3.0)\n",
            "Collecting pynvml (from codecarbon==2.2.3->autotrain-advanced==0.6.37)\n",
            "  Downloading pynvml-11.5.0-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from codecarbon==2.2.3->autotrain-advanced==0.6.37) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from codecarbon==2.2.3->autotrain-advanced==0.6.37) (9.0.0)\n",
            "Collecting fuzzywuzzy (from codecarbon==2.2.3->autotrain-advanced==0.6.37)\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from codecarbon==2.2.3->autotrain-advanced==0.6.37) (8.1.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers==0.21.4->autotrain-advanced==0.6.37) (3.13.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers==0.21.4->autotrain-advanced==0.6.37) (7.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.21.4->autotrain-advanced==0.6.37) (2023.6.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.21.4->autotrain-advanced==0.6.37) (0.4.1)\n",
            "Collecting datasets>=2.0.0 (from evaluate==0.3.0->autotrain-advanced==0.6.37)\n",
            "  Downloading datasets-2.16.1-py3-none-any.whl (507 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill (from evaluate==0.3.0->autotrain-advanced==0.6.37)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate==0.3.0->autotrain-advanced==0.6.37) (3.4.1)\n",
            "Collecting multiprocess (from evaluate==0.3.0->autotrain-advanced==0.6.37)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate==0.3.0->autotrain-advanced==0.6.37) (2023.6.0)\n",
            "Collecting responses<0.19 (from evaluate==0.3.0->autotrain-advanced==0.6.37)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.41.0->autotrain-advanced==0.6.37) (23.2.1)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.41.0->autotrain-advanced==0.6.37) (5.1.2)\n",
            "Collecting fastapi (from gradio==3.41.0->autotrain-advanced==0.6.37)\n",
            "  Downloading fastapi-0.109.0-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio==3.41.0->autotrain-advanced==0.6.37)\n",
            "  Downloading ffmpy-0.3.1.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==0.5.0 (from gradio==3.41.0->autotrain-advanced==0.6.37)\n",
            "  Downloading gradio_client-0.5.0-py3-none-any.whl (298 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.2/298.2 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx (from gradio==3.41.0->autotrain-advanced==0.6.37)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio==3.41.0->autotrain-advanced==0.6.37) (6.1.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.41.0->autotrain-advanced==0.6.37) (3.1.3)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.41.0->autotrain-advanced==0.6.37) (2.1.3)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.41.0->autotrain-advanced==0.6.37) (3.7.1)\n",
            "Collecting orjson~=3.0 (from gradio==3.41.0->autotrain-advanced==0.6.37)\n",
            "  Downloading orjson-3.9.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydub (from gradio==3.41.0->autotrain-advanced==0.6.37)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart (from gradio==3.41.0->autotrain-advanced==0.6.37)\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version~=2.0 (from gradio==3.41.0->autotrain-advanced==0.6.37)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.41.0->autotrain-advanced==0.6.37) (4.5.0)\n",
            "Collecting uvicorn>=0.14.0 (from gradio==3.41.0->autotrain-advanced==0.6.37)\n",
            "  Downloading uvicorn-0.26.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.5/60.5 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets<12.0,>=10.0 (from gradio==3.41.0->autotrain-advanced==0.6.37)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from invisible-watermark==0.2.0->autotrain-advanced==0.6.37) (1.5.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.10/dist-packages (from invisible-watermark==0.2.0->autotrain-advanced==0.6.37) (4.8.0.76)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from invisible-watermark==0.2.0->autotrain-advanced==0.6.37) (2.1.0+cu121)\n",
            "Collecting rapidfuzz==2.13.7 (from jiwer==3.0.2->autotrain-advanced==0.6.37)\n",
            "  Downloading rapidfuzz-2.13.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna==3.3.0->autotrain-advanced==0.6.37) (1.12.0)\n",
            "Collecting cmaes>=0.10.0 (from optuna==3.3.0->autotrain-advanced==0.6.37)\n",
            "  Downloading cmaes-0.10.0-py3-none-any.whl (29 kB)\n",
            "Collecting colorlog (from optuna==3.3.0->autotrain-advanced==0.6.37)\n",
            "  Downloading colorlog-6.8.0-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna==3.3.0->autotrain-advanced==0.6.37) (2.0.24)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->autotrain-advanced==0.6.37) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->autotrain-advanced==0.6.37) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->autotrain-advanced==0.6.37) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->autotrain-advanced==0.6.37) (2023.11.17)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sacremoses==0.0.53->autotrain-advanced==0.6.37) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.3.0->autotrain-advanced==0.6.37) (3.2.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets[vision]~=2.14.0->autotrain-advanced==0.6.37) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets[vision]~=2.14.0->autotrain-advanced==0.6.37) (0.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets[vision]~=2.14.0->autotrain-advanced==0.6.37) (3.8.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4->autotrain-advanced==0.6.37) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4->autotrain-advanced==0.6.37) (2023.3.post1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->autotrain-advanced==0.6.37) (2.0.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->autotrain-advanced==0.6.37) (1.60.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->autotrain-advanced==0.6.37) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->autotrain-advanced==0.6.37) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->autotrain-advanced==0.6.37) (3.5.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->autotrain-advanced==0.6.37) (67.7.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->autotrain-advanced==0.6.37) (0.7.2)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers->autotrain-advanced==0.6.37) (0.15.0)\n",
            "Collecting tyro>=0.5.11 (from trl->autotrain-advanced==0.6.37)\n",
            "  Downloading tyro-0.6.6-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna==3.3.0->autotrain-advanced==0.6.37) (1.3.0)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.41.0->autotrain-advanced==0.6.37) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.41.0->autotrain-advanced==0.6.37) (0.12.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[vision]~=2.14.0->autotrain-advanced==0.6.37) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[vision]~=2.14.0->autotrain-advanced==0.6.37) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[vision]~=2.14.0->autotrain-advanced==0.6.37) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[vision]~=2.14.0->autotrain-advanced==0.6.37) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[vision]~=2.14.0->autotrain-advanced==0.6.37) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[vision]~=2.14.0->autotrain-advanced==0.6.37) (1.3.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->autotrain-advanced==0.6.37) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->autotrain-advanced==0.6.37) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->autotrain-advanced==0.6.37) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->autotrain-advanced==0.6.37) (1.3.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.41.0->autotrain-advanced==0.6.37) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.41.0->autotrain-advanced==0.6.37) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.41.0->autotrain-advanced==0.6.37) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.41.0->autotrain-advanced==0.6.37) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.41.0->autotrain-advanced==0.6.37) (3.1.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.1->autotrain-advanced==0.6.37) (3.2.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.1->autotrain-advanced==0.6.37) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.1->autotrain-advanced==0.6.37) (2023.12.9)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna==3.3.0->autotrain-advanced==0.6.37) (3.0.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->invisible-watermark==0.2.0->autotrain-advanced==0.6.37) (1.12)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->invisible-watermark==0.2.0->autotrain-advanced==0.6.37) (2.1.0)\n",
            "Collecting docstring-parser>=0.14.1 (from tyro>=0.5.11->trl->autotrain-advanced==0.6.37)\n",
            "  Downloading docstring_parser-0.15-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl->autotrain-advanced==0.6.37) (13.7.0)\n",
            "Collecting shtab>=1.5.6 (from tyro>=0.5.11->trl->autotrain-advanced==0.6.37)\n",
            "  Downloading shtab-1.6.5-py3-none-any.whl (13 kB)\n",
            "Collecting h11>=0.8 (from uvicorn>=0.14.0->gradio==3.41.0->autotrain-advanced==0.6.37)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/lib/python3.10/dist-packages (from arrow->codecarbon==2.2.3->autotrain-advanced==0.6.37) (2.8.19.20240106)\n",
            "Collecting starlette<0.36.0,>=0.35.0 (from fastapi->gradio==3.41.0->autotrain-advanced==0.6.37)\n",
            "  Downloading starlette-0.35.1-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions~=4.0 (from gradio==3.41.0->autotrain-advanced==0.6.37)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.41.0->autotrain-advanced==0.6.37) (3.7.1)\n",
            "Collecting httpcore==1.* (from httpx->gradio==3.41.0->autotrain-advanced==0.6.37)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.41.0->autotrain-advanced==0.6.37) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers==0.21.4->autotrain-advanced==0.6.37) (3.17.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.41.0->autotrain-advanced==0.6.37) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.41.0->autotrain-advanced==0.6.37) (0.32.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.41.0->autotrain-advanced==0.6.37) (0.17.1)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->autotrain-advanced==0.6.37) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->autotrain-advanced==0.6.37) (3.2.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl->autotrain-advanced==0.6.37) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl->autotrain-advanced==0.6.37) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->gradio==3.41.0->autotrain-advanced==0.6.37) (1.2.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->invisible-watermark==0.2.0->autotrain-advanced==0.6.37) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl->autotrain-advanced==0.6.37) (0.1.2)\n",
            "Building wheels for collected packages: ipadic, sacremoses, ffmpy\n",
            "  Building wheel for ipadic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ipadic: filename=ipadic-1.0.0-py3-none-any.whl size=13556704 sha256=915f8317841e5b4341cc06c2ef86069f2311dda45ec53ae54de7d5ab837c42a5\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/ea/e3/2f6e0860a327daba3b030853fce4483ed37468bbf1101c59c3\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895239 sha256=f8a1ec3480e9efb6d4002b6949fe7eada67d27880cb47b156fb504bc72b57275\n",
            "  Stored in directory: /root/.cache/pip/wheels/00/24/97/a2ea5324f36bc626e1ea0267f33db6aa80d157ee977e9e42fb\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.1-py3-none-any.whl size=5579 sha256=6e05aa3a35e71e5cb0a3894b89e1824e0b8755c78a233375cec7d0a4b584d275\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/a6/d1/1c0828c304a4283b2c1639a09ad86f83d7c487ef34c6b4a1bf\n",
            "Successfully built ipadic sacremoses ffmpy\n",
            "Installing collected packages: sentencepiece, pydub, ipadic, fuzzywuzzy, ffmpy, werkzeug, websockets, typing-extensions, tqdm, shtab, semantic-version, rapidfuzz, python-multipart, pynvml, protobuf, Pillow, packaging, orjson, loguru, joblib, h11, einops, docstring-parser, dill, colorlog, cmaes, xgboost, uvicorn, tiktoken, starlette, scikit-learn, sacremoses, responses, pydantic, multiprocess, jiwer, httpcore, bitsandbytes, tyro, invisible-watermark, httpx, fastapi, diffusers, codecarbon, optuna, gradio-client, datasets, trl, peft, gradio, evaluate, autotrain-advanced\n",
            "  Attempting uninstall: werkzeug\n",
            "    Found existing installation: Werkzeug 3.0.1\n",
            "    Uninstalling Werkzeug-3.0.1:\n",
            "      Successfully uninstalled Werkzeug-3.0.1\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.66.1\n",
            "    Uninstalling tqdm-4.66.1:\n",
            "      Successfully uninstalled tqdm-4.66.1\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 23.2\n",
            "    Uninstalling packaging-23.2:\n",
            "      Successfully uninstalled packaging-23.2\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.3.2\n",
            "    Uninstalling joblib-1.3.2:\n",
            "      Successfully uninstalled joblib-1.3.2\n",
            "  Attempting uninstall: xgboost\n",
            "    Found existing installation: xgboost 2.0.3\n",
            "    Uninstalling xgboost-2.0.3:\n",
            "      Successfully uninstalled xgboost-2.0.3\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.10.13\n",
            "    Uninstalling pydantic-1.10.13:\n",
            "      Successfully uninstalled pydantic-1.10.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "tensorflow-metadata 1.14.0 requires absl-py<2.0.0,>=0.9, but you have absl-py 2.0.0 which is incompatible.\n",
            "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 4.23.4 which is incompatible.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Pillow-10.0.0 autotrain-advanced-0.6.37 bitsandbytes-0.42.0 cmaes-0.10.0 codecarbon-2.2.3 colorlog-6.8.0 datasets-2.14.7 diffusers-0.21.4 dill-0.3.7 docstring-parser-0.15 einops-0.6.1 evaluate-0.3.0 fastapi-0.109.0 ffmpy-0.3.1 fuzzywuzzy-0.18.0 gradio-3.41.0 gradio-client-0.5.0 h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 invisible-watermark-0.2.0 ipadic-1.0.0 jiwer-3.0.2 joblib-1.3.1 loguru-0.7.0 multiprocess-0.70.15 optuna-3.3.0 orjson-3.9.12 packaging-23.1 peft-0.7.1 protobuf-4.23.4 pydantic-1.10.11 pydub-0.25.1 pynvml-11.5.0 python-multipart-0.0.6 rapidfuzz-2.13.7 responses-0.18.0 sacremoses-0.0.53 scikit-learn-1.3.0 semantic-version-2.10.0 sentencepiece-0.1.99 shtab-1.6.5 starlette-0.35.1 tiktoken-0.5.2 tqdm-4.65.0 trl-0.7.10 typing-extensions-4.9.0 tyro-0.6.6 uvicorn-0.26.0 websockets-11.0.3 werkzeug-2.3.6 xgboost-1.7.6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bitsandbytes==0.40.2\n",
            "  Downloading bitsandbytes-0.40.2-py3-none-any.whl (92.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.5/92.5 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes\n",
            "  Attempting uninstall: bitsandbytes\n",
            "    Found existing installation: bitsandbytes 0.42.0\n",
            "    Uninstalling bitsandbytes-0.42.0:\n",
            "      Successfully uninstalled bitsandbytes-0.42.0\n",
            "Successfully installed bitsandbytes-0.40.2\n",
            "Collecting cachetools==5.3.1\n",
            "  Downloading cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n",
            "Installing collected packages: cachetools\n",
            "  Attempting uninstall: cachetools\n",
            "    Found existing installation: cachetools 5.3.2\n",
            "    Uninstalling cachetools-5.3.2:\n",
            "      Successfully uninstalled cachetools-5.3.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed cachetools-5.3.1\n",
            "Collecting certifi==2023.7.22\n",
            "  Downloading certifi-2023.7.22-py3-none-any.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.3/158.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: certifi\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2023.11.17\n",
            "    Uninstalling certifi-2023.11.17:\n",
            "      Successfully uninstalled certifi-2023.11.17\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed certifi-2023.7.22\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting charset-normalizer==3.3.0\n",
            "  Downloading charset_normalizer-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: charset-normalizer\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 3.3.2\n",
            "    Uninstalling charset-normalizer-3.3.2:\n",
            "      Successfully uninstalled charset-normalizer-3.3.2\n",
            "Successfully installed charset-normalizer-3.3.0\n",
            "Requirement already satisfied: click==8.1.7 in /usr/local/lib/python3.10/dist-packages (8.1.7)\n",
            "Requirement already satisfied: cmaes==0.10.0 in /usr/local/lib/python3.10/dist-packages (0.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from cmaes==0.10.0) (1.23.5)\n",
            "Requirement already satisfied: codecarbon==2.2.3 in /usr/local/lib/python3.10/dist-packages (2.2.3)\n",
            "Requirement already satisfied: arrow in /usr/local/lib/python3.10/dist-packages (from codecarbon==2.2.3) (1.3.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from codecarbon==2.2.3) (1.5.3)\n",
            "Requirement already satisfied: pynvml in /usr/local/lib/python3.10/dist-packages (from codecarbon==2.2.3) (11.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from codecarbon==2.2.3) (2.31.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from codecarbon==2.2.3) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from codecarbon==2.2.3) (9.0.0)\n",
            "Requirement already satisfied: fuzzywuzzy in /usr/local/lib/python3.10/dist-packages (from codecarbon==2.2.3) (0.18.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from codecarbon==2.2.3) (8.1.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from arrow->codecarbon==2.2.3) (2.8.2)\n",
            "Requirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/lib/python3.10/dist-packages (from arrow->codecarbon==2.2.3) (2.8.19.20240106)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->codecarbon==2.2.3) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas->codecarbon==2.2.3) (1.23.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->codecarbon==2.2.3) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->codecarbon==2.2.3) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->codecarbon==2.2.3) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->codecarbon==2.2.3) (2023.7.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7.0->arrow->codecarbon==2.2.3) (1.16.0)\n",
            "Collecting colorlog==6.7.0\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog\n",
            "  Attempting uninstall: colorlog\n",
            "    Found existing installation: colorlog 6.8.0\n",
            "    Uninstalling colorlog-6.8.0:\n",
            "      Successfully uninstalled colorlog-6.8.0\n",
            "Successfully installed colorlog-6.7.0\n",
            "Collecting contourpy==1.1.1\n",
            "  Downloading contourpy-1.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.7/301.7 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16 in /usr/local/lib/python3.10/dist-packages (from contourpy==1.1.1) (1.23.5)\n",
            "Installing collected packages: contourpy\n",
            "  Attempting uninstall: contourpy\n",
            "    Found existing installation: contourpy 1.2.0\n",
            "    Uninstalling contourpy-1.2.0:\n",
            "      Successfully uninstalled contourpy-1.2.0\n",
            "Successfully installed contourpy-1.1.1\n",
            "Requirement already satisfied: cycler==0.12.1 in /usr/local/lib/python3.10/dist-packages (0.12.1)\n",
            "Collecting datasets==2.15.0\n",
            "  Downloading datasets-2.15.0-py3-none-any.whl (521 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets==2.15.0) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.15.0) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets==2.15.0) (0.6)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.15.0) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==2.15.0) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.15.0) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.15.0) (4.65.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets==2.15.0) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets==2.15.0) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.15.0) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==2.15.0) (3.8.6)\n",
            "Requirement already satisfied: huggingface-hub>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.15.0) (0.20.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets==2.15.0) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.15.0) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.15.0) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.15.0) (3.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.15.0) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.15.0) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.15.0) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.15.0) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.15.0) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets==2.15.0) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets==2.15.0) (4.9.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.15.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.15.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.15.0) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.15.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.15.0) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets==2.15.0) (1.16.0)\n",
            "Installing collected packages: datasets\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 2.14.7\n",
            "    Uninstalling datasets-2.14.7:\n",
            "      Successfully uninstalled datasets-2.14.7\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "autotrain-advanced 0.6.37 requires datasets[vision]~=2.14.0, but you have datasets 2.15.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.15.0\n",
            "Requirement already satisfied: diffusers==0.21.4 in /usr/local/lib/python3.10/dist-packages (0.21.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers==0.21.4) (10.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers==0.21.4) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.21.4) (0.20.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers==0.21.4) (7.0.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers==0.21.4) (1.23.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.21.4) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers==0.21.4) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.21.4) (0.4.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.21.4) (2023.6.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.21.4) (4.65.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.21.4) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.21.4) (4.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.21.4) (23.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers==0.21.4) (3.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.21.4) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.21.4) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.21.4) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.21.4) (2023.7.22)\n",
            "Requirement already satisfied: dill==0.3.7 in /usr/local/lib/python3.10/dist-packages (0.3.7)\n",
            "Requirement already satisfied: docstring-parser==0.15 in /usr/local/lib/python3.10/dist-packages (0.15)\n",
            "Requirement already satisfied: einops==0.6.1 in /usr/local/lib/python3.10/dist-packages (0.6.1)\n",
            "Requirement already satisfied: evaluate==0.3.0 in /usr/local/lib/python3.10/dist-packages (0.3.0)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate==0.3.0) (2.15.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate==0.3.0) (1.23.5)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate==0.3.0) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate==0.3.0) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate==0.3.0) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate==0.3.0) (4.65.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate==0.3.0) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate==0.3.0) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate==0.3.0) (2023.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate==0.3.0) (0.20.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate==0.3.0) (23.1)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate==0.3.0) (0.18.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate==0.3.0) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate==0.3.0) (0.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate==0.3.0) (3.8.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate==0.3.0) (6.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate==0.3.0) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate==0.3.0) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate==0.3.0) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate==0.3.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate==0.3.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate==0.3.0) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate==0.3.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate==0.3.0) (2023.3.post1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.3.0) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.3.0) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.3.0) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.3.0) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.3.0) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.3.0) (1.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate==0.3.0) (1.16.0)\n",
            "Collecting fastapi==0.104.0\n",
            "  Downloading fastapi-0.104.0-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi==0.104.0) (3.7.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi==0.104.0) (1.10.11)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi==0.104.0)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from fastapi==0.104.0) (4.9.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi==0.104.0) (3.6)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi==0.104.0) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi==0.104.0) (1.2.0)\n",
            "Installing collected packages: starlette, fastapi\n",
            "  Attempting uninstall: starlette\n",
            "    Found existing installation: starlette 0.35.1\n",
            "    Uninstalling starlette-0.35.1:\n",
            "      Successfully uninstalled starlette-0.35.1\n",
            "  Attempting uninstall: fastapi\n",
            "    Found existing installation: fastapi 0.109.0\n",
            "    Uninstalling fastapi-0.109.0:\n",
            "      Successfully uninstalled fastapi-0.109.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed fastapi-0.104.0 starlette-0.27.0\n",
            "Requirement already satisfied: ffmpy==0.3.1 in /usr/local/lib/python3.10/dist-packages (0.3.1)\n",
            "Collecting filelock==3.12.4\n",
            "  Downloading filelock-3.12.4-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: filelock\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.13.1\n",
            "    Uninstalling filelock-3.13.1:\n",
            "      Successfully uninstalled filelock-3.13.1\n",
            "Successfully installed filelock-3.12.4\n",
            "Collecting flash-attn==2.3.3\n",
            "  Downloading flash_attn-2.3.3.tar.gz (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from flash-attn==2.3.3) (2.1.0+cu121)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from flash-attn==2.3.3) (0.6.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from flash-attn==2.3.3) (23.1)\n",
            "Collecting ninja (from flash-attn==2.3.3)\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn==2.3.3) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn==2.3.3) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn==2.3.3) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn==2.3.3) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn==2.3.3) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn==2.3.3) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn==2.3.3) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->flash-attn==2.3.3) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->flash-attn==2.3.3) (1.3.0)\n",
            "Building wheels for collected packages: flash-attn\n",
            "  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flash-attn: filename=flash_attn-2.3.3-cp310-cp310-linux_x86_64.whl size=57042553 sha256=b1df92cb5bd7657d38b789dd48e907aa3e0bd2715c817eb85f3c4320bb11fb3f\n",
            "  Stored in directory: /root/.cache/pip/wheels/e5/e6/fa/941802ec61d1afd320d27160ab1db98e6dba65381f84b76d4a\n",
            "Successfully built flash-attn\n",
            "Installing collected packages: ninja, flash-attn\n",
            "Successfully installed flash-attn-2.3.3 ninja-1.11.1.1\n",
            "Collecting fonttools==4.43.1\n",
            "  Downloading fonttools-4.43.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fonttools\n",
            "  Attempting uninstall: fonttools\n",
            "    Found existing installation: fonttools 4.47.2\n",
            "    Uninstalling fonttools-4.47.2:\n",
            "      Successfully uninstalled fonttools-4.47.2\n",
            "Successfully installed fonttools-4.43.1\n",
            "Collecting frozenlist==1.4.0\n",
            "  Downloading frozenlist-1.4.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (225 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.7/225.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: frozenlist\n",
            "  Attempting uninstall: frozenlist\n",
            "    Found existing installation: frozenlist 1.4.1\n",
            "    Uninstalling frozenlist-1.4.1:\n",
            "      Successfully uninstalled frozenlist-1.4.1\n",
            "Successfully installed frozenlist-1.4.0\n",
            "Requirement already satisfied: fsspec==2023.6.0 in /usr/local/lib/python3.10/dist-packages (2023.6.0)\n",
            "Requirement already satisfied: fuzzywuzzy==0.18.0 in /usr/local/lib/python3.10/dist-packages (0.18.0)\n",
            "Collecting google-auth==2.23.3\n",
            "  Downloading google_auth-2.23.3-py2.py3-none-any.whl (182 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.3/182.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth==2.23.3) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth==2.23.3) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth==2.23.3) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth==2.23.3) (0.5.1)\n",
            "Installing collected packages: google-auth\n",
            "  Attempting uninstall: google-auth\n",
            "    Found existing installation: google-auth 2.17.3\n",
            "    Uninstalling google-auth-2.17.3:\n",
            "      Successfully uninstalled google-auth-2.17.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "google-colab 1.0.0 requires google-auth==2.17.3, but you have google-auth 2.23.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed google-auth-2.23.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting google-auth-oauthlib==1.1.0\n",
            "  Downloading google_auth_oauthlib-1.1.0-py2.py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib==1.1.0) (2.23.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib==1.1.0) (1.3.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-auth-oauthlib==1.1.0) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-auth-oauthlib==1.1.0) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-auth-oauthlib==1.1.0) (4.9)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib==1.1.0) (3.2.2)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib==1.1.0) (2.31.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-auth-oauthlib==1.1.0) (0.5.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib==1.1.0) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib==1.1.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib==1.1.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib==1.1.0) (2023.7.22)\n",
            "Installing collected packages: google-auth-oauthlib\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.0\n",
            "    Uninstalling google-auth-oauthlib-1.2.0:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.0\n",
            "Successfully installed google-auth-oauthlib-1.1.0\n",
            "Requirement already satisfied: gradio==3.41.0 in /usr/local/lib/python3.10/dist-packages (3.41.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.41.0) (23.2.1)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.41.0) (5.1.2)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio==3.41.0) (0.104.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio==3.41.0) (0.3.1)\n",
            "Requirement already satisfied: gradio-client==0.5.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.41.0) (0.5.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from gradio==3.41.0) (0.26.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.41.0) (0.20.2)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio==3.41.0) (6.1.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.41.0) (3.1.3)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.41.0) (2.1.3)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.41.0) (3.7.1)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.41.0) (1.23.5)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.41.0) (3.9.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio==3.41.0) (23.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.41.0) (1.5.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.41.0) (10.0.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from gradio==3.41.0) (1.10.11)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio==3.41.0) (0.25.1)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (from gradio==3.41.0) (0.0.6)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.41.0) (6.0.1)\n",
            "Requirement already satisfied: requests~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.41.0) (2.31.0)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.41.0) (2.10.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.41.0) (4.9.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.41.0) (0.26.0)\n",
            "Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.41.0) (11.0.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.5.0->gradio==3.41.0) (2023.6.0)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.41.0) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.41.0) (0.12.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio==3.41.0) (3.12.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio==3.41.0) (4.65.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.41.0) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.41.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.41.0) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.41.0) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.41.0) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.41.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio==3.41.0) (2023.3.post1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio==3.41.0) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio==3.41.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio==3.41.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio==3.41.0) (2023.7.22)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio==3.41.0) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio==3.41.0) (0.14.0)\n",
            "Requirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio==3.41.0) (3.7.1)\n",
            "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio==3.41.0) (0.27.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.41.0) (1.0.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.41.0) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi->gradio==3.41.0) (1.2.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.41.0) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.41.0) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.41.0) (0.32.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.41.0) (0.17.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio==3.41.0) (1.16.0)\n",
            "Requirement already satisfied: gradio-client==0.5.0 in /usr/local/lib/python3.10/dist-packages (0.5.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.5.0) (2023.6.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.5.0) (0.26.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.5.0) (0.20.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.5.0) (23.1)\n",
            "Requirement already satisfied: requests~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.5.0) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.5.0) (4.9.0)\n",
            "Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.5.0) (11.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.0->gradio-client==0.5.0) (3.12.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.0->gradio-client==0.5.0) (4.65.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.0->gradio-client==0.5.0) (6.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio-client==0.5.0) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio-client==0.5.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio-client==0.5.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio-client==0.5.0) (2023.7.22)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio-client==0.5.0) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->gradio-client==0.5.0) (1.0.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio-client==0.5.0) (1.3.0)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->gradio-client==0.5.0) (0.14.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->gradio-client==0.5.0) (1.2.0)\n",
            "Collecting greenlet==3.0.0\n",
            "  Downloading greenlet-3.0.0-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (612 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m612.9/612.9 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: greenlet\n",
            "  Attempting uninstall: greenlet\n",
            "    Found existing installation: greenlet 3.0.3\n",
            "    Uninstalling greenlet-3.0.3:\n",
            "      Successfully uninstalled greenlet-3.0.3\n",
            "Successfully installed greenlet-3.0.0\n",
            "Collecting grpcio==1.59.0\n",
            "  Downloading grpcio-1.59.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: grpcio\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.60.0\n",
            "    Uninstalling grpcio-1.60.0:\n",
            "      Successfully uninstalled grpcio-1.60.0\n",
            "Successfully installed grpcio-1.59.0\n",
            "Requirement already satisfied: h11==0.14.0 in /usr/local/lib/python3.10/dist-packages (0.14.0)\n",
            "Collecting httpcore==0.18.0\n",
            "  Downloading httpcore-0.18.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore==0.18.0) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpcore==0.18.0) (2023.7.22)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==0.18.0) (0.14.0)\n",
            "Requirement already satisfied: sniffio==1.* in /usr/local/lib/python3.10/dist-packages (from httpcore==0.18.0) (1.3.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->httpcore==0.18.0) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->httpcore==0.18.0) (1.2.0)\n",
            "Installing collected packages: httpcore\n",
            "  Attempting uninstall: httpcore\n",
            "    Found existing installation: httpcore 1.0.2\n",
            "    Uninstalling httpcore-1.0.2:\n",
            "      Successfully uninstalled httpcore-1.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "httpx 0.26.0 requires httpcore==1.*, but you have httpcore 0.18.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed httpcore-0.18.0\n",
            "Collecting httpx==0.25.0\n",
            "  Downloading httpx-0.25.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.7/75.7 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.25.0) (2023.7.22)\n",
            "Requirement already satisfied: httpcore<0.19.0,>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from httpx==0.25.0) (0.18.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx==0.25.0) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.25.0) (1.3.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.19.0,>=0.18.0->httpx==0.25.0) (3.7.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.19.0,>=0.18.0->httpx==0.25.0) (0.14.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->httpcore<0.19.0,>=0.18.0->httpx==0.25.0) (1.2.0)\n",
            "Installing collected packages: httpx\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.26.0\n",
            "    Uninstalling httpx-0.26.0:\n",
            "      Successfully uninstalled httpx-0.26.0\n",
            "Successfully installed httpx-0.25.0\n",
            "Collecting huggingface-hub==0.17.3\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub==0.17.3) (3.12.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub==0.17.3) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub==0.17.3) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub==0.17.3) (4.65.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub==0.17.3) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub==0.17.3) (4.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub==0.17.3) (23.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub==0.17.3) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub==0.17.3) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub==0.17.3) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub==0.17.3) (2023.7.22)\n",
            "Installing collected packages: huggingface-hub\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.20.2\n",
            "    Uninstalling huggingface-hub-0.20.2:\n",
            "      Successfully uninstalled huggingface-hub-0.20.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "autotrain-advanced 0.6.37 requires datasets[vision]~=2.14.0, but you have datasets 2.15.0 which is incompatible.\n",
            "datasets 2.15.0 requires huggingface-hub>=0.18.0, but you have huggingface-hub 0.17.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed huggingface-hub-0.17.3\n",
            "Collecting idna==3.4\n",
            "  Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: idna\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.6\n",
            "    Uninstalling idna-3.6:\n",
            "      Successfully uninstalled idna-3.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed idna-3.4\n",
            "Collecting imageio==2.31.5\n",
            "  Downloading imageio-2.31.5-py3-none-any.whl (313 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.2/313.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from imageio==2.31.5) (1.23.5)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio==2.31.5) (10.0.0)\n",
            "Installing collected packages: imageio\n",
            "  Attempting uninstall: imageio\n",
            "    Found existing installation: imageio 2.31.6\n",
            "    Uninstalling imageio-2.31.6:\n",
            "      Successfully uninstalled imageio-2.31.6\n",
            "Successfully installed imageio-2.31.5\n",
            "Collecting importlib-metadata==6.8.0\n",
            "  Downloading importlib_metadata-6.8.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata==6.8.0) (3.17.0)\n",
            "Installing collected packages: importlib-metadata\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 7.0.1\n",
            "    Uninstalling importlib-metadata-7.0.1:\n",
            "      Successfully uninstalled importlib-metadata-7.0.1\n",
            "Successfully installed importlib-metadata-6.8.0\n",
            "Collecting importlib-resources==6.1.0\n",
            "  Downloading importlib_resources-6.1.0-py3-none-any.whl (33 kB)\n",
            "Installing collected packages: importlib-resources\n",
            "  Attempting uninstall: importlib-resources\n",
            "    Found existing installation: importlib-resources 6.1.1\n",
            "    Uninstalling importlib-resources-6.1.1:\n",
            "      Successfully uninstalled importlib-resources-6.1.1\n",
            "Successfully installed importlib-resources-6.1.0\n",
            "Collecting inquirerpy==0.3.4\n",
            "  Downloading InquirerPy-0.3.4-py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.7/67.7 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pfzy<0.4.0,>=0.3.1 (from inquirerpy==0.3.4)\n",
            "  Downloading pfzy-0.3.4-py3-none-any.whl (8.5 kB)\n",
            "Requirement already satisfied: prompt-toolkit<4.0.0,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from inquirerpy==0.3.4) (3.0.43)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit<4.0.0,>=3.0.1->inquirerpy==0.3.4) (0.2.13)\n",
            "Installing collected packages: pfzy, inquirerpy\n",
            "Successfully installed inquirerpy-0.3.4 pfzy-0.3.4\n",
            "Requirement already satisfied: invisible-watermark==0.2.0 in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: Pillow>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from invisible-watermark==0.2.0) (10.0.0)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from invisible-watermark==0.2.0) (1.5.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from invisible-watermark==0.2.0) (1.23.5)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.10/dist-packages (from invisible-watermark==0.2.0) (4.8.0.76)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from invisible-watermark==0.2.0) (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->invisible-watermark==0.2.0) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->invisible-watermark==0.2.0) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->invisible-watermark==0.2.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->invisible-watermark==0.2.0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->invisible-watermark==0.2.0) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->invisible-watermark==0.2.0) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->invisible-watermark==0.2.0) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->invisible-watermark==0.2.0) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->invisible-watermark==0.2.0) (1.3.0)\n",
            "Requirement already satisfied: ipadic==1.0.0 in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "Collecting jinja2==3.1.2\n",
            "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2==3.1.2) (2.1.3)\n",
            "Installing collected packages: jinja2\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.3\n",
            "    Uninstalling Jinja2-3.1.3:\n",
            "      Successfully uninstalled Jinja2-3.1.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed jinja2-3.1.2\n",
            "Requirement already satisfied: jiwer==3.0.2 in /usr/local/lib/python3.10/dist-packages (3.0.2)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from jiwer==3.0.2) (8.1.7)\n",
            "Requirement already satisfied: rapidfuzz==2.13.7 in /usr/local/lib/python3.10/dist-packages (from jiwer==3.0.2) (2.13.7)\n",
            "Requirement already satisfied: joblib==1.3.1 in /usr/local/lib/python3.10/dist-packages (1.3.1)\n",
            "Collecting jsonschema==4.19.1\n",
            "  Downloading jsonschema-4.19.1-py3-none-any.whl (83 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.3/83.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema==4.19.1) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema==4.19.1) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema==4.19.1) (0.32.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema==4.19.1) (0.17.1)\n",
            "Installing collected packages: jsonschema\n",
            "  Attempting uninstall: jsonschema\n",
            "    Found existing installation: jsonschema 4.19.2\n",
            "    Uninstalling jsonschema-4.19.2:\n",
            "      Successfully uninstalled jsonschema-4.19.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed jsonschema-4.19.1\n",
            "Collecting jsonschema-specifications==2023.7.1\n",
            "  Downloading jsonschema_specifications-2023.7.1-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: referencing>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema-specifications==2023.7.1) (0.32.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from referencing>=0.28.0->jsonschema-specifications==2023.7.1) (23.1.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from referencing>=0.28.0->jsonschema-specifications==2023.7.1) (0.17.1)\n",
            "Installing collected packages: jsonschema-specifications\n",
            "  Attempting uninstall: jsonschema-specifications\n",
            "    Found existing installation: jsonschema-specifications 2023.12.1\n",
            "    Uninstalling jsonschema-specifications-2023.12.1:\n",
            "      Successfully uninstalled jsonschema-specifications-2023.12.1\n",
            "Successfully installed jsonschema-specifications-2023.7.1\n",
            "Requirement already satisfied: kiwisolver==1.4.5 in /usr/local/lib/python3.10/dist-packages (1.4.5)\n",
            "Requirement already satisfied: lazy-loader==0.3 in /usr/local/lib/python3.10/dist-packages (0.3)\n",
            "Requirement already satisfied: loguru==0.7.0 in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
            "Collecting mako==1.2.4\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from mako==1.2.4) (2.1.3)\n",
            "Installing collected packages: mako\n",
            "  Attempting uninstall: mako\n",
            "    Found existing installation: Mako 1.3.0\n",
            "    Uninstalling Mako-1.3.0:\n",
            "      Successfully uninstalled Mako-1.3.0\n",
            "Successfully installed mako-1.2.4\n",
            "Collecting markdown==3.5\n",
            "  Downloading Markdown-3.5-py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: markdown\n",
            "  Attempting uninstall: markdown\n",
            "    Found existing installation: Markdown 3.5.2\n",
            "    Uninstalling Markdown-3.5.2:\n",
            "      Successfully uninstalled Markdown-3.5.2\n",
            "Successfully installed markdown-3.5\n",
            "Requirement already satisfied: markdown-it-py==3.0.0 in /usr/local/lib/python3.10/dist-packages (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py==3.0.0) (0.1.2)\n",
            "Requirement already satisfied: markupsafe==2.1.3 in /usr/local/lib/python3.10/dist-packages (2.1.3)\n",
            "Collecting matplotlib==3.8.0\n",
            "  Downloading matplotlib-3.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.8.0) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.8.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.8.0) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.8.0) (1.4.5)\n",
            "Requirement already satisfied: numpy<2,>=1.21 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.8.0) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.8.0) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.8.0) (10.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.8.0) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.8.0) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib==3.8.0) (1.16.0)\n",
            "Installing collected packages: matplotlib\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.7.1\n",
            "    Uninstalling matplotlib-3.7.1:\n",
            "      Successfully uninstalled matplotlib-3.7.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed matplotlib-3.8.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mdurl==0.1.2 in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Requirement already satisfied: mpmath==1.3.0 in /usr/local/lib/python3.10/dist-packages (1.3.0)\n",
            "Requirement already satisfied: multidict==6.0.4 in /usr/local/lib/python3.10/dist-packages (6.0.4)\n",
            "Requirement already satisfied: multiprocess==0.70.15 in /usr/local/lib/python3.10/dist-packages (0.70.15)\n",
            "Requirement already satisfied: dill>=0.3.7 in /usr/local/lib/python3.10/dist-packages (from multiprocess==0.70.15) (0.3.7)\n",
            "Collecting networkx==3.2\n",
            "  Downloading networkx-3.2-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: networkx\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.2.1\n",
            "    Uninstalling networkx-3.2.1:\n",
            "      Successfully uninstalled networkx-3.2.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed networkx-3.2\n",
            "Requirement already satisfied: ninja==1.11.1.1 in /usr/local/lib/python3.10/dist-packages (1.11.1.1)\n",
            "Collecting numpy==1.26.1\n",
            "  Downloading numpy-1.26.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.23.5\n",
            "    Uninstalling numpy-1.23.5:\n",
            "      Successfully uninstalled numpy-1.23.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "autotrain-advanced 0.6.37 requires datasets[vision]~=2.14.0, but you have datasets 2.15.0 which is incompatible.\n",
            "datasets 2.15.0 requires huggingface-hub>=0.18.0, but you have huggingface-hub 0.17.3 which is incompatible.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.1\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-cublas-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m86.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-cuda-cupti-cu12\n",
            "Successfully installed nvidia-cuda-cupti-cu12-12.1.105\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-cuda-nvrtc-cu12\n",
            "Successfully installed nvidia-cuda-nvrtc-cu12-12.1.105\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-cuda-runtime-cu12\n",
            "Successfully installed nvidia-cuda-runtime-cu12-12.1.105\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nvidia-cublas-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cudnn-cu12==8.9.2.26) (12.1.3.1)\n",
            "Installing collected packages: nvidia-cudnn-cu12\n",
            "Successfully installed nvidia-cudnn-cu12-8.9.2.26\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-cufft-cu12\n",
            "Successfully installed nvidia-cufft-cu12-11.0.2.54\n",
            "Collecting nvidia-curand-cu12\n",
            "  Downloading nvidia_curand_cu12-10.3.4.107-py3-none-manylinux1_x86_64.whl (56.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-curand-cu12\n",
            "Successfully installed nvidia-curand-cu12-10.3.4.107\n",
            "Collecting protobuf==3.20.1\n",
            "  Downloading protobuf-3.20.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.23.4\n",
            "    Uninstalling protobuf-4.23.4:\n",
            "      Successfully uninstalled protobuf-4.23.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "autotrain-advanced 0.6.37 requires datasets[vision]~=2.14.0, but you have datasets 2.15.0 which is incompatible.\n",
            "autotrain-advanced 0.6.37 requires protobuf==4.23.4, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-ai-generativelanguage 0.4.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-api-core 2.11.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-aiplatform 1.39.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-bigquery 3.12.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-bigquery-connection 1.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.24.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-datastore 2.15.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-firestore 2.11.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-functions 1.13.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-iam 2.13.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-language 2.9.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-resource-manager 1.11.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-translate 3.11.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "googleapis-common-protos 1.62.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "grpc-google-iam-v1 0.13.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "tensorflow 2.15.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.20.1 which is incompatible.\n",
            "tensorflow-metadata 1.14.0 requires absl-py<2.0.0,>=0.9, but you have absl-py 2.0.0 which is incompatible.\n",
            "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 3.20.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed protobuf-3.20.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting trl==0.4.7\n",
            "  Downloading trl-0.4.7-py3-none-any.whl (77 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/77.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m61.4/77.4 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.4/77.4 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from trl==0.4.7) (2.1.0+cu121)\n",
            "Requirement already satisfied: transformers>=4.18.0 in /usr/local/lib/python3.10/dist-packages (from trl==0.4.7) (4.35.2)\n",
            "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.10/dist-packages (from trl==0.4.7) (1.26.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from trl==0.4.7) (0.21.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from trl==0.4.7) (2.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl==0.4.7) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl==0.4.7) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl==0.4.7) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl==0.4.7) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl==0.4.7) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl==0.4.7) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl==0.4.7) (2.1.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.18.0->trl==0.4.7) (0.17.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.18.0->trl==0.4.7) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.18.0->trl==0.4.7) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.18.0->trl==0.4.7) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.18.0->trl==0.4.7) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.18.0->trl==0.4.7) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.18.0->trl==0.4.7) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.18.0->trl==0.4.7) (4.65.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->trl==0.4.7) (5.9.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->trl==0.4.7) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->trl==0.4.7) (0.6)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->trl==0.4.7) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->trl==0.4.7) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->trl==0.4.7) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->trl==0.4.7) (0.70.15)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->trl==0.4.7) (3.8.6)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers>=4.18.0->trl==0.4.7)\n",
            "  Downloading huggingface_hub-0.20.3-py3-none-any.whl (330 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.1/330.1 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl==0.4.7) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl==0.4.7) (3.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl==0.4.7) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl==0.4.7) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl==0.4.7) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl==0.4.7) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl==0.4.7) (1.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.18.0->trl==0.4.7) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.18.0->trl==0.4.7) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.18.0->trl==0.4.7) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.4.0->trl==0.4.7) (2.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl==0.4.7) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl==0.4.7) (2023.3.post1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.4.0->trl==0.4.7) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets->trl==0.4.7) (1.16.0)\n",
            "Installing collected packages: huggingface-hub, trl\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.17.3\n",
            "    Uninstalling huggingface-hub-0.17.3:\n",
            "      Successfully uninstalled huggingface-hub-0.17.3\n",
            "  Attempting uninstall: trl\n",
            "    Found existing installation: trl 0.7.10\n",
            "    Uninstalling trl-0.7.10:\n",
            "      Successfully uninstalled trl-0.7.10\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "autotrain-advanced 0.6.37 requires datasets[vision]~=2.14.0, but you have datasets 2.15.0 which is incompatible.\n",
            "autotrain-advanced 0.6.37 requires protobuf==4.23.4, but you have protobuf 3.20.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed huggingface-hub-0.20.3 trl-0.4.7\n"
          ]
        }
      ],
      "source": [
        "!pip install absl-py==2.0.0\n",
        "!pip install accelerate==0.21.0\n",
        "!pip install aiofiles==23.2.1\n",
        "!pip install aiohttp==3.8.6\n",
        "!pip install aiosignal==1.3.1\n",
        "!pip install albumentations==1.3.1\n",
        "!pip install alembic==1.12.0\n",
        "!pip install altair==5.1.2\n",
        "!pip install anyio==3.7.1\n",
        "!pip install arrow==1.3.0\n",
        "!pip install async-timeout==4.0.3\n",
        "!pip install attrs==23.1.0\n",
        "!pip install autotrain-advanced==0.6.37\n",
        "!pip install bitsandbytes==0.40.2\n",
        "!pip install cachetools==5.3.1\n",
        "!pip install certifi==2023.7.22\n",
        "!pip install charset-normalizer==3.3.0\n",
        "!pip install click==8.1.7\n",
        "!pip install cmaes==0.10.0\n",
        "!pip install codecarbon==2.2.3\n",
        "!pip install colorlog==6.7.0\n",
        "!pip install contourpy==1.1.1\n",
        "!pip install cycler==0.12.1\n",
        "!pip install datasets==2.15.0\n",
        "!pip install diffusers==0.21.4\n",
        "!pip install dill==0.3.7\n",
        "!pip install docstring-parser==0.15\n",
        "!pip install einops==0.6.1\n",
        "!pip install evaluate==0.3.0\n",
        "!pip install fastapi==0.104.0\n",
        "!pip install ffmpy==0.3.1\n",
        "!pip install filelock==3.12.4\n",
        "!pip install flash-attn==2.3.3\n",
        "!pip install fonttools==4.43.1\n",
        "!pip install frozenlist==1.4.0\n",
        "!pip install fsspec==2023.6.0\n",
        "!pip install fuzzywuzzy==0.18.0\n",
        "!pip install google-auth==2.23.3\n",
        "!pip install google-auth-oauthlib==1.1.0\n",
        "!pip install gradio==3.41.0\n",
        "!pip install gradio-client==0.5.0\n",
        "!pip install greenlet==3.0.0\n",
        "!pip install grpcio==1.59.0\n",
        "!pip install h11==0.14.0\n",
        "!pip install httpcore==0.18.0\n",
        "!pip install httpx==0.25.0\n",
        "!pip install huggingface-hub==0.17.3\n",
        "!pip install idna==3.4\n",
        "!pip install imageio==2.31.5\n",
        "!pip install importlib-metadata==6.8.0\n",
        "!pip install importlib-resources==6.1.0\n",
        "!pip install inquirerpy==0.3.4\n",
        "!pip install invisible-watermark==0.2.0\n",
        "!pip install ipadic==1.0.0\n",
        "!pip install jinja2==3.1.2\n",
        "!pip install jiwer==3.0.2\n",
        "!pip install joblib==1.3.1\n",
        "!pip install jsonschema==4.19.1\n",
        "!pip install jsonschema-specifications==2023.7.1\n",
        "!pip install kiwisolver==1.4.5\n",
        "!pip install lazy-loader==0.3\n",
        "!pip install loguru==0.7.0\n",
        "!pip install mako==1.2.4\n",
        "!pip install markdown==3.5\n",
        "!pip install markdown-it-py==3.0.0\n",
        "!pip install markupsafe==2.1.3\n",
        "!pip install matplotlib==3.8.0\n",
        "!pip install mdurl==0.1.2\n",
        "!pip install mpmath==1.3.0\n",
        "!pip install multidict==6.0.4\n",
        "!pip install multiprocess==0.70.15\n",
        "!pip install networkx==3.2\n",
        "!pip install ninja==1.11.1.1\n",
        "!pip install numpy==1.26.1\n",
        "!pip install nvidia-cublas-cu12==12.1.3.1\n",
        "!pip install nvidia-cuda-cupti-cu12==12.1.105\n",
        "!pip install nvidia-cuda-nvrtc-cu12==12.1.105\n",
        "!pip install nvidia-cuda-runtime-cu12==12.1.105\n",
        "!pip install nvidia-cudnn-cu12==8.9.2.26\n",
        "!pip install nvidia-cufft-cu12==11.0.2.54\n",
        "!pip install nvidia-curand-cu12\n",
        "!pip install protobuf==3.20.1\n",
        "!pip install trl==0.4.7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6Jlbq9mjmgq",
        "outputId": "2ee76601-a1a3-4bce-f47a-9433f4aceab6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.31.0\n",
            "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (3.12.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (1.26.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.31.0)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m101.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (4.65.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.31.0) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.31.0) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0) (2023.7.22)\n",
            "Installing collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.15.0\n",
            "    Uninstalling tokenizers-0.15.0:\n",
            "      Successfully uninstalled tokenizers-0.15.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.35.2\n",
            "    Uninstalling transformers-4.35.2:\n",
            "      Successfully uninstalled transformers-4.35.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "autotrain-advanced 0.6.37 requires datasets[vision]~=2.14.0, but you have datasets 2.15.0 which is incompatible.\n",
            "autotrain-advanced 0.6.37 requires protobuf==4.23.4, but you have protobuf 3.20.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tokenizers-0.13.3 transformers-4.31.0\n",
            "Requirement already satisfied: sentencepiece==0.1.99 in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Collecting datasets==2.14.5\n",
            "  Downloading datasets-2.14.5-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.6/519.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets==2.14.5) (1.26.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.14.5) (10.0.1)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.14.5) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==2.14.5) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.14.5) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.14.5) (4.65.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets==2.14.5) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets==2.14.5) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.14.5) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==2.14.5) (3.8.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.14.5) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets==2.14.5) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.14.5) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.14.5) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.14.5) (3.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.14.5) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.14.5) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.14.5) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.14.5) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.14.5) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets==2.14.5) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets==2.14.5) (4.9.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.14.5) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.14.5) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.14.5) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.14.5) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.14.5) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets==2.14.5) (1.16.0)\n",
            "Installing collected packages: datasets\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 2.15.0\n",
            "    Uninstalling datasets-2.15.0:\n",
            "      Successfully uninstalled datasets-2.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "autotrain-advanced 0.6.37 requires protobuf==4.23.4, but you have protobuf 3.20.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.14.5\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install transformers==4.31.0\n",
        "!pip install sentencepiece==0.1.99\n",
        "!pip install datasets==2.14.5\n",
        "!pip install -q bitsandbytes einops wand"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVkGd4wLrOwR",
        "outputId": "e0d10e5e-5222-471f-b016-7974383befc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Projects/bangla-llama/data\n"
          ]
        }
      ],
      "source": [
        "# Train with SentencePiece\n",
        "\n",
        "%cd data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkBNxLIE1R8X",
        "outputId": "1f0f8884-cf1f-4a74-976a-8b406bf68eb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.4G\t/content/drive/My Drive/Projects/bangla-llama/data/bangla_corpus\n",
            "3.0M\t/content/drive/My Drive/Projects/bangla-llama/data/models\n",
            "29G\t/content/drive/My Drive/Projects/bangla-llama/data/uonlp\n",
            "4.0K\t/content/drive/My Drive/Projects/bangla-llama/data/cache\n",
            "224K\t/content/drive/My Drive/Projects/bangla-llama/data/output\n",
            "308M\t/content/drive/My Drive/Projects/bangla-llama/data/bn_part_00007_512\n",
            "7.4G\t/content/drive/My Drive/Projects/bangla-llama/data/bn_part_00007_text_512\n",
            "298M\t/content/drive/My Drive/Projects/bangla-llama/data/bn_part_00003_512\n",
            "7.3G\t/content/drive/My Drive/Projects/bangla-llama/data/bn_part_00003_text_512\n",
            "298M\t/content/drive/My Drive/Projects/bangla-llama/data/bn_part_00013_512\n",
            "7.3G\t/content/drive/My Drive/Projects/bangla-llama/data/bn_part_00013_text_512\n",
            "298M\t/content/drive/My Drive/Projects/bangla-llama/data/bn_part_00006_512\n",
            "7.3G\t/content/drive/My Drive/Projects/bangla-llama/data/bn_part_00006_text_512\n",
            "307M\t/content/drive/My Drive/Projects/bangla-llama/data/bn_part_00014_512\n",
            "8.1G\t/content/drive/My Drive/Projects/bangla-llama/data/bn_part_00014_text_512\n",
            "326M\t/content/drive/My Drive/Projects/bangla-llama/data/bn_part_00016_512\n",
            "5.9G\t/content/drive/My Drive/Projects/bangla-llama/data/bn_part_00016_text_512\n",
            "298M\t/content/drive/My Drive/Projects/bangla-llama/data/bn_part_00009_512\n",
            "7.3G\t/content/drive/My Drive/Projects/bangla-llama/data/bn_part_00009_text_512\n",
            "298M\t/content/drive/My Drive/Projects/bangla-llama/data/bn_part_00002_512\n",
            "7.3G\t/content/drive/My Drive/Projects/bangla-llama/data/bn_part_00002_text_512\n",
            "298M\t/content/drive/My Drive/Projects/bangla-llama/data/bn_part_00004_512\n",
            "7.3G\t/content/drive/My Drive/Projects/bangla-llama/data/bn_part_00004_text_512\n",
            "298M\t/content/drive/My Drive/Projects/bangla-llama/data/bn_part_00012_512\n",
            "7.3G\t/content/drive/My Drive/Projects/bangla-llama/data/bn_part_00012_text_512\n",
            "298M\t/content/drive/My Drive/Projects/bangla-llama/data/bn_part_00005_512\n",
            "7.3G\t/content/drive/My Drive/Projects/bangla-llama/data/bn_part_00005_text_512\n",
            "298M\t/content/drive/My Drive/Projects/bangla-llama/data/bn_part_00008_512\n",
            "7.3G\t/content/drive/My Drive/Projects/bangla-llama/data/bn_part_00008_text_512\n",
            "298M\t/content/drive/My Drive/Projects/bangla-llama/data/bn_part_00001_512\n",
            "7.3G\t/content/drive/My Drive/Projects/bangla-llama/data/bn_part_00001_text_512\n",
            "298M\t/content/drive/My Drive/Projects/bangla-llama/data/bn_part_00000_512\n",
            "7.3G\t/content/drive/My Drive/Projects/bangla-llama/data/bn_part_00000_text_512\n",
            "298M\t/content/drive/My Drive/Projects/bangla-llama/data/bn_part_00011_512\n",
            "7.3G\t/content/drive/My Drive/Projects/bangla-llama/data/bn_part_00011_text_512\n",
            "298M\t/content/drive/My Drive/Projects/bangla-llama/data/bn_part_00010_512\n",
            "7.3G\t/content/drive/My Drive/Projects/bangla-llama/data/bn_part_00010_text_512\n",
            "337M\t/content/drive/My Drive/Projects/bangla-llama/data/bn_part_00015_512\n",
            "11G\t/content/drive/My Drive/Projects/bangla-llama/data/bn_part_00015_text_512\n",
            "11K\t/content/drive/My Drive/Projects/bangla-llama/data/bn_part_00017_512\n",
            "7.1G\t/content/drive/My Drive/Projects/bangla-llama/data/bn_part_00017_text_512\n",
            "169G\t/content/drive/My Drive/Projects/bangla-llama/data\n"
          ]
        }
      ],
      "source": [
        "#!find /content -type f -size +10M -exec du -h {} + | sort -hr\n",
        "!du -h --max-depth=1 /content/drive/My\\ Drive/Projects/bangla-llama/data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAlfp2Va2oZ8",
        "outputId": "1b77c02d-6410-4b77-959f-05c555d93e42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bn\n"
          ]
        }
      ],
      "source": [
        "!ls /content/drive/My\\ Drive/Projects/bangla-llama/data/uonlp/culturaX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqgEzZxcrSdY",
        "outputId": "2de6597b-cc23-4b6a-db57-2f059c777b16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mbangla_corpus\u001b[0m/           \u001b[01;34mbn_part_00005_512\u001b[0m/       \u001b[01;34mbn_part_00010_text_512\u001b[0m/  \u001b[01;34mbn_part_00016_512\u001b[0m/\n",
            "\u001b[01;34mbn_part_00000_512\u001b[0m/       \u001b[01;34mbn_part_00005_text_512\u001b[0m/  \u001b[01;34mbn_part_00011_512\u001b[0m/       \u001b[01;34mbn_part_00016_text_512\u001b[0m/\n",
            "\u001b[01;34mbn_part_00000_text_512\u001b[0m/  \u001b[01;34mbn_part_00006_512\u001b[0m/       \u001b[01;34mbn_part_00011_text_512\u001b[0m/  \u001b[01;34mbn_part_00017_512\u001b[0m/\n",
            "\u001b[01;34mbn_part_00001_512\u001b[0m/       \u001b[01;34mbn_part_00006_text_512\u001b[0m/  \u001b[01;34mbn_part_00012_512\u001b[0m/       \u001b[01;34mbn_part_00017_text_512\u001b[0m/\n",
            "\u001b[01;34mbn_part_00001_text_512\u001b[0m/  \u001b[01;34mbn_part_00007_512\u001b[0m/       \u001b[01;34mbn_part_00012_text_512\u001b[0m/  \u001b[01;34mcache\u001b[0m/\n",
            "\u001b[01;34mbn_part_00002_512\u001b[0m/       \u001b[01;34mbn_part_00007_text_512\u001b[0m/  \u001b[01;34mbn_part_00013_512\u001b[0m/       \u001b[01;34mmodels\u001b[0m/\n",
            "\u001b[01;34mbn_part_00002_text_512\u001b[0m/  \u001b[01;34mbn_part_00008_512\u001b[0m/       \u001b[01;34mbn_part_00013_text_512\u001b[0m/  \u001b[01;34moutput\u001b[0m/\n",
            "\u001b[01;34mbn_part_00003_512\u001b[0m/       \u001b[01;34mbn_part_00008_text_512\u001b[0m/  \u001b[01;34mbn_part_00014_512\u001b[0m/       \u001b[01;34muonlp\u001b[0m/\n",
            "\u001b[01;34mbn_part_00003_text_512\u001b[0m/  \u001b[01;34mbn_part_00009_512\u001b[0m/       \u001b[01;34mbn_part_00014_text_512\u001b[0m/\n",
            "\u001b[01;34mbn_part_00004_512\u001b[0m/       \u001b[01;34mbn_part_00009_text_512\u001b[0m/  \u001b[01;34mbn_part_00015_512\u001b[0m/\n",
            "\u001b[01;34mbn_part_00004_text_512\u001b[0m/  \u001b[01;34mbn_part_00010_512\u001b[0m/       \u001b[01;34mbn_part_00015_text_512\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "%ls /content/drive/MyDrive/Projects/bangla-llama/data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgDCcrydrZpa",
        "outputId": "b5241109-ad57-4fa0-a9d6-4c80b45894e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Get:6 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease [18.1 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:10 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,051 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [1,635 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:13 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main Sources [2,263 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,621 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [50.4 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,309 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,340 kB]\n",
            "Get:18 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main amd64 Packages [1,161 kB]\n",
            "Fetched 10.7 MB in 3s (3,607 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ],
      "source": [
        "!apt-get update"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAQWCYtmr5pg",
        "outputId": "70c3ed73-9057-4bbc-9e17-34a191e67514"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "zip is already the newest version (3.0-12build2).\n",
            "unzip is already the newest version (6.0-26ubuntu3.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 26 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!apt-get install -y zip unzip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMnghXVPsAbf",
        "outputId": "6b07acc7-1648-48cb-89dc-ac640e5db772"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unzip:  cannot find or open bangla_corpus.zip, bangla_corpus.zip.zip or bangla_corpus.zip.ZIP.\n"
          ]
        }
      ],
      "source": [
        "#unzip bangla corpus\n",
        "#!unzip bangla_corpus.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMoNiNbtsIyr",
        "outputId": "d1fada95-1c87-4757-e472-4643c98173ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ben-bd_web_2017_1M.tar.gz  ben_news_2020_300K.tar.gz\t ben_wikipedia_2021_1M\t       corpus\n",
            "ben_community_2022.tar.gz  ben_newscrawl_2017_1M.tar.gz  ben_wikipedia_2021_1M.tar.gz\n"
          ]
        }
      ],
      "source": [
        "!ls bangla_corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uX9GvZ7HsaSR",
        "outputId": "53b6ece5-2410-459f-e721-3c9f96e6dabc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Projects/bangla-llama/data/bangla_corpus\n"
          ]
        }
      ],
      "source": [
        "%cd bangla_corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVn-RDcZsd9y",
        "outputId": "3c1a56fd-fc30-42f4-d0e7-73f697694aa6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ben_wikipedia_2021_1M/\n",
            "ben_wikipedia_2021_1M/ben_wikipedia_2021_1M-co_n.txt\n",
            "ben_wikipedia_2021_1M/ben_wikipedia_2021_1M-import.sql\n",
            "ben_wikipedia_2021_1M/ben_wikipedia_2021_1M-sentences.txt\n",
            "ben_wikipedia_2021_1M/ben_wikipedia_2021_1M-sources.txt\n",
            "ben_wikipedia_2021_1M/ben_wikipedia_2021_1M-co_s.txt\n",
            "ben_wikipedia_2021_1M/ben_wikipedia_2021_1M-inv_w.txt\n",
            "ben_wikipedia_2021_1M/ben_wikipedia_2021_1M-inv_so.txt\n",
            "ben_wikipedia_2021_1M/ben_wikipedia_2021_1M-words.txt\n"
          ]
        }
      ],
      "source": [
        "#!tar zxvf ben_wikipedia_2021_1M.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AyES0besOKT",
        "outputId": "096342fb-4179-4626-f727-3f251de67aa2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tail: cannot open 'ben_wikipedia_2021_1M/ben_wikipedia_2021_1M-sentences.txt' for reading: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!tail ben_wikipedia_2021_1M/ben_wikipedia_2021_1M-sentences.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfFGQTLFtRTN"
      },
      "outputs": [],
      "source": [
        "#!mkdir /content/drive/MyDrive/Projects/bangla-llama/data/bangla_corpus/corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1f0uMaXptoJZ"
      },
      "outputs": [],
      "source": [
        "#!mkdir /content/drive/MyDrive/Projects/bangla-llama/data/models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0vdkIPvtUv2",
        "outputId": "dd06cd27-b714-48e3-b8e4-80557b83f0d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total 227825\n",
            "-rw------- 1 root root 233292475 Jan 15 23:15 ben_wikipedia_2021_1M-sentences.txt\n"
          ]
        }
      ],
      "source": [
        "!ls -lrt /content/drive/MyDrive/Projects/bangla-llama/data/bangla_corpus/corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wiurLO6htKBM"
      },
      "outputs": [],
      "source": [
        "#!cp /content/drive/MyDrive/Projects/bangla-llama/data/bangla_corpus/ben_wikipedia_2021_1M/ben_wikipedia_2021_1M-sentences.txt /content/drive/MyDrive/Projects/bangla-llama/data/bangla_corpus/corpus/ben_wikipedia_2021_1M-sentences.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXcF36mWsuoc",
        "outputId": "6b20af9a-8a55-44a5-85cc-bda08850a3c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Projects/bangla-llama\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/Projects/bangla-llama/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFpQQPy5tAXb",
        "outputId": "8c455b7f-a175-4f93-e562-f07188d4ac23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ben-bd_web_2017_1M.tar.gz  ben_news_2020_300K.tar.gz\t ben_wikipedia_2021_1M\t       corpus\n",
            "ben_community_2022.tar.gz  ben_newscrawl_2017_1M.tar.gz  ben_wikipedia_2021_1M.tar.gz\n"
          ]
        }
      ],
      "source": [
        "!ls /content/drive/MyDrive/Projects/bangla-llama/data/bangla_corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-FFDXVPEzma"
      },
      "outputs": [],
      "source": [
        "# Create bangla corpus from huggingface dataset\n",
        "import argparse\n",
        "import logging\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "from tqdm import tqdm\n",
        "\n",
        "# logging.basicConfig(\n",
        "#     level=logging.INFO,\n",
        "#     format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n",
        "# )\n",
        "# logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "class CorpusCreator:\n",
        "    def __init__(self):\n",
        "        self.hf_dataset = 'uonlp/CulturaX'\n",
        "        self.text_col = 'text'\n",
        "        self.output_dir = '/content/drive/MyDrive/Projects/bangla-llama/data/bangla_corpus/corpus'\n",
        "        self.dataset_split = 'train'\n",
        "        self.output_file_name = 'bangla_sentence_corpus_from_CulturaX.txt'\n",
        "\n",
        "    def create_sentence_corpus(\n",
        "        self,\n",
        "        hf_dataset, #='/content/drive/MyDrive/Projects/bangla-llama/data/bangla_corpus/corpus',\n",
        "        text_col, #='text',\n",
        "        dataset_split=\"train\",\n",
        "        output_file_name=\"bangla_sentence_corpus.txt\",\n",
        "    ):\n",
        "        try:\n",
        "            dataset = load_dataset(hf_dataset, split=dataset_split)\n",
        "            train_df = pd.DataFrame(dataset)\n",
        "\n",
        "            os.makedirs(self.output_dir, exist_ok=True)\n",
        "            corpus_path = os.path.join(self.output_dir, output_file_name)\n",
        "\n",
        "            with open(corpus_path, \"w\") as file:\n",
        "                for index, value in tqdm(\n",
        "                    train_df[text_col].iteritems(), total=len(train_df)\n",
        "                ):\n",
        "                    file.write(str(value) + \"\\n\")\n",
        "\n",
        "        except Exception as e:\n",
        "            # logger.error(f\"Error creating the text corpus -> {e}\")\n",
        "            pass\n",
        "\n",
        "        return corpus_path\n",
        "\n",
        "    def run(self):\n",
        "        parser = argparse.ArgumentParser(\n",
        "            description=\"Create a sentence corpus from a Hugging Face dataset.\"\n",
        "        )\n",
        "        parser.add_argument(\n",
        "            \"--hf-dataset\",\n",
        "            # required=True,\n",
        "            help=\"Name of the Hugging Face dataset (e.g., 'imdb').\",\n",
        "        )\n",
        "        parser.add_argument(\n",
        "            \"--text-col\",\n",
        "            # required=True,\n",
        "            help=\"Name of the text column in the dataset.\",\n",
        "        )\n",
        "        parser.add_argument(\n",
        "            \"--dataset-split\",\n",
        "            default=\"train\",\n",
        "            help=\"Dataset split to use (default: 'train').\",\n",
        "        )\n",
        "        parser.add_argument(\n",
        "            \"--output-file-name\",\n",
        "            default=\"tamil_sentence_corpus.txt\",\n",
        "            help=\"Name of the output corpus file (default: 'tamil_sentence_corpus.txt').\",\n",
        "        )\n",
        "\n",
        "        arg_str = '--hf-dataset ' + self.hf_dataset + ' --text-col ' + self.text_col + ' --dataset-split ' + self.dataset_split + ' --output-file-name ' + self.output_file_name\n",
        "        args = parser.parse_args(arg_str.split())\n",
        "        print(args)\n",
        "        self.create_sentence_corpus(\n",
        "            args.hf_dataset, args.text_col, args.dataset_split, args.output_file_name\n",
        "        )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ocf0q6i8GMiC"
      },
      "outputs": [],
      "source": [
        "corpus_creator = CorpusCreator()\n",
        "#corpus_creator.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zc15vTYUOAK"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ic_FoWIFH41G"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset_name = 'uonlp/CulturaX' #french novels\n",
        "#dataset = load_dataset(dataset_name, \"bn\", use_auth_token=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fjpT0ReXRtZ"
      },
      "outputs": [],
      "source": [
        "#!mkdir /content/drive/MyDrive/Projects/bangla-llama/data/cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O2EYsf3JXctJ"
      },
      "outputs": [],
      "source": [
        "#!mkdir /content/drive/MyDrive/Projects/bangla-llama/data/output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1vGA2BA9TRL",
        "outputId": "c8639926-5db2-467a-84d1-084395d0bedc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Projects/bangla-llama/data/uonlp/culturaX/bn:\n",
            "bn_part_00000.parquet  bn_part_00005.parquet  bn_part_00010.parquet  bn_part_00015.parquet\n",
            "bn_part_00001.parquet  bn_part_00006.parquet  bn_part_00011.parquet  bn_part_00016.parquet\n",
            "bn_part_00002.parquet  bn_part_00007.parquet  bn_part_00012.parquet  bn_part_00017.parquet\n",
            "bn_part_00003.parquet  bn_part_00008.parquet  bn_part_00013.parquet\n",
            "bn_part_00004.parquet  bn_part_00009.parquet  bn_part_00014.parquet\n"
          ]
        }
      ],
      "source": [
        "!ls -R /content/drive/MyDrive/Projects/bangla-llama/data/uonlp/culturaX/bn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "720e021855e143a2a27ce91adf234209",
            "82b5c59d829b4b3483531678173c4ae4",
            "0779842cd9b64198ae1517da1ff8f405",
            "a6e9621d424340e693a301d1de7e1435",
            "e997a293549f41be8ff8bdfa511cad54",
            "0ed211bdefd748dfa14535ed99891238",
            "f44b6f3251784c148a27042f5c982950",
            "0f880e16905a4be1b718273daceac680",
            "6a0cab4a12aa4387856747ba1b5a9c3c",
            "d77d5b8bb4b04b0b9a8c1d7b7bff4082",
            "a8456d230c704ab9b7264e5b815c4c12",
            "991c844cbeba4bc5a9c0c628fb9d750c",
            "f571015852eb4df0a356f98edff00646",
            "42d4a74ea6aa430bb0207309448c984f",
            "8c128584f6d94fa5826f9e51ab4dd769",
            "68736d7bef8f464a9ac99bf3a37c0a61",
            "1f192500bcd34ffd851504aa7f5ebafc",
            "92346b3e0d964e349a990b28b913b764",
            "36c4a3510d204df0bcf8fd8e489335b8",
            "eb8014a53cb84abcb0ace6864bd2ef96",
            "33ea235f0a85492d8f723a7dcb532b66",
            "04d0f620e7d54a76b88998dd1fff5bdb",
            "8a66255895fe4a84abea2bd29b980bef",
            "7f9b10f32ac04c909e9218a146cb0ee6",
            "f8e736390872479dac25f52404947bda",
            "d1da4e3908bf468c96a692edd69c06d3",
            "fcfed57b5f2148f0b56d5857dd6056f1",
            "36c9d990123147eaa12bae188abb1fde",
            "96cebf3d2dec4d178d4ad7030cbc91a6",
            "c8388c595da1420ba7fbfedb5196b09f",
            "49359dbf5f544bb3a5ba8d0d4088e2a2",
            "ac4b4b923a3e45dd9e31c065aa4df0ea",
            "a30f800461174e0993a2a60a48b2ac98",
            "e6e9c03e9e5c45ea8ffcf43cb34b85d2",
            "3fbd883cd0344882a02f5dc78041e0d2",
            "fb94cdd865b94ae2bde1189333412698",
            "95d0e0b8ef04423fb50cf257b5f002fd",
            "95e483355a7c41adbc8e98fa860f4c2a",
            "8a46818fb4fc4587aca1b11e1d71eace",
            "7811b700c799497486ae056ffc362fde",
            "d4286a71fc8544bbaad3f2a9b779e888",
            "c3e390c62c2c4652ae245cd946d4dfe8",
            "aecbf1f7d27f48da88d60589547820d1",
            "5c728be6054b4137a0dfdb2142c67cd4"
          ]
        },
        "id": "6lWMt0ne8_GZ",
        "outputId": "d725398d-3ed5-4dd3-88c7-69cbcb76038c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "720e021855e143a2a27ce91adf234209",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Resolving data files:   0%|          | 0/18 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "991c844cbeba4bc5a9c0c628fb9d750c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8a66255895fe4a84abea2bd29b980bef",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e6e9c03e9e5c45ea8ffcf43cb34b85d2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# from datasets import load_dataset\n",
        "\n",
        "# # Path to the directory containing the Parquet files\n",
        "# data_dir = '/content/drive/MyDrive/Projects/bangla-llama/data/uonlp/culturaX/bn'\n",
        "\n",
        "# # List of all Parquet files\n",
        "# parquet_files = [f'{data_dir}/bn_part_00000.parquet',\n",
        "#                  f'{data_dir}/bn_part_00001.parquet',\n",
        "#                  f'{data_dir}/bn_part_00002.parquet',\n",
        "#                  f'{data_dir}/bn_part_00003.parquet',\n",
        "#                  f'{data_dir}/bn_part_00004.parquet',\n",
        "#                  f'{data_dir}/bn_part_00005.parquet',\n",
        "#                  f'{data_dir}/bn_part_00006.parquet',\n",
        "#                  f'{data_dir}/bn_part_00007.parquet',\n",
        "#                  f'{data_dir}/bn_part_00008.parquet',\n",
        "#                  f'{data_dir}/bn_part_00009.parquet',\n",
        "#                  f'{data_dir}/bn_part_00010.parquet',\n",
        "#                  f'{data_dir}/bn_part_00011.parquet',\n",
        "#                  f'{data_dir}/bn_part_00012.parquet',\n",
        "#                  f'{data_dir}/bn_part_00013.parquet',\n",
        "#                  f'{data_dir}/bn_part_00014.parquet',\n",
        "#                  f'{data_dir}/bn_part_00015.parquet',\n",
        "#                  f'{data_dir}/bn_part_00016.parquet',\n",
        "#                  f'{data_dir}/bn_part_00017.parquet']\n",
        "\n",
        "# # Load the dataset\n",
        "# dataset = load_dataset('parquet', data_files=parquet_files, split='train', keep_in_memory=False)\n",
        "\n",
        "# Display the dataset structure\n",
        "#print(dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtUDniumS0b3"
      },
      "outputs": [],
      "source": [
        "#dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RY636txXKcvZ"
      },
      "outputs": [],
      "source": [
        "batch = dataset.select(range(10000, 20001))\n",
        "tenth_thousandth_text = batch['text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "TjgLIelDUrp3",
        "outputId": "2e737a83-6ccb-4c6a-bb13-a38a8354774e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ডাকসুর ভিপি নুরের ওপরও ডিম নিক্ষেপ | uttorbangla.com\\nআজ- বৃহস্পতিবার, ৪ জুন, ২০২০ :: ২১ জ্যৈষ্ঠ ১৪২৭ :: সময়- ২ : ০৭ পুর্বাহ্ন\\nHome / ক্যাম্পাস / ডাকসুর ভিপি নুরের ওপরও ডিম নিক্ষেপ\\nডাকসুর ভিপি নুরের ওপরও ডিম নিক্ষেপ\\nডেস্ক: ঢাকা বিশ্ববিদ্যালয়ের সলিমুল্লাহ মুসলিম (এসএম) হলে দুই ঘণ্টা অবরুদ্ধ থাকার পর মুক্ত হওয়া ডাকসুর ভিপি নুরুল হক নুরের ওপর ডিম নিক্ষেপ করা হয়েছে। এ সময় তার সঙ্গে থাকা অন্য ছাত্র নেতাদের দিকেও ডিম ছোড়া হয়। ছাত্রলীগের নেতাকর্মীরা এই ডিম নিক্ষেপ করেছেন বলে অভিযোগ উঠেছে।\\nএর আগে আজ মঙ্গলবার বিকেল ৫টার দিকে এসএম হলে গেলে নুকরে লাঞ্ছিত ও অবরুদ্ধ করে রাখেন ছাত্রলীগের নেতাকর্মীরা। দুই ঘণ্টা পর সন্ধ্যা ৭টার দিকে প্রাধ্যক্ষ হলে গেলে বেরিয়ে আসেন নুর। এ সময় তার ও সঙ্গীদের ওপর ডিম নিক্ষেপের ঘটনা ঘটে।\\nহলের শিক্ষার্থীদের সঙ্গে কথা বলে জানা যায়, গতকাল সোমবার দিবাগত রাতে এসএম হলের আবাসিক ছাত্র মো. ফরিদ হাসানকে ছাত্রলীগের নেতাকর্মীরা মারধর করে রক্তাক্ত করেন। ওই ঘটনার জের ধরে আজ বিকেল ৫টার দিকে অন্যান্য ছাত্রনেতাদের নিয়ে এসএম হলে যান ভিপি নুর। এ সময় তাকে লাঞ্ছিত করেন ছাত্রলীগ নেতারা। হল অফিসে নুরের থেকে মুচলেকা চাওয়ার একটি ভিডিও ফেসবুকে প্রকাশ পেয়েছে।\\nএসএম হলে শামসুন্নাহার হল সংসদের ভিপি শেখ তাসনিম আফরোজ ইমির শরীরে ছাত্রলীগের নেতারা হাত দিয়েছেন বলে অভিযোগ ওঠে। এ সময় তাদের দিকে ছাত্রলীগের নেতাকর্মীরা ডিম নিক্ষেপ করেন। সন্ধ্যা ৭টার দিকে অবরুদ্ধ থেকে মুক্ত হয়ে ক্যাম্পাসে ভিপি নুরের নেতৃত্বে বিক্ষোভ মিছিল করেন ছাত্রনেতারা। পরে নুর গণমাধ্যমকর্মীদের সঙ্গে কথা বলেন।'"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tenth_thousandth_text[5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kt4yaWheGr-O"
      },
      "outputs": [],
      "source": [
        "corpus_creator.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZUbqIa10aBQr"
      },
      "outputs": [],
      "source": [
        "!cat /content/drive/MyDrive/Projects/bangla-llama/data/bangla_corpus/corpus/ben_wikipedia_2021_1M-sentences.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a29d0tCabD03",
        "outputId": "eaba20f1-891f-492c-8adf-08f1c81b9589"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ben_wikipedia_2021_1M-sentences.txt\n"
          ]
        }
      ],
      "source": [
        "!ls /content/drive/MyDrive/Projects/bangla-llama/data/bangla_corpus/corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pT4xcXOcjrbp"
      },
      "outputs": [],
      "source": [
        "#!rm -rf /content/drive/MyDrive/Projects/bangla-llama/data/models/*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJgCmqXns2Sg"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "import sentencepiece as spm\n",
        "\n",
        "\n",
        "class SentencePieceTrainer:\n",
        "    def __init__(self):\n",
        "        self.corpus_dir = \"/content/drive/MyDrive/Projects/bangla-llama/data/bangla_corpus/corpus\"\n",
        "        self.input_file = self.corpus_dir + \"/ben_wikipedia_2021_1M-sentences.txt\"\n",
        "        self.output_dir = \"/content/drive/MyDrive/Projects/bangla-llama/data/models\"\n",
        "        self.model_prefix = \"bangla_sp\"\n",
        "        self.vocab_size = 20000\n",
        "        self.character_coverage = 1.0\n",
        "        self.model_type = \"unigram\"\n",
        "\n",
        "    def train_sentencepiece_model(self, input_file):\n",
        "        output_model_path = os.path.join(self.output_dir, f\"{self.model_prefix}.model\")\n",
        "\n",
        "        spm.SentencePieceTrainer.train(\n",
        "            input=input_file,\n",
        "            model_prefix=self.model_prefix,\n",
        "            vocab_size=self.vocab_size,\n",
        "            character_coverage=self.character_coverage,\n",
        "            model_type=self.model_type,\n",
        "        )\n",
        "\n",
        "        # os.rename(\n",
        "        #     f\"{self.model_prefix}.vocab\",\n",
        "        #     os.path.join(self.output_dir, f\"{self.model_prefix}.vocab\"),\n",
        "        # )\n",
        "\n",
        "        shutil.move(\n",
        "          f\"{self.model_prefix}.vocab\",\n",
        "           os.path.join(self.output_dir, f\"{self.model_prefix}.vocab\"),\n",
        "        )\n",
        "\n",
        "        # os.rename(\n",
        "        #     f\"{self.model_prefix}.model\",\n",
        "        #     os.path.join(self.output_dir, f\"{self.model_prefix}.model\"),\n",
        "        # )\n",
        "\n",
        "        shutil.move(\n",
        "          f\"{self.model_prefix}.model\",\n",
        "           os.path.join(self.output_dir, f\"{self.model_prefix}.model\"),\n",
        "        )\n",
        "\n",
        "        return output_model_path\n",
        "\n",
        "    def run(self):\n",
        "        parser = argparse.ArgumentParser(description=\"Train a SentencePiece model.\")\n",
        "        parser.add_argument(\n",
        "            \"--input-file\",\n",
        "            required=True,\n",
        "            help=\"Path to the input text corpus file.\",\n",
        "        )\n",
        "        parser.add_argument(\n",
        "            \"--output-dir\",\n",
        "            default=self.output_dir,\n",
        "            help=\"Directory where the trained model and vocabulary will be saved.\",\n",
        "        )\n",
        "        parser.add_argument(\n",
        "            \"--model-prefix\",\n",
        "            default=self.model_prefix,\n",
        "            help=\"Prefix for the model and vocabulary filenames.\",\n",
        "        )\n",
        "        parser.add_argument(\n",
        "            \"--vocab-size\",\n",
        "            type=int,\n",
        "            default=self.vocab_size,\n",
        "            help=\"Size of the vocabulary.\",\n",
        "        )\n",
        "        parser.add_argument(\n",
        "            \"--character-coverage\",\n",
        "            type=float,\n",
        "            default=self.character_coverage,\n",
        "            help=\"Character coverage for the model.\",\n",
        "        )\n",
        "        parser.add_argument(\n",
        "            \"--model-type\",\n",
        "            default=self.model_type,\n",
        "            choices=[\"bpe\", \"unigram\", \"char\", \"word\"],\n",
        "            help=\"Type of SentencePiece model.\",\n",
        "        )\n",
        "\n",
        "        #args = parser.parse_args()\n",
        "\n",
        "        arg_str = ' --input-file ' + self.input_file + ' --output-dir ' + self.output_dir + ' --model-prefix ' +  self.model_prefix + ' --vocab-size ' + str(self.vocab_size) + ' --character-coverage ' + str(self.character_coverage) + ' --model-type ' + self.model_type\n",
        "\n",
        "        args = parser.parse_args(arg_str.split())\n",
        "\n",
        "        self.output_dir = args.output_dir\n",
        "        self.model_prefix = args.model_prefix\n",
        "        self.vocab_size = args.vocab_size\n",
        "        self.character_coverage = args.character_coverage\n",
        "        self.model_type = args.model_type\n",
        "\n",
        "        os.makedirs(self.output_dir, exist_ok=True)\n",
        "\n",
        "        self.train_sentencepiece_model(args.input_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NhJBqOFUuIxa"
      },
      "outputs": [],
      "source": [
        "sp_trainer = SentencePieceTrainer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRjMGMC5uLnC",
        "outputId": "bb38fb6c-5ae7-4880-8b36-399d688c91be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " --input-file /content/drive/MyDrive/Projects/bangla-llama/data/bangla_corpus/corpus/ben_wikipedia_2021_1M-sentences.txt --output-dir /content/drive/MyDrive/Projects/bangla-llama/data/models --model-prefix bangla_sp --vocab-size 20000 --character-coverage 1.0 --model-type unigram\n"
          ]
        }
      ],
      "source": [
        "#sp_trainer.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tGQLf8Y3cmy",
        "outputId": "2ce2d754-8c6c-4f41-d0c4-56b23390c8cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bangla_sp.model  bangla_sp.vocab  merged_tokenizer_hf  merged_tokenizer_sp\n"
          ]
        }
      ],
      "source": [
        "!ls /content/drive/MyDrive/Projects/bangla-llama/data/models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eg7zJhqH9a59",
        "outputId": "d72ff56d-88bd-4b8e-a9ae-6f52b29c1e40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bangla_sp.model  merged_tokenizer_hf  merged_tokenizer_spbangla_llama.model\n",
            "bangla_sp.vocab  merged_tokenizer_sp\n"
          ]
        }
      ],
      "source": [
        "!ls /content/drive/MyDrive/Projects/bangla-llama/data/models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHoNuRtALned",
        "outputId": "c27f6f71-5fac-4ae1-de53-019e82662e07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ls: cannot access 'scripts': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!ls scripts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RES6-F4He15C",
        "outputId": "4bd7739d-d26c-4f6f-cda3-918779eb659a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Projects/bangla-llama\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/Projects/bangla-llama/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g4_esQYHMXyZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"] = \"python\"\n",
        "import argparse\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APXDVOj4MZuh"
      },
      "outputs": [],
      "source": [
        "import sentencepiece as spm\n",
        "from transformers import LlamaTokenizer\n",
        "from sentencepiece import sentencepiece_model_pb2 as sp_pb2_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VsLwIAvdUh_i"
      },
      "outputs": [],
      "source": [
        "#!mkdir bangla_sp.model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJr4nkSLUwTv"
      },
      "outputs": [],
      "source": [
        "#!mkdir ./llama-tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8c5O2W4McPf"
      },
      "outputs": [],
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--llama_tokenizer_dir\", default=None, type=str, required=True)\n",
        "parser.add_argument(\"--bangla_sp_model_file\", default=\"./tamil_sp.model\", type=str)\n",
        "args = parser.parse_args('--llama_tokenizer_dir /content/drive/MyDrive/Projects/bangla-llama/data/llamatokenizer --bangla_sp_model_file /content/drive/MyDrive/Projects/bangla-llama/data/models/bangla_sp.model'.split())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSmnuCwtX66t"
      },
      "outputs": [],
      "source": [
        "llama_tokenizer_dir = args.llama_tokenizer_dir\n",
        "bangla_sp_model_file = args.bangla_sp_model_file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "fdqJDB1hlQZY",
        "outputId": "a5b4521c-6a76-40ce-a97c-b91410a16808"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/Projects/bangla-llama/data/llamatokenizer'"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llama_tokenizer_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nhLn-AR-htaZ",
        "outputId": "760d3b6b-a95d-4631-dab3-de7d28607d68"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/Projects/bangla-llama/data/models/bangla_sp.model'"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bangla_sp_model_file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "182e5e30abec41609d3ec97ec728806e",
            "3d5f7634c14b42a5a1f459714923e7b1",
            "68590b1519c343eb80cb41f6416b231d",
            "bbb3b0fbba5249ee8ebd02e9dcc943df",
            "25b1afa3f2a04cebb3638cf5c1a0ace7",
            "ba0b649dffe241839ef8c490d953b8da",
            "ca28585c45f44c1ba90a935a9fd80a84",
            "4afb20af14c5486a965257f7ac37ab39",
            "9c5a4f10a3b846f1a3300aa7573d6e90",
            "1f8254a537e747d59b72be8784126c91",
            "19d5d64eb1434ed48c6185ac99e795c9",
            "0f544d143b17457b817e9be313bec6e5",
            "aa5f687cfe1b40088e48f9a190a6031b",
            "445b7b613b134c16bb03733d11fb2fd6",
            "41b9a11e3a154c648dc974a296b3f005",
            "0922856da2504447a45a10c62fc415b1",
            "eeb506fbaa604bb28a50222ad893c0b2",
            "91fc5ca585664eff9d34a1fe2f25132d",
            "96645d05af0747df8bb0571cf5f2a847",
            "21eebf3818f940f9a606ba3a3e0da5b4",
            "d47070f2122d447c940f359d86c62ff0",
            "b5b7914ab2314ab8ba4aef0526e9d175",
            "f0f92ba414ab473694d03f502ccf14f6",
            "9482e25a32774d86a999601a6aa24da7",
            "e55980b7bd4d4137afaaf9c13a10c8a4",
            "29f28473e3524f59a2b09f49501804bb",
            "afa656cedd804bbab891cb3a3b3ccd72",
            "be9b0158a2b8486584812b378f64b110",
            "25bada1822b949f794f0b1d6e49bf6c7",
            "bcef0d60dd1e47ebb6fdaadc4955f004",
            "fff25c9116fb4dde827f1bba65e3910b",
            "100e09c176414b8cb17b7349309ebcdf"
          ]
        },
        "id": "CGrZK-ZOYm9d",
        "outputId": "7656adc6-39a8-4e76-8d10-e041a5b98035"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "182e5e30abec41609d3ec97ec728806e"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from huggingface_hub import login\n",
        "login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJWLMZOtajwv",
        "outputId": "45e3c852-c17f-4618-adcd-5e479380dd57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n",
            "    Setting a new token will erase the existing one.\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: \n",
            "Add token as git credential? (Y/n) Y\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved in your configured git credential helpers (store).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gELArSY2c6I5",
        "outputId": "7ce92b4f-4e02-4e54-e645-8d37e73fa530"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.20.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.12.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.65.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (23.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lf0LttlIck2r"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import HfApi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tS7VDH-Acnyg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# Manually set the token\n",
        "hf_token = \"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\"\n",
        "os.environ[\"HF_TOKEN\"] = hf_token\n",
        "\n",
        "# Use the token to authenticate\n",
        "api = HfApi()\n",
        "#api.set_access_token(hf_token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5Jp7Ybv9dGO4",
        "outputId": "91c8a837-fcc9-4570-8306-51e2a06cf7b2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'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'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "os.getenv(\"HF_TOKEN\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jJQAet9DezW"
      },
      "outputs": [],
      "source": [
        "llama_tokenizer_dir = \"TinyPixel/Llama-2-7B-bf16-sharded\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CNPadJsTVqVc"
      },
      "outputs": [],
      "source": [
        "llama_tokenizer = LlamaTokenizer.from_pretrained(\"TinyPixel/Llama-2-7B-bf16-sharded\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PczkkojTXcYB"
      },
      "outputs": [],
      "source": [
        "bangla_sp_model = spm.SentencePieceProcessor()\n",
        "#bangla_sp_model.Load(bangla_sp_model_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "fT8lPpgK_JRz",
        "outputId": "b32dc712-f4e1-4840-939c-3dc9bf888dff"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/Projects/bangla-llama/data/models/bangla_sp.model'"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bangla_sp_model_file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6zbK1DYVe_O",
        "outputId": "6eca5904-5d69-482f-fc4c-e01e474a00bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bangla_sp_model.Load(bangla_sp_model_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FweCXfUrVeBE",
        "outputId": "0e8fd500-90f0-4bd8-994c-2816d1be9fda"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "499723"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llama_spm = sp_pb2_model.ModelProto()\n",
        "llama_spm.ParseFromString(llama_tokenizer.sp_model.serialized_model_proto())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAXPnz1O_REO",
        "outputId": "b48fa0ba-f6af-4e29-cd6a-2fd91b8a65b3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "690477"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bangla_spm = sp_pb2_model.ModelProto()\n",
        "bangla_spm.ParseFromString(bangla_sp_model.serialized_model_proto())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CG1rdWr_cv3",
        "outputId": "24c07ab5-feda-4e08-d06c-c3d5233ee36d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "32000 20000\n",
            "['<s>', '</s>', '<unk>']\n",
            "[1, 2, 0]\n",
            "{'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>'}\n"
          ]
        }
      ],
      "source": [
        "print(len(llama_tokenizer), len(bangla_sp_model))\n",
        "print(llama_tokenizer.all_special_tokens)\n",
        "print(llama_tokenizer.all_special_ids)\n",
        "print(llama_tokenizer.special_tokens_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUZ_HMYwAKjw",
        "outputId": "68f38d1c-c3ff-461d-e59f-216903e8634b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "32000\n",
            "Before:32000\n",
            "New model pieces: 50437\n"
          ]
        }
      ],
      "source": [
        "## Add Bangla tokens to LLaMA tokenizer\n",
        "llama_spm_tokens_set = set(p.piece for p in llama_spm.pieces)\n",
        "print(len(llama_spm_tokens_set))\n",
        "print(f\"Before:{len(llama_spm_tokens_set)}\")\n",
        "for p in bangla_spm.pieces:\n",
        "    piece = p.piece\n",
        "    if piece not in llama_spm_tokens_set:\n",
        "        new_p = sp_pb2_model.ModelProto().SentencePiece()\n",
        "        new_p.piece = piece\n",
        "        new_p.score = 0\n",
        "        llama_spm.pieces.append(new_p)\n",
        "print(f\"New model pieces: {len(llama_spm.pieces)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEM36bh4A_fo"
      },
      "outputs": [],
      "source": [
        "#%mkdir /content/drive/MyDrive/Projects/bangla-llama/data/models/merged_tokenizer_sp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6DoLx3PBCwO"
      },
      "outputs": [],
      "source": [
        "#%mkdir /content/drive/MyDrive/Projects/bangla-llama/data/models/merged_tokenizer_hf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcS_YGAOBXPA",
        "outputId": "a5cc6341-b5e4-47c2-f7a9-1ace44739555"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bangla_sp.model  bangla_sp.vocab  merged_tokenizer_hf  merged_tokenizer_sp\n"
          ]
        }
      ],
      "source": [
        "!ls /content/drive/MyDrive/Projects/bangla-llama/data/models/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcszcvorBq4i",
        "outputId": "6ba76b71-9f47-4f6b-bdb5-7c89ce5c33b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bangla_llama.model  special_tokens_map.json  tokenizer_config.json  tokenizer.model\n"
          ]
        }
      ],
      "source": [
        "!ls /content/drive/MyDrive/Projects/bangla-llama/data/models/merged_tokenizer_sp/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJK15mT9AgGo"
      },
      "outputs": [],
      "source": [
        "## Save\n",
        "output_sp_dir = \"/content/drive/MyDrive/Projects/bangla-llama/data/models/merged_tokenizer_sp\"\n",
        "output_hf_dir = \"/content/drive/MyDrive/Projects/bangla-llama/data/models/merged_tokenizer_sp\"  # the path to save Tamil-LLaMA tokenizer\n",
        "os.makedirs(output_sp_dir, exist_ok=True)\n",
        "with open(output_sp_dir + \"/bangla_llama.model\", \"wb\") as f:\n",
        "    f.write(llama_spm.SerializeToString())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h01YI14BCeS-",
        "outputId": "caa46008-6a9e-4f04-e7f7-35ebde999a40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bangla-LLaMA tokenizer has been saved to /content/drive/MyDrive/Projects/bangla-llama/data/models/merged_tokenizer_sp\n"
          ]
        }
      ],
      "source": [
        "tokenizer = LlamaTokenizer(vocab_file=output_sp_dir + \"/bangla_llama.model\")\n",
        "\n",
        "tokenizer.save_pretrained(output_hf_dir)\n",
        "print(f\"Bangla-LLaMA tokenizer has been saved to {output_hf_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uznXC6oMC5w1",
        "outputId": "63f7ebec-fc11-44e4-8a12-9468b5393bf4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['<s>', '</s>', '<unk>']\n",
            "[1, 2, 0]\n",
            "{'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>'}\n"
          ]
        }
      ],
      "source": [
        "# Test\n",
        "llama_tokenizer = LlamaTokenizer.from_pretrained(llama_tokenizer_dir)\n",
        "bangla_llama_tokenizer = LlamaTokenizer.from_pretrained(output_hf_dir)\n",
        "print(tokenizer.all_special_tokens)\n",
        "print(tokenizer.all_special_ids)\n",
        "print(tokenizer.special_tokens_map)\n",
        "\n",
        "text = \"\"\"আমার জন্ম বাংলাদেশে\n",
        "I was born in Bangladesh\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPEaKnCNDUyh",
        "outputId": "9b06b512-0f46-4f5d-b207-284d92653a90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test text:\n",
            " আমার জন্ম বাংলাদেশে\n",
            "I was born in Bangladesh\n",
            "Tokenized by LLaMA tokenizer:['▁', '<0xE0>', '<0xA6>', '<0x86>', 'ম', 'া', 'র', '▁', 'জ', 'ন', '্', 'ম', '▁', 'ব', 'া', '<0xE0>', '<0xA6>', '<0x82>', 'ল', 'া', 'দ', 'ে', 'শ', 'ে', '<0x0A>', 'I', '▁was', '▁born', '▁in', '▁Bang', 'l', 'adesh']\n",
            "LLaMA tokenizer n_tokens=32\n",
            "Tokenized by Tamil-LLaMA tokenizer:['▁আমার', '▁জন্ম', '▁বা', 'ং', 'লা', 'দেশ', 'ে', '<0x0A>', 'I', '▁was', '▁born', '▁in', '▁Bang', 'l', 'adesh']\n",
            "Bangla LLaMA tokenizer n_tokens=15\n"
          ]
        }
      ],
      "source": [
        "print(\"Test text:\\n\", text)\n",
        "llama_tokenized = llama_tokenizer.tokenize(text)\n",
        "bangla_llama_tokenized = bangla_llama_tokenizer.tokenize(text)\n",
        "print(f\"Tokenized by LLaMA tokenizer:{llama_tokenized}\")\n",
        "print(f\"LLaMA tokenizer n_tokens={len(llama_tokenized)}\")\n",
        "print(f\"Tokenized by Tamil-LLaMA tokenizer:{bangla_llama_tokenized}\")\n",
        "print(f\"Bangla LLaMA tokenizer n_tokens={len(bangla_llama_tokenized)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C15i5RNc8Cci"
      },
      "source": [
        "# **Pretraining**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHQGPgg4cY_k",
        "outputId": "19b53d52-b208-4139-ed86-823fec2575df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:jax._src.xla_bridge:CUDA backend failed to initialize: Found CUDA version 12010, but JAX was built against version 12020, which is newer. The copy of CUDA that is installed must be at least as new as the version against which JAX was built. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ]
        }
      ],
      "source": [
        "import logging\n",
        "import math\n",
        "import os\n",
        "import sys\n",
        "from dataclasses import dataclass, field\n",
        "from itertools import chain\n",
        "from pathlib import Path\n",
        "from typing import Any, Dict, List, Mapping, Optional\n",
        "\n",
        "import datasets\n",
        "import numpy as np\n",
        "import torch\n",
        "import transformers\n",
        "from datasets import concatenate_datasets, load_dataset\n",
        "from peft import (\n",
        "    LoraConfig,\n",
        "    PeftModel,\n",
        "    PeftModelForCausalLM,\n",
        "    TaskType,\n",
        "    get_peft_model,\n",
        "    get_peft_model_state_dict,\n",
        ")\n",
        "from peft.tuners.lora import LoraLayer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from transformers import (\n",
        "    CONFIG_MAPPING,\n",
        "    MODEL_FOR_CAUSAL_LM_MAPPING,\n",
        "    AutoConfig,\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    HfArgumentParser,\n",
        "    LlamaForCausalLM,\n",
        "    LlamaTokenizer,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    is_torch_tpu_available,\n",
        "    set_seed,\n",
        ")\n",
        "from transformers.testing_utils import CaptureLogger\n",
        "from transformers.trainer_utils import PREFIX_CHECKPOINT_DIR, get_last_checkpoint\n",
        "from transformers.utils import send_example_telemetry\n",
        "from transformers.utils.versions import require_version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZgzgASnchZi"
      },
      "outputs": [],
      "source": [
        "class SavePeftModelCallback(transformers.TrainerCallback):\n",
        "    def save_model(self, args, state, kwargs):\n",
        "        if state.best_model_checkpoint is not None:\n",
        "            checkpoint_folder = os.path.join(\n",
        "                state.best_model_checkpoint, \"pt_lora_model\"\n",
        "            )\n",
        "        else:\n",
        "            checkpoint_folder = os.path.join(\n",
        "                args.output_dir, f\"{PREFIX_CHECKPOINT_DIR}-{state.global_step}\"\n",
        "            )\n",
        "\n",
        "        peft_model_path = os.path.join(checkpoint_folder, \"pt_lora_model\")\n",
        "        kwargs[\"model\"].save_pretrained(peft_model_path)\n",
        "        kwargs[\"tokenizer\"].save_pretrained(peft_model_path)\n",
        "\n",
        "    def on_save(self, args, state, control, **kwargs):\n",
        "        self.save_model(args, state, kwargs)\n",
        "        return control\n",
        "\n",
        "    def on_train_end(self, args, state, control, **kwargs):\n",
        "        peft_model_path = os.path.join(args.output_dir, \"pt_lora_model\")\n",
        "        kwargs[\"model\"].save_pretrained(peft_model_path)\n",
        "        kwargs[\"tokenizer\"].save_pretrained(peft_model_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMZ6ai4lcl-d"
      },
      "outputs": [],
      "source": [
        "def prepare_model_for_kbit_training(model, use_gradient_checkpointing=True):\n",
        "    r\"\"\"\n",
        "    This method wraps the entire protocol for preparing a model before running a training. This includes:\n",
        "        1- Cast the layernorm in fp32 2- making output embedding layer require grads 3- Add the upcasting of the lm\n",
        "        head to fp32\n",
        "\n",
        "    Args:\n",
        "        model, (`transformers.PreTrainedModel`):\n",
        "            The loaded model from `transformers`\n",
        "    \"\"\"\n",
        "    loaded_in_kbit = getattr(model, \"is_loaded_in_8bit\", False) or getattr(\n",
        "        model, \"is_loaded_in_4bit\", False\n",
        "    )\n",
        "\n",
        "    for name, param in model.named_parameters():\n",
        "        # freeze base model's layers\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # cast all non INT8/INT4 parameters to fp32\n",
        "    for param in model.parameters():\n",
        "        if (\n",
        "            (param.dtype == torch.float16) or (param.dtype == torch.bfloat16)\n",
        "        ) and loaded_in_kbit:\n",
        "            param.data = param.data.to(torch.float32)\n",
        "\n",
        "    # Cast the layernorm in fp32\n",
        "    for name, module in model.named_modules():\n",
        "        if \"norm\" in name:\n",
        "            module = module.to(torch.float32)\n",
        "\n",
        "    if loaded_in_kbit and use_gradient_checkpointing:\n",
        "        # For backward compatibility\n",
        "        if hasattr(model, \"enable_input_require_grads\"):\n",
        "            model.enable_input_require_grads()\n",
        "        else:\n",
        "\n",
        "            def make_inputs_require_grad(module, _input, output):\n",
        "                output.requires_grad_(True)\n",
        "\n",
        "            model.get_input_embeddings().register_forward_hook(make_inputs_require_grad)\n",
        "        # enable gradient checkpointing for memory efficiency\n",
        "        model.gradient_checkpointing_enable()\n",
        "\n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ke1S-mGcveA"
      },
      "outputs": [],
      "source": [
        "def accuracy(predictions, references, normalize=True, sample_weight=None):\n",
        "    return {\n",
        "        \"accuracy\": float(\n",
        "            accuracy_score(\n",
        "                references,\n",
        "                predictions,\n",
        "                normalize=normalize,\n",
        "                sample_weight=sample_weight,\n",
        "            )\n",
        "        )\n",
        "    }\n",
        "\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "    # preds have the same shape as the labels, after the argmax(-1) has been calculated\n",
        "    # by preprocess_logits_for_metrics but we need to shift the labels\n",
        "    labels = labels[:, 1:].reshape(-1)\n",
        "    preds = preds[:, :-1].reshape(-1)\n",
        "    return accuracy(predictions=preds, references=labels)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PUMarGlfczSe"
      },
      "outputs": [],
      "source": [
        "def preprocess_logits_for_metrics(logits, labels):\n",
        "    if isinstance(logits, tuple):\n",
        "        # Depending on the model and config, logits may contain extra tensors,\n",
        "        # like past_key_values, but logits always come first\n",
        "        logits = logits[0]\n",
        "    return logits.argmax(dim=-1)\n",
        "\n",
        "\n",
        "def fault_tolerance_data_collator(features: List) -> Dict[str, Any]:\n",
        "    if not isinstance(features[0], Mapping):\n",
        "        features = [vars(f) for f in features]\n",
        "    first = features[0]\n",
        "    batch = {}\n",
        "\n",
        "    # Special handling for labels.\n",
        "    # Ensure that tensor is created with the correct type\n",
        "    # (it should be automatically the case, but let's make sure of it.)\n",
        "    if \"label\" in first and first[\"label\"] is not None:\n",
        "        label = (\n",
        "            first[\"label\"].item()\n",
        "            if isinstance(first[\"label\"], torch.Tensor)\n",
        "            else first[\"label\"]\n",
        "        )\n",
        "        dtype = torch.long if isinstance(label, int) else torch.float\n",
        "        batch[\"labels\"] = torch.tensor([f[\"label\"] for f in features], dtype=dtype)\n",
        "    elif \"label_ids\" in first and first[\"label_ids\"] is not None:\n",
        "        if isinstance(first[\"label_ids\"], torch.Tensor):\n",
        "            batch[\"labels\"] = torch.stack([f[\"label_ids\"] for f in features])\n",
        "        else:\n",
        "            dtype = (\n",
        "                torch.long if isinstance(first[\"label_ids\"][0], int) else torch.float\n",
        "            )\n",
        "            batch[\"labels\"] = torch.tensor(\n",
        "                [f[\"label_ids\"] for f in features], dtype=dtype\n",
        "            )\n",
        "\n",
        "    # Handling of all other possible keys.\n",
        "    # Again, we will use the first element to figure out which key/values are not None for this model.\n",
        "\n",
        "    try:\n",
        "        for k, v in first.items():\n",
        "            if (\n",
        "                k not in (\"label\", \"label_ids\")\n",
        "                and v is not None\n",
        "                and not isinstance(v, str)\n",
        "            ):\n",
        "                if isinstance(v, torch.Tensor):\n",
        "                    batch[k] = torch.stack([f[k] for f in features])\n",
        "                elif isinstance(v, np.ndarray):\n",
        "                    batch[k] = torch.tensor(np.stack([f[k] for f in features]))\n",
        "                else:\n",
        "                    batch[k] = torch.tensor([f[k] for f in features])\n",
        "    except ValueError:  # quick fix by simply take the first example\n",
        "        for k, v in first.items():\n",
        "            if (\n",
        "                k not in (\"label\", \"label_ids\")\n",
        "                and v is not None\n",
        "                and not isinstance(v, str)\n",
        "            ):\n",
        "                if isinstance(v, torch.Tensor):\n",
        "                    batch[k] = torch.stack([features[0][k]] * len(features))\n",
        "                elif isinstance(v, np.ndarray):\n",
        "                    batch[k] = torch.tensor(np.stack([features[0][k]] * len(features)))\n",
        "                else:\n",
        "                    batch[k] = torch.tensor([features[0][k]] * len(features))\n",
        "\n",
        "    return batch\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKEn3W_wc82T"
      },
      "outputs": [],
      "source": [
        "MODEL_CONFIG_CLASSES = list(MODEL_FOR_CAUSAL_LM_MAPPING.keys())\n",
        "MODEL_TYPES = tuple(conf.model_type for conf in MODEL_CONFIG_CLASSES)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIELaWINc-0f"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class ModelArguments:\n",
        "    \"\"\"\n",
        "    Arguments pertaining to which model/config/tokenizer we are going to fine-tune, or train from scratch.\n",
        "    \"\"\"\n",
        "\n",
        "    model_name_or_path: Optional[str] = field(\n",
        "        default=None,\n",
        "        metadata={\n",
        "            \"help\": (\n",
        "                \"The model checkpoint for weights initialization.Don't set if you want to train a model from scratch.\"\n",
        "            )\n",
        "        },\n",
        "    )\n",
        "    tokenizer_name_or_path: Optional[str] = field(\n",
        "        default=None,\n",
        "        metadata={\n",
        "            \"help\": (\n",
        "                \"The tokenizer for weights initialization.Don't set if you want to train a model from scratch.\"\n",
        "            )\n",
        "        },\n",
        "    )\n",
        "    model_type: Optional[str] = field(\n",
        "        default=None,\n",
        "        metadata={\n",
        "            \"help\": \"If training from scratch, pass a model type from the list: \"\n",
        "            + \", \".join(MODEL_TYPES)\n",
        "        },\n",
        "    )\n",
        "    config_overrides: Optional[str] = field(\n",
        "        default=None,\n",
        "        metadata={\n",
        "            \"help\": (\n",
        "                \"Override some existing default config settings when a model is trained from scratch. Example: \"\n",
        "                \"n_embd=10,resid_pdrop=0.2,scale_attn_weights=false,summary_type=cls_index\"\n",
        "            )\n",
        "        },\n",
        "    )\n",
        "    config_name: Optional[str] = field(\n",
        "        default=None,\n",
        "        metadata={\n",
        "            \"help\": \"Pretrained config name or path if not the same as model_name\"\n",
        "        },\n",
        "    )\n",
        "    tokenizer_name: Optional[str] = field(\n",
        "        default=None,\n",
        "        metadata={\n",
        "            \"help\": \"Pretrained tokenizer name or path if not the same as model_name\"\n",
        "        },\n",
        "    )\n",
        "    cache_dir: Optional[str] = field(\n",
        "        default=None,\n",
        "        metadata={\n",
        "            \"help\": \"Where do you want to store the pretrained models downloaded from huggingface.co\"\n",
        "        },\n",
        "    )\n",
        "    use_fast_tokenizer: bool = field(\n",
        "        default=True,\n",
        "        metadata={\n",
        "            \"help\": \"Whether to use one of the fast tokenizer (backed by the tokenizers library) or not.\"\n",
        "        },\n",
        "    )\n",
        "    model_revision: str = field(\n",
        "        default=\"main\",\n",
        "        metadata={\n",
        "            \"help\": \"The specific model version to use (can be a branch name, tag name or commit id).\"\n",
        "        },\n",
        "    )\n",
        "    use_auth_token: bool = field(\n",
        "        default=False,\n",
        "        metadata={\n",
        "            \"help\": (\n",
        "                \"Will use the token generated when running `huggingface-cli login` (necessary to use this script \"\n",
        "                \"with private models).\"\n",
        "            )\n",
        "        },\n",
        "    )\n",
        "    torch_dtype: Optional[str] = field(\n",
        "        default=None,\n",
        "        metadata={\n",
        "            \"help\": (\n",
        "                \"Override the default `torch.dtype` and load the model under this dtype. If `auto` is passed, the \"\n",
        "                \"dtype will be automatically derived from the model's weights.\"\n",
        "            ),\n",
        "            \"choices\": [\"auto\", \"bfloat16\", \"float16\", \"float32\"],\n",
        "        },\n",
        "    )\n",
        "\n",
        "    def __post_init__(self):\n",
        "        if self.config_overrides is not None and (\n",
        "            self.config_name is not None or self.model_name_or_path is not None\n",
        "        ):\n",
        "            raise ValueError(\n",
        "                \"--config_overrides can't be used in combination with --config_name or --model_name_or_path\"\n",
        "            )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfmpsmgX_Q7-"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class DataTrainingArguments:\n",
        "    \"\"\"\n",
        "    Arguments pertaining to what data we are going to input our model for training and eval.\n",
        "    \"\"\"\n",
        "\n",
        "    dataset_dir: Optional[str] = field(\n",
        "        default=None,\n",
        "        metadata={\"help\": \"The name of the dataset to use (via the datasets library).\"},\n",
        "    )\n",
        "    dataset_config_name: Optional[str] = field(\n",
        "        default=None,\n",
        "        metadata={\n",
        "            \"help\": \"The configuration name of the dataset to use (via the datasets library).\"\n",
        "        },\n",
        "    )\n",
        "    train_file: Optional[str] = field(\n",
        "        default=None, metadata={\"help\": \"The input training data file (a text file).\"}\n",
        "    )\n",
        "    validation_file: Optional[str] = field(\n",
        "        default=None,\n",
        "        metadata={\n",
        "            \"help\": \"An optional input evaluation data file to evaluate the perplexity on (a text file).\"\n",
        "        },\n",
        "    )\n",
        "    max_train_samples: Optional[int] = field(\n",
        "        default=None,\n",
        "        metadata={\n",
        "            \"help\": (\n",
        "                \"For debugging purposes or quicker training, truncate the number of training examples to this \"\n",
        "                \"value if set.\"\n",
        "            )\n",
        "        },\n",
        "    )\n",
        "    max_eval_samples: Optional[int] = field(\n",
        "        default=None,\n",
        "        metadata={\n",
        "            \"help\": (\n",
        "                \"For debugging purposes or quicker training, truncate the number of evaluation examples to this \"\n",
        "                \"value if set.\"\n",
        "            )\n",
        "        },\n",
        "    )\n",
        "    streaming: bool = field(default=False, metadata={\"help\": \"Enable streaming mode\"})\n",
        "    block_size: Optional[int] = field(\n",
        "        default=None,\n",
        "        metadata={\n",
        "            \"help\": (\n",
        "                \"Optional input sequence length after tokenization. \"\n",
        "                \"The training dataset will be truncated in block of this size for training. \"\n",
        "                \"Default to the model max input length for single sentence inputs (take into account special tokens).\"\n",
        "            )\n",
        "        },\n",
        "    )\n",
        "    overwrite_cache: bool = field(\n",
        "        default=False,\n",
        "        metadata={\"help\": \"Overwrite the cached training and evaluation sets\"},\n",
        "    )\n",
        "    validation_split_percentage: Optional[float] = field(\n",
        "        default=0.05,\n",
        "        metadata={\n",
        "            \"help\": \"The percentage of the train set used as validation set in case there's no validation split\"\n",
        "        },\n",
        "    )\n",
        "    preprocessing_num_workers: Optional[int] = field(\n",
        "        default=None,\n",
        "        metadata={\"help\": \"The number of processes to use for the preprocessing.\"},\n",
        "    )\n",
        "    keep_linebreaks: bool = field(\n",
        "        default=True,\n",
        "        metadata={\"help\": \"Whether to keep line breaks when using TXT files or not.\"},\n",
        "    )\n",
        "    data_cache_dir: Optional[str] = field(\n",
        "        default=\"./\", metadata={\"help\": \"The datasets processed stored\"}\n",
        "    )\n",
        "\n",
        "    def __post_init__(self):\n",
        "        if self.streaming:\n",
        "            require_version(\n",
        "                \"datasets>=2.0.0\", \"The streaming feature requires `datasets>=2.0.0`\"\n",
        "            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g23SfIo2_TB0"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class MyTrainingArguments(TrainingArguments):\n",
        "    trainable: Optional[str] = field(default=\"q_proj,v_proj\")\n",
        "    lora_rank: Optional[int] = field(default=8)\n",
        "    lora_dropout: Optional[float] = field(default=0.1)\n",
        "    lora_alpha: Optional[float] = field(default=32.0)\n",
        "    modules_to_save: Optional[str] = field(default=None)\n",
        "    debug_mode: Optional[bool] = field(default=False)\n",
        "    peft_path: Optional[str] = field(default=None)\n",
        "    flash_attn: Optional[bool] = field(default=False)\n",
        "    double_quant: Optional[bool] = field(default=True)\n",
        "    quant_type: Optional[str] = field(default=\"nf4\")\n",
        "    load_in_kbits: Optional[int] = field(default=16)\n",
        "    use_mixed_precision: Optional[bool] = field(default=False)  # Add this line\n",
        "    per_device_train_batch_size: Optional[int] = field(default=8) # Default batch size\n",
        "    per_device_eval_batch_size: Optional[int] = field(default=8) # Default batch size\n",
        "    gradient_accumulation_steps: Optional[int] = field(default=8) # Default gradient accumulation steps\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61gt89vAoLdf"
      },
      "outputs": [],
      "source": [
        "logger = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6D0ZVICrQdy",
        "outputId": "aec4f86f-d4fe-460f-8367-f94bf4789fab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bn_part_00000.parquet  bn_part_00005.parquet  bn_part_00010.parquet  bn_part_00015.parquet\n",
            "bn_part_00001.parquet  bn_part_00006.parquet  bn_part_00011.parquet  bn_part_00016.parquet\n",
            "bn_part_00002.parquet  bn_part_00007.parquet  bn_part_00012.parquet  bn_part_00017.parquet\n",
            "bn_part_00003.parquet  bn_part_00008.parquet  bn_part_00013.parquet\n",
            "bn_part_00004.parquet  bn_part_00009.parquet  bn_part_00014.parquet\n"
          ]
        }
      ],
      "source": [
        "!ls /content/drive/MyDrive/Projects/bangla-llama/data/uonlp/culturaX/bn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuXeoIJIrTHE",
        "outputId": "94974364-d69c-45bd-ce48-8e0499eb464c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bangla_llama.model  special_tokens_map.json  tokenizer_config.json  tokenizer.model\n"
          ]
        }
      ],
      "source": [
        "!ls /content/drive/MyDrive/Projects/bangla-llama/data/models/merged_tokenizer_sp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBq3x7G-rYnN"
      },
      "outputs": [],
      "source": [
        "!ls /content/drive/MyDrive/Projects/bangla-llama/data/cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTVW5U4yrcy2",
        "outputId": "ae57c2f2-ef58-46d1-828d-31d8eb2f5f79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checkpoint-200\tcheckpoint-250\truns\n"
          ]
        }
      ],
      "source": [
        "!ls /content/drive/MyDrive/Projects/bangla-llama/data/output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/Projects/bangla-llama/data/output/runs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRIQpazRz6Tg",
        "outputId": "b10b22dc-e7ad-4c95-8d61-e3ac943d2f86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jan16_15-19-09_7baf5f2f4c38  Jan17_15-49-39_e89b3f711d70  Jan17_16-35-29_e89b3f711d70\n",
            "Jan16_15-43-37_7baf5f2f4c38  Jan17_15-53-06_e89b3f711d70  Jan17_16-39-01_e89b3f711d70\n",
            "Jan16_15-59-38_7baf5f2f4c38  Jan17_15-58-54_e89b3f711d70  Jan17_16-59-13_e89b3f711d70\n",
            "Jan16_16-05-59_7baf5f2f4c38  Jan17_16-00-54_e89b3f711d70  Jan17_18-56-32_e89b3f711d70\n",
            "Jan16_16-13-37_7baf5f2f4c38  Jan17_16-06-15_e89b3f711d70  Jan17_19-08-50_e89b3f711d70\n",
            "Jan17_15-30-49_e89b3f711d70  Jan17_16-07-08_e89b3f711d70  Jan17_19-10-35_e89b3f711d70\n",
            "Jan17_15-35-53_e89b3f711d70  Jan17_16-12-36_e89b3f711d70  Jan17_19-12-15_e89b3f711d70\n",
            "Jan17_15-39-11_e89b3f711d70  Jan17_16-16-40_e89b3f711d70  Jan17_19-14-36_e89b3f711d70\n",
            "Jan17_15-43-16_e89b3f711d70  Jan17_16-18-52_e89b3f711d70  Jan17_23-08-20_1a1489702d40\n",
            "Jan17_15-44-16_e89b3f711d70  Jan17_16-23-05_e89b3f711d70  Jan19_20-02-36_362ca61ba938\n",
            "Jan17_15-46-58_e89b3f711d70  Jan17_16-26-03_e89b3f711d70\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdo0QG_7sgMq"
      },
      "outputs": [],
      "source": [
        "# Below code is based on https://github.com/lm-sys/FastChat/blob/main/fastchat/train/llama_flash_attn_monkey_patch.py.\n",
        "from typing import Optional, Tuple\n",
        "import torch\n",
        "\n",
        "import transformers\n",
        "from transformers.models.llama.modeling_llama import apply_rotary_pos_emb\n",
        "\n",
        "from einops import rearrange\n",
        "try:\n",
        "    from flash_attn.flash_attn_interface import flash_attn_varlen_qkvpacked_func\n",
        "    from flash_attn.bert_padding import unpad_input, pad_input\n",
        "except ImportError:\n",
        "    raise ImportError(\n",
        "        \"FlashAttention-2 is not installed correctly. Please check the usage in https://github.com/Dao-AILab/flash-attention for more details.\"\n",
        "    )\n",
        "\n",
        "def forward(\n",
        "    self,\n",
        "    hidden_states: torch.Tensor,\n",
        "    attention_mask: Optional[torch.Tensor] = None,\n",
        "    position_ids: Optional[torch.Tensor] = None,\n",
        "    past_key_value: Optional[Tuple[torch.Tensor]] = None,\n",
        "    output_attentions: bool = False,\n",
        "    use_cache: bool = False,\n",
        ") -> Tuple[torch.Tensor, Optional[torch.Tensor], Optional[Tuple[torch.Tensor]]]:\n",
        "    \"\"\"Input shape: Batch x Time x Channel\n",
        "\n",
        "    attention_mask: [bsz, q_len]\n",
        "    \"\"\"\n",
        "    bsz, q_len, _ = hidden_states.size()\n",
        "\n",
        "    query_states = (\n",
        "        self.q_proj(hidden_states)\n",
        "        .view(bsz, q_len, self.num_heads, self.head_dim)\n",
        "        .transpose(1, 2)\n",
        "    )\n",
        "    key_states = (\n",
        "        self.k_proj(hidden_states)\n",
        "        .view(bsz, q_len, self.num_heads, self.head_dim)\n",
        "        .transpose(1, 2)\n",
        "    )\n",
        "    value_states = (\n",
        "        self.v_proj(hidden_states)\n",
        "        .view(bsz, q_len, self.num_heads, self.head_dim)\n",
        "        .transpose(1, 2)\n",
        "    )\n",
        "    # [bsz, q_len, nh, hd]\n",
        "    # [bsz, nh, q_len, hd]\n",
        "\n",
        "    kv_seq_len = key_states.shape[-2]\n",
        "    assert past_key_value is None, \"past_key_value is not supported\"\n",
        "\n",
        "    cos, sin = self.rotary_emb(value_states, seq_len=kv_seq_len)\n",
        "    query_states, key_states = apply_rotary_pos_emb(\n",
        "        query_states, key_states, cos, sin, position_ids\n",
        "    )\n",
        "    # [bsz, nh, t, hd]\n",
        "    assert not output_attentions, \"output_attentions is not supported\"\n",
        "    assert not use_cache, \"use_cache is not supported\"\n",
        "\n",
        "    # Flash attention codes from\n",
        "    # https://github.com/HazyResearch/flash-attention/blob/main/flash_attn/flash_attention.py\n",
        "\n",
        "    # transform the data into the format required by flash attention\n",
        "    qkv = torch.stack(\n",
        "        [query_states, key_states, value_states], dim=2\n",
        "    )  # [bsz, nh, 3, q_len, hd]\n",
        "    qkv = qkv.transpose(1, 3)  # [bsz, q_len, 3, nh, hd]\n",
        "    # We have disabled _prepare_decoder_attention_mask in LlamaModel\n",
        "    # the attention_mask should be the same as the key_padding_mask\n",
        "    key_padding_mask = attention_mask\n",
        "\n",
        "    if key_padding_mask is None:\n",
        "        qkv = rearrange(qkv, \"b s ... -> (b s) ...\")\n",
        "        max_s = q_len\n",
        "        cu_q_lens = torch.arange(\n",
        "            0, (bsz + 1) * q_len, step=q_len, dtype=torch.int32, device=qkv.device\n",
        "        )\n",
        "        output = flash_attn_varlen_qkvpacked_func(\n",
        "            qkv, cu_q_lens, max_s, 0.0, softmax_scale=None, causal=True\n",
        "        )\n",
        "        output = rearrange(output, \"(b s) ... -> b s ...\", b=bsz)\n",
        "    else:\n",
        "        nheads = qkv.shape[-2]\n",
        "        x = rearrange(qkv, \"b s three h d -> b s (three h d)\")\n",
        "        x_unpad, indices, cu_q_lens, max_s = unpad_input(x, key_padding_mask)\n",
        "        x_unpad = rearrange(\n",
        "            x_unpad, \"nnz (three h d) -> nnz three h d\", three=3, h=nheads\n",
        "        )\n",
        "        output_unpad = flash_attn_varlen_qkvpacked_func(\n",
        "            x_unpad, cu_q_lens, max_s, 0.0, softmax_scale=None, causal=True\n",
        "        )\n",
        "        output = rearrange(\n",
        "            pad_input(\n",
        "                rearrange(output_unpad, \"nnz h d -> nnz (h d)\"), indices, bsz, q_len\n",
        "            ),\n",
        "            \"b s (h d) -> b s h d\",\n",
        "            h=nheads,\n",
        "        )\n",
        "    return self.o_proj(rearrange(output, \"b s h d -> b s (h d)\")), None, None\n",
        "\n",
        "\n",
        "# Disable the transformation of the attention mask in LlamaModel as the flash attention\n",
        "# requires the attention mask to be the same as the key_padding_mask\n",
        "def _prepare_decoder_attention_mask(\n",
        "    self, attention_mask, input_shape, inputs_embeds, past_key_values_length\n",
        "):\n",
        "    # [bsz, seq_len]\n",
        "    return attention_mask\n",
        "\n",
        "\n",
        "def replace_llama_attn_with_flash_attn():\n",
        "    transformers.models.llama.modeling_llama.LlamaModel._prepare_decoder_attention_mask = (\n",
        "        _prepare_decoder_attention_mask\n",
        "    )\n",
        "    transformers.models.llama.modeling_llama.LlamaAttention.forward = forward"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/Projects/bangla-llama/data/output/checkpoint-11000/pt_lora_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugqa0dnKiajx",
        "outputId": "3c8dfed9-ac5b-4c04-edaf-b6903e11c57e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "adapter_config.json  pt_lora_model  scheduler.pt\t     tokenizer.model\n",
            "adapter_model.bin    README.md\t    special_tokens_map.json  trainer_state.json\n",
            "optimizer.pt\t     rng_state.pth  tokenizer_config.json    training_args.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sxlwyoURMv6"
      },
      "source": [
        "# Training Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1hAWAvMqWzZ"
      },
      "outputs": [],
      "source": [
        "parser = HfArgumentParser(\n",
        "        (ModelArguments, DataTrainingArguments, MyTrainingArguments)\n",
        "    )\n",
        "if len(sys.argv) == 2 and sys.argv[1].endswith(\".json\"):\n",
        "    # If we pass only one argument to the script and it's the path to a json file,\n",
        "    # let's parse it to get our arguments.\n",
        "    model_args, data_args, training_args = parser.parse_json_file(\n",
        "        json_file=os.path.abspath(sys.argv[1])\n",
        "    )\n",
        "else:\n",
        "    random_seed = 1357\n",
        "    cmd_line_args = [\n",
        "      #\"--model_name_or_path\", \"unsloth/llama-2-7b\", #\"TinyPixel/Llama-2-7B-bf16-sharded\",\n",
        "      \"--model_name_or_path\", \"brishtiteveja/bangla-llama-7b-base-v0.1\",\n",
        "      #\"--model_name_or_path\", \"/content/drive/MyDrive/Projects/bangla-llama/data/output/checkpoint-11000/pt_lora_model\",\n",
        "\n",
        "      #\"--tokenizer_name\", \"unsloth/llama-2-7b\",\n",
        "      \"--tokenizer_name_or_path\", \"brishtiteveja/bangla-llama-7b-base-v0.1\",\n",
        "      #\"--tokenizer_name_or_path\", \"/content/drive/MyDrive/Projects/bangla-llama/data/models/merged_tokenizer_sp\",\n",
        "      #\"--tokenizer_name_or_path\", \"/content/drive/MyDrive/Projects/bangla-llama/data/output/checkpoint-11000/pt_lora_model\",\n",
        "\n",
        "\n",
        "      \"--dataset_dir\", \"/content/drive/MyDrive/Projects/bangla-llama/data/uonlp/culturaX/bn\",\n",
        "      \"--data_cache_dir\", \"/content/drive/MyDrive/Projects/bangla-llama/data\",\n",
        "      \"--validation_split_percentage\", \"0.1\",\n",
        "      \"--per_device_train_batch_size\", \"8\",\n",
        "      \"--do_train\",\n",
        "      #\"--seed\", str(random_seed),\n",
        "      #\"--fp16\",\n",
        "      \"--bf16\",\n",
        "      \"--num_train_epochs\", \"1\",\n",
        "      \"--lr_scheduler_type\", \"cosine\",\n",
        "      \"--learning_rate\", \"1e-4\",\n",
        "      \"--warmup_ratio\", \"0.05\",\n",
        "      \"--weight_decay\", \"0.01\",\n",
        "      \"--logging_strategy\", \"steps\",\n",
        "      \"--logging_steps\", \"5\",\n",
        "      \"--save_strategy\", \"steps\",\n",
        "      \"--save_total_limit\", \"1\",\n",
        "      \"--save_steps\", \"1000\",\n",
        "      \"--gradient_accumulation_steps\", \"4\",\n",
        "      \"--preprocessing_num_workers\", \"8\",\n",
        "      \"--block_size\", \"512\",\n",
        "      \"--output_dir\", \"/content/drive/MyDrive/Projects/bangla-llama/data/output\",\n",
        "      #\"--overwrite_output_dir\",\n",
        "      \"--ddp_timeout\", \"30000\",\n",
        "      \"--logging_first_step\", \"True\",\n",
        "      \"--lora_rank\", \"64\",\n",
        "      \"--double_quant\", \"True\",\n",
        "      \"--lora_alpha\", \"128.0\",\n",
        "      \"--trainable\", \"q_proj,v_proj,k_proj,o_proj,gate_proj,down_proj,up_proj\",\n",
        "      \"--lora_dropout\", \"0.1\",\n",
        "      \"--modules_to_save\", \"embed_tokens,lm_head\",\n",
        "      #\"--torch_dtype\", \"float16\",\n",
        "      \"--gradient_checkpointing\",\n",
        "      \"--ddp_find_unused_parameters\", \"False\",\n",
        "      #\"--flash_attn\", \"True\"\n",
        "\n",
        "      #\"--quant_type\", \"nf4\",\n",
        "      #\"--load_in_kbits\", \"16\",\n",
        "    # Add other command line arguments as needed\n",
        "  ]\n",
        "\n",
        "model_args, data_args, training_args = parser.parse_args_into_dataclasses(cmd_line_args)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/drive/MyDrive/Projects/bangla-llama/data/results"
      ],
      "metadata": {
        "id": "t1JcvVXdi7Gm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZnC9wSAnqfch"
      },
      "outputs": [],
      "source": [
        "if training_args.flash_attn:\n",
        "    #from flash_attn_patch import replace_llama_attn_with_flash_attn\n",
        "\n",
        "    replace_llama_attn_with_flash_attn()\n",
        "\n",
        "# Sending telemetry. Tracking the example usage helps us better allocate resources to maintain them. The\n",
        "# information sent is the one passed as arguments along with your Python/PyTorch versions.\n",
        "send_example_telemetry(\"run_clm\", model_args, data_args)\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(\n",
        "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
        "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
        "    level=logging.INFO,  # if training_args.local_rank in [-1, 0] else logging.WARN,\n",
        "    handlers=[logging.StreamHandler(sys.stdout)],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7daiCWRmqv4H",
        "outputId": "6a2d1ed6-6174-43c0-996a-a862b318dc8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False\n"
          ]
        }
      ],
      "source": [
        "# Sending telemetry. Tracking the example usage helps us better allocate resources to maintain them. The\n",
        "# information sent is the one passed as arguments along with your Python/PyTorch versions.\n",
        "send_example_telemetry(\"run_clm\", model_args, data_args)\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(\n",
        "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
        "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
        "    level=logging.INFO,  # if training_args.local_rank in [-1, 0] else logging.WARN,\n",
        "    handlers=[logging.StreamHandler(sys.stdout)],\n",
        ")\n",
        "\n",
        "if training_args.should_log:\n",
        "    # The default of training_args.log_level is passive, so we set log level at info here to have that default.\n",
        "    transformers.utils.logging.set_verbosity_info()\n",
        "\n",
        "log_level = training_args.get_process_log_level()\n",
        "logger.setLevel(log_level)\n",
        "datasets.utils.logging.set_verbosity(log_level)\n",
        "transformers.utils.logging.set_verbosity(log_level)\n",
        "transformers.utils.logging.enable_default_handler()\n",
        "transformers.utils.logging.enable_explicit_format()\n",
        "# transformers.tokenization_utils.logging.set_verbosity_warning()\n",
        "\n",
        "if training_args.flash_attn:\n",
        "    logger.info(\"Using Flash Attention!\")\n",
        "\n",
        "# Log on each process the small summary:\n",
        "logger.warning(\n",
        "    f\"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu}\"\n",
        "    + f\"distributed training: {bool(training_args.local_rank != -1)}, 16-bits training: {training_args.fp16}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "last_checkpoint = get_last_checkpoint(training_args.output_dir)\n",
        "print(last_checkpoint)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAl7nMa-qk0b",
        "outputId": "96b98548-6289-49ed-a1ea-65a8ed2d3f2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Projects/bangla-llama/data/output/checkpoint-11000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls -R /content/drive/MyDrive/Projects/bangla-llama/data/output/checkpoint-11000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9At-tlnlzVGU",
        "outputId": "dc723cbf-e89c-426a-cd12-52acc8c4c488"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Projects/bangla-llama/data/output/checkpoint-11000:\n",
            "adapter_config.json  \u001b[0m\u001b[01;34mpt_lora_model\u001b[0m/  special_tokens_map.json  training_args.bin\n",
            "adapter_model.bin    README.md       tokenizer_config.json\n",
            "config.json          rng_state.pth   tokenizer.model\n",
            "optimizer.pt         scheduler.pt    trainer_state.json\n",
            "\n",
            "/content/drive/MyDrive/Projects/bangla-llama/data/output/checkpoint-11000/pt_lora_model:\n",
            "adapter_config.json        config.json  special_tokens_map.json  tokenizer.model\n",
            "adapter_model.safetensors  README.md    tokenizer_config.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!du -h /content/drive/MyDrive/Projects/bangla-llama/data/output/checkpoint-11000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWVJWVQazf4K",
        "outputId": "0c0700fc-1128-4ca5-8610-2fcded3e0067"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "926K\t/content/drive/MyDrive/Projects/bangla-llama/data/output/checkpoint-11000/pt_lora_model\n",
            "2.2G\t/content/drive/MyDrive/Projects/bangla-llama/data/output/checkpoint-11000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -R /content/drive/MyDrive/Projects/bangla-llama/data/output/checkpoint-11000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKGCVKl0zA8e",
        "outputId": "f3a2442e-aa5b-42b5-8684-2c80bf22df31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Projects/bangla-llama/data/output/checkpoint-11000:\n",
            "adapter_config.json  pt_lora_model  special_tokens_map.json  training_args.bin\n",
            "adapter_model.bin    README.md\t    tokenizer_config.json\n",
            "config.json\t     rng_state.pth  tokenizer.model\n",
            "optimizer.pt\t     scheduler.pt   trainer_state.json\n",
            "\n",
            "/content/drive/MyDrive/Projects/bangla-llama/data/output/checkpoint-11000/pt_lora_model:\n",
            "adapter_config.json\t   config.json\t      README.md\t\t       tokenizer_config.json\n",
            "adapter_model.safetensors  pytorch_model.bin  special_tokens_map.json  tokenizer.model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%cp -r /content/drive/MyDrive/Projects/bangla-llama/data/output/checkpoint-11000 /content/drive/MyDrive/Projects/bangla-llama/data/output/checkpoint-11000-backup"
      ],
      "metadata": {
        "id": "BVQtI9s8sEDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wL9E1JKNrGjz",
        "outputId": "d35adb4b-aedc-44c2-c746-a2a1a16df4ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False\n",
            "INFO:__main__:Checkpoint detected, resuming training at /content/drive/MyDrive/Projects/bangla-llama/data/output/checkpoint-11000. To avoid this behavior, change the `--output_dir` or add `--overwrite_output_dir` to train from scratch.\n"
          ]
        }
      ],
      "source": [
        "# Log on each process the small summary:\n",
        "logger.warning(\n",
        "    f\"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu}\"\n",
        "    + f\"distributed training: {bool(training_args.local_rank != -1)}, 16-bits training: {training_args.fp16}\"\n",
        ")\n",
        "\n",
        "# Detecting last checkpoint.\n",
        "last_checkpoint = None\n",
        "if (\n",
        "    os.path.isdir(training_args.output_dir)\n",
        "    and training_args.do_train\n",
        "    and not training_args.overwrite_output_dir\n",
        "):\n",
        "    last_checkpoint = get_last_checkpoint(training_args.output_dir)\n",
        "    if last_checkpoint is None and len(os.listdir(training_args.output_dir)) > 0:\n",
        "        raise ValueError(\n",
        "            f\"Output directory ({training_args.output_dir}) already exists and is not empty. \"\n",
        "            \"Use --overwrite_output_dir to overcome.\"\n",
        "        )\n",
        "    elif (\n",
        "        last_checkpoint is not None and training_args.resume_from_checkpoint is None\n",
        "    ):\n",
        "        logger.info(\n",
        "            f\"Checkpoint detected, resuming training at {last_checkpoint}. To avoid this behavior, change \"\n",
        "            \"the `--output_dir` or add `--overwrite_output_dir` to train from scratch.\"\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenizer"
      ],
      "metadata": {
        "id": "3vJiqcb_j4T8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_args.model_name_or_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xrDOgElplMMA",
        "outputId": "d41d9d15-40a0-47af-ef6d-40b22baa6695"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'brishtiteveja/bangla-llama-7b-base-v0.1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.vocab_size)"
      ],
      "metadata": {
        "id": "oF2n5vTJvJvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/Projects/bangla-llama/data/output/checkpoint-11000/pt_lora_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKl2_BDLlRFy",
        "outputId": "72c8ea41-9162-4b53-9d3c-5075a94bb57b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "adapter_config.json\t   config.json\t      README.md\t\t       tokenizer_config.json\n",
            "adapter_model.safetensors  pytorch_model.bin  special_tokens_map.json  tokenizer.model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_args.tokenizer_name_or_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "bp_hpWSKleUk",
        "outputId": "d250213e-78ad-4be6-8591-70dbd3b6d402"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Projects/bangla-llama/data/output/checkpoint-11000/pt_lora_model'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "        'unsloth/llama-2-7b'\n",
        "        #'brishtiteveja/bangla-llama-7b-base-v0.1'\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQAcYMdAmwBg",
        "outputId": "40ade324-67ca-4679-f91e-9e6079222a5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[INFO|tokenization_utils_base.py:1839] 2024-01-22 05:20:10,629 >> loading file tokenizer.model from cache at /root/.cache/huggingface/hub/models--unsloth--llama-2-7b/snapshots/06c7083cec3b7f2985dba884752da880cce5f983/tokenizer.model\n",
            "[INFO|tokenization_utils_base.py:1839] 2024-01-22 05:20:10,630 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--unsloth--llama-2-7b/snapshots/06c7083cec3b7f2985dba884752da880cce5f983/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:1839] 2024-01-22 05:20:10,632 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1839] 2024-01-22 05:20:10,632 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--unsloth--llama-2-7b/snapshots/06c7083cec3b7f2985dba884752da880cce5f983/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:1839] 2024-01-22 05:20:10,633 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--unsloth--llama-2-7b/snapshots/06c7083cec3b7f2985dba884752da880cce5f983/tokenizer_config.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "diO7vWA5m8EZ",
        "outputId": "f19a9ca9-9091-48dd-aa65-a90739c8bd4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LlamaTokenizer(name_or_path='brishtiteveja/bangla-llama-7b-base-v0.1', vocab_size=50437, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'eos_token': AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True)}, clean_up_tokenization_spaces=False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 801,
          "referenced_widgets": [
            "0c52cf5c719745b8890b83315a50b949",
            "8cc7fbd222ed4581ab7b22b578c46bb2",
            "2db38b2d20ea4f67883a97c6d729ae4d",
            "fe4460a7e35942fa8ea2c72ad3da8fb2",
            "d4f674ac94c04516b6359066ccb009b0",
            "f7eedb206eed4c76836cd5057d81cc0c",
            "f2afec77840b4958bdb17651190c5aac",
            "e10d7e62f820455198f1c5ec0cf155b9",
            "46bfdb92bd9b42c79316f476d0876c31",
            "1cf4c6587d4c421dacb75fdf5ab0a8ee",
            "eef594bc4e684e86911664bcbde0d81f"
          ]
        },
        "id": "FrwieFtdrYb8",
        "outputId": "5232ba21-0c5a-4ed1-ceb7-56baeb73011d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/673 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0c52cf5c719745b8890b83315a50b949"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[INFO|configuration_utils.py:712] 2024-01-22 05:54:43,854 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--brishtiteveja--bangla-llama-7b-base-v0.1/snapshots/b813d720142b5858fdfa3d4da89cbe8ecc867ed4/config.json\n",
            "[INFO|configuration_utils.py:768] 2024-01-22 05:54:43,856 >> Model config LlamaConfig {\n",
            "  \"_name_or_path\": \"brishtiteveja/bangla-llama-7b-base-v0.1\",\n",
            "  \"architectures\": [\n",
            "    \"LlamaForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 11008,\n",
            "  \"max_position_embeddings\": 4096,\n",
            "  \"model_type\": \"llama\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.31.0\",\n",
            "  \"use_cache\": false,\n",
            "  \"vocab_size\": 50437\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:1839] 2024-01-22 05:54:44,124 >> loading file tokenizer.model from cache at /root/.cache/huggingface/hub/models--brishtiteveja--bangla-llama-7b-base-v0.1/snapshots/b813d720142b5858fdfa3d4da89cbe8ecc867ed4/tokenizer.model\n",
            "[INFO|tokenization_utils_base.py:1839] 2024-01-22 05:54:44,125 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1839] 2024-01-22 05:54:44,126 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--brishtiteveja--bangla-llama-7b-base-v0.1/snapshots/b813d720142b5858fdfa3d4da89cbe8ecc867ed4/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:1839] 2024-01-22 05:54:44,126 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--brishtiteveja--bangla-llama-7b-base-v0.1/snapshots/b813d720142b5858fdfa3d4da89cbe8ecc867ed4/tokenizer_config.json\n",
            "[WARNING|logging.py:295] 2024-01-22 05:54:44,129 >> You are using the legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565\n"
          ]
        }
      ],
      "source": [
        "# Set seed before initializing model.\n",
        "set_seed(training_args.seed)\n",
        "\n",
        "config_kwargs = {\n",
        "    \"cache_dir\": model_args.cache_dir,\n",
        "    \"revision\": model_args.model_revision,\n",
        "    \"use_auth_token\": True if model_args.use_auth_token else None,\n",
        "}\n",
        "if model_args.config_name:\n",
        "    config = AutoConfig.from_pretrained(model_args.config_name, **config_kwargs)\n",
        "elif model_args.model_name_or_path:\n",
        "    config = AutoConfig.from_pretrained(\n",
        "        model_args.model_name_or_path, **config_kwargs\n",
        "    )\n",
        "else:\n",
        "    config = CONFIG_MAPPING[model_args.model_type]()\n",
        "    logger.warning(\"You are instantiating a new config instance from scratch.\")\n",
        "    if model_args.config_overrides is not None:\n",
        "        logger.info(f\"Overriding config: {model_args.config_overrides}\")\n",
        "        config.update_from_string(model_args.config_overrides)\n",
        "        logger.info(f\"New config: {config}\")\n",
        "\n",
        "tokenizer_kwargs = {\n",
        "    \"cache_dir\": model_args.cache_dir,\n",
        "    \"use_fast\": model_args.use_fast_tokenizer,\n",
        "    \"revision\": model_args.model_revision,\n",
        "    \"use_auth_token\": True if model_args.use_auth_token else None,\n",
        "}\n",
        "\n",
        "if model_args.tokenizer_name:\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\n",
        "        model_args.tokenizer_name, **tokenizer_kwargs\n",
        "    )\n",
        "elif model_args.tokenizer_name_or_path:\n",
        "    tokenizer = LlamaTokenizer.from_pretrained(\n",
        "        model_args.tokenizer_name_or_path, **tokenizer_kwargs\n",
        "    )\n",
        "else:\n",
        "    raise ValueError(\n",
        "        \"You are instantiating a new tokenizer from scratch. This is not supported by this script.\"\n",
        "        \"You can do it from another script, save it, and load it from here, using --tokenizer_name.\"\n",
        "    )\n",
        "tokenizer.add_eos_token = True\n",
        "\n",
        "# Preprocessing the datasets.\n",
        "# First we tokenize all the texts.\n",
        "# since this will be pickled to avoid _LazyModule error in Hasher force logger loading before tokenize_function\n",
        "tok_logger = transformers.utils.logging.get_logger(\n",
        "    \"transformers.tokenization_utils_base\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAD_YCZTx3kz"
      },
      "outputs": [],
      "source": [
        "def tokenize_function(examples):\n",
        "    with CaptureLogger(tok_logger) as cl:\n",
        "        output = tokenizer(examples[\"text\"])\n",
        "    # clm input could be much much longer than block_size\n",
        "    if \"Token indices sequence length is longer than the\" in cl.out:\n",
        "        tok_logger.warning(\n",
        "            \"^^^^^^^^^^^^^^^^ Please ignore the warning above - this long input will be chunked into smaller bits\"\n",
        "            \" before being passed to the model.\"\n",
        "        )\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PdkGNcarx6Kk"
      },
      "outputs": [],
      "source": [
        "if data_args.block_size is None:\n",
        "    block_size = tokenizer.model_max_length\n",
        "    if block_size > 1024:\n",
        "        logger.warning(\n",
        "            \"The chosen tokenizer supports a `model_max_length` that is longer than the default `block_size` value\"\n",
        "            \" of 1024. If you would like to use a longer `block_size` up to `tokenizer.model_max_length` you can\"\n",
        "            \" override this default with `--block_size xxx`.\"\n",
        "        )\n",
        "        block_size = 1024\n",
        "else:\n",
        "    if data_args.block_size > tokenizer.model_max_length:\n",
        "        logger.warning(\n",
        "            f\"The block_size passed ({data_args.block_size}) is larger than the maximum length for the model\"\n",
        "            f\"({tokenizer.model_max_length}). Using block_size={tokenizer.model_max_length}.\"\n",
        "        )\n",
        "    block_size = min(data_args.block_size, tokenizer.model_max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9b1JPwCwrjDP"
      },
      "outputs": [],
      "source": [
        "# Main data processing function that will concatenate all texts from our dataset and generate chunks of block_size.\n",
        "def group_texts(examples):\n",
        "    # Concatenate all texts.\n",
        "    concatenated_examples = {k: list(chain(*examples[k])) for k in examples.keys()}\n",
        "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
        "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
        "    # customize this part to your needs.\n",
        "    if total_length >= block_size:\n",
        "        total_length = (total_length // block_size) * block_size\n",
        "    # Split by chunks of max_len.\n",
        "    result = {\n",
        "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
        "        for k, t in concatenated_examples.items()\n",
        "    }\n",
        "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Bm7suFV31CA"
      },
      "outputs": [],
      "source": [
        "def transform_record(record):\n",
        "    record['timestamp'] = [record['timestamp']] if record['timestamp'] is not None else []\n",
        "    record['url'] = [record['url']] if record['url'] is not None else []\n",
        "    record['source'] = [record['source']] if record['source'] is not None else []\n",
        "    record['labels'] = record.get('labels', [])\n",
        "    return record"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahaTReJyRUAE"
      },
      "source": [
        "# Training Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7J9QdyQru2W",
        "outputId": "fd1a39e3-42c3-4b4b-c4f9-fb16d55b51f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:training datasets-bn_part_00007 has been loaded from disk\n",
            "INFO:__main__:training datasets-bn_part_00003 has been loaded from disk\n",
            "INFO:__main__:training datasets-bn_part_00013 has been loaded from disk\n",
            "INFO:__main__:training datasets-bn_part_00006 has been loaded from disk\n",
            "INFO:__main__:training datasets-bn_part_00014 has been loaded from disk\n",
            "INFO:__main__:training datasets-bn_part_00016 has been loaded from disk\n",
            "INFO:__main__:training datasets-bn_part_00009 has been loaded from disk\n",
            "INFO:__main__:training datasets-bn_part_00002 has been loaded from disk\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bn_part_00007\n",
            "/content/drive/MyDrive/Projects/bangla-llama/data/bn_part_00007_512\n",
            "bn_part_00003\n",
            "/content/drive/MyDrive/Projects/bangla-llama/data/bn_part_00003_512\n",
            "bn_part_00013\n",
            "/content/drive/MyDrive/Projects/bangla-llama/data/bn_part_00013_512\n",
            "bn_part_00006\n",
            "/content/drive/MyDrive/Projects/bangla-llama/data/bn_part_00006_512\n",
            "bn_part_00014\n",
            "/content/drive/MyDrive/Projects/bangla-llama/data/bn_part_00014_512\n",
            "bn_part_00016\n",
            "/content/drive/MyDrive/Projects/bangla-llama/data/bn_part_00016_512\n",
            "bn_part_00009\n",
            "/content/drive/MyDrive/Projects/bangla-llama/data/bn_part_00009_512\n",
            "bn_part_00002\n",
            "/content/drive/MyDrive/Projects/bangla-llama/data/bn_part_00002_512\n",
            "bn_part_00004\n",
            "/content/drive/MyDrive/Projects/bangla-llama/data/bn_part_00004_512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:training datasets-bn_part_00004 has been loaded from disk\n",
            "INFO:__main__:training datasets-bn_part_00012 has been loaded from disk\n",
            "INFO:__main__:training datasets-bn_part_00005 has been loaded from disk\n",
            "INFO:__main__:training datasets-bn_part_00008 has been loaded from disk\n",
            "INFO:__main__:training datasets-bn_part_00001 has been loaded from disk\n",
            "INFO:__main__:training datasets-bn_part_00000 has been loaded from disk\n",
            "INFO:__main__:training datasets-bn_part_00011 has been loaded from disk\n",
            "INFO:__main__:training datasets-bn_part_00010 has been loaded from disk\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bn_part_00012\n",
            "/content/drive/MyDrive/Projects/bangla-llama/data/bn_part_00012_512\n",
            "bn_part_00005\n",
            "/content/drive/MyDrive/Projects/bangla-llama/data/bn_part_00005_512\n",
            "bn_part_00008\n",
            "/content/drive/MyDrive/Projects/bangla-llama/data/bn_part_00008_512\n",
            "bn_part_00001\n",
            "/content/drive/MyDrive/Projects/bangla-llama/data/bn_part_00001_512\n",
            "bn_part_00000\n",
            "/content/drive/MyDrive/Projects/bangla-llama/data/bn_part_00000_512\n",
            "bn_part_00011\n",
            "/content/drive/MyDrive/Projects/bangla-llama/data/bn_part_00011_512\n",
            "bn_part_00010\n",
            "/content/drive/MyDrive/Projects/bangla-llama/data/bn_part_00010_512\n",
            "bn_part_00015\n",
            "/content/drive/MyDrive/Projects/bangla-llama/data/bn_part_00015_512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:training datasets-bn_part_00015 has been loaded from disk\n",
            "INFO:__main__:training datasets-bn_part_00017 has been loaded from disk\n",
            "Loading cached split indices for dataset at /content/drive/MyDrive/Projects/bangla-llama/data/bn_part_00007_512/train/cache-2e59fee9fdb52c15.arrow and /content/drive/MyDrive/Projects/bangla-llama/data/bn_part_00007_512/train/cache-7fc8c6d72d6e3ae8.arrow\n",
            "INFO:datasets.arrow_dataset:Loading cached split indices for dataset at /content/drive/MyDrive/Projects/bangla-llama/data/bn_part_00007_512/train/cache-2e59fee9fdb52c15.arrow and /content/drive/MyDrive/Projects/bangla-llama/data/bn_part_00007_512/train/cache-7fc8c6d72d6e3ae8.arrow\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bn_part_00017\n",
            "/content/drive/MyDrive/Projects/bangla-llama/data/bn_part_00017_512\n",
            "struct<timestamp: list<item: string>, url: list<item: string>, source: list<item: string>, input_ids: list<item: int32>, attention_mask: list<item: int8>, labels: list<item: int64>>\n",
            "struct<timestamp: string, url: string, source: string, input_ids: list<item: int32>, attention_mask: list<item: int8>>\n",
            "Converting to match types\n",
            "Before transformation: {'timestamp': Value(dtype='string', id=None), 'url': Value(dtype='string', id=None), 'source': Value(dtype='string', id=None), 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None), 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None)}\n",
            "After transformation: {'timestamp': Value(dtype='string', id=None), 'url': Value(dtype='string', id=None), 'source': Value(dtype='string', id=None), 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None), 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None)}\n"
          ]
        }
      ],
      "source": [
        "with training_args.main_process_first(desc=\"dataset map tokenization and grouping\"):\n",
        "    lm_datasets = []\n",
        "    path = Path(data_args.dataset_dir)\n",
        "    files = [file.name for file in path.glob(\"*.parquet\")]\n",
        "    if training_args.debug_mode is True:\n",
        "        files = [files[0]]\n",
        "    for idx, file in enumerate(files):\n",
        "        data_file = os.path.join(path, file)\n",
        "        filename = \"\".join(file.split(\".\")[:-1])\n",
        "        print(filename)\n",
        "        cache_path = os.path.join(\n",
        "            data_args.data_cache_dir, filename + f\"_{block_size}\"\n",
        "        )\n",
        "        print(cache_path)\n",
        "        os.makedirs(cache_path, exist_ok=True)\n",
        "        try:\n",
        "            processed_dataset = datasets.load_from_disk(\n",
        "                cache_path, keep_in_memory=False\n",
        "            )\n",
        "            logger.info(f\"training datasets-{filename} has been loaded from disk\")\n",
        "        except Exception:\n",
        "            cache_dir = os.path.join(\n",
        "                data_args.data_cache_dir, filename + f\"_text_{block_size}\"\n",
        "            )\n",
        "            os.makedirs(cache_dir, exist_ok=True)\n",
        "            raw_dataset = load_dataset(\n",
        "                \"parquet\",\n",
        "                data_files=data_file,\n",
        "                cache_dir=cache_dir,\n",
        "                keep_in_memory=False,\n",
        "            )\n",
        "            logger.info(f\"{file} has been loaded\")\n",
        "            tokenized_dataset = raw_dataset.map(\n",
        "                tokenize_function,\n",
        "                batched=True,\n",
        "                num_proc=data_args.preprocessing_num_workers,\n",
        "                remove_columns=\"text\",\n",
        "                load_from_cache_file=True,\n",
        "                keep_in_memory=False,\n",
        "                cache_file_names={\n",
        "                    k: os.path.join(cache_dir, \"tokenized.arrow\")\n",
        "                    for k in raw_dataset\n",
        "                },\n",
        "                desc=\"Running tokenizer on dataset\",\n",
        "            )\n",
        "            grouped_datasets = tokenized_dataset.map(\n",
        "                group_texts,\n",
        "                batched=True,\n",
        "                num_proc=data_args.preprocessing_num_workers,\n",
        "                load_from_cache_file=True,\n",
        "                keep_in_memory=False,\n",
        "                cache_file_names={\n",
        "                    k: os.path.join(cache_dir, \"grouped.arrow\")\n",
        "                    for k in tokenized_dataset\n",
        "                },\n",
        "                desc=f\"Grouping texts in chunks of {block_size}\",\n",
        "            )\n",
        "            processed_dataset = grouped_datasets\n",
        "            processed_dataset.save_to_disk(cache_path)\n",
        "        if idx == 0:\n",
        "            lm_datasets = processed_dataset[\"train\"]\n",
        "        else:\n",
        "            if lm_datasets.features.type != processed_dataset[\"train\"].features.type:\n",
        "              print(lm_datasets.features.type)\n",
        "              print(processed_dataset[\"train\"].features.type)\n",
        "\n",
        "              print(\"Converting to match types\")\n",
        "\n",
        "\n",
        "              print(\"Before transformation:\", processed_dataset[\"train\"].features)\n",
        "              processed_dataset['train'] = processed_dataset['train'].map(transform_record)\n",
        "              print(\"After transformation:\", processed_dataset[\"train\"].features)\n",
        "\n",
        "              continue\n",
        "              # assert (\n",
        "              #     lm_datasets.features.type\n",
        "              #     == processed_dataset[\"train\"].features.type\n",
        "              # )\n",
        "            lm_datasets = concatenate_datasets(\n",
        "                [lm_datasets, processed_dataset[\"train\"]]\n",
        "            )\n",
        "    lm_datasets = lm_datasets.train_test_split(\n",
        "        test_size=data_args.validation_split_percentage\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLpGSlDGyFb0",
        "outputId": "24513419-c4ae-485c-9d18-2c1b32f5a1d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:Num train_samples  393071\n",
            "INFO:__main__:Training example:\n",
            "INFO:__main__:\n",
            ",্,ী্,্।?্্ে??নে্,ন,, !?া!!ি্ত,ি!!!া,-র!!-ুা!!!\n",
            "ে।া,।?ু-র,ম।,-প-ি-,ক-মম,ব।\n",
            ",গ;ু,,ে?েম।াে,।ে।-েি।\n",
            ",্তো।।ী,ে।নদা,রে,-ব,নেে,ন\n"
          ]
        }
      ],
      "source": [
        "if training_args.do_train:\n",
        "    train_dataset = lm_datasets[\"train\"]\n",
        "    if data_args.max_train_samples is not None:\n",
        "        max_train_samples = min(len(train_dataset), data_args.max_train_samples)\n",
        "        train_dataset = train_dataset.select(range(max_train_samples))\n",
        "    logger.info(f\"Num train_samples  {len(train_dataset)}\")\n",
        "    logger.info(\"Training example:\")\n",
        "    logger.info(tokenizer.decode(train_dataset[0][\"input_ids\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8V15sdMsBVL"
      },
      "outputs": [],
      "source": [
        "if training_args.do_eval:\n",
        "    eval_dataset = lm_datasets[\"test\"]\n",
        "    if data_args.max_eval_samples is not None:\n",
        "        max_eval_samples = min(len(eval_dataset), data_args.max_eval_samples)\n",
        "        eval_dataset = eval_dataset.select(range(max_eval_samples))\n",
        "    logger.info(f\"Num eval_samples  {len(eval_dataset)}\")\n",
        "    logger.info(\"Evaluation example:\")\n",
        "    logger.info(tokenizer.decode(eval_dataset[0][\"input_ids\"]))\n",
        "compute_dtype = (\n",
        "    torch.float16\n",
        "    if training_args.fp16\n",
        "    else (torch.bfloat16 if training_args.bf16 else torch.float32)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7aALS6O66cr"
      },
      "outputs": [],
      "source": [
        "if training_args.load_in_kbits in [4, 8]:\n",
        "    load_in_4bit = training_args.load_in_kbits == 4\n",
        "    load_in_8bit = training_args.load_in_kbits == 8\n",
        "    if training_args.modules_to_save is not None:\n",
        "        load_in_8bit_skip_modules = training_args.modules_to_save.split(\",\")\n",
        "    else:\n",
        "        load_in_8bit_skip_modules = None\n",
        "    quantization_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=training_args.load_in_kbits == 4,\n",
        "        load_in_8bit=training_args.load_in_kbits == 8,\n",
        "        llm_int8_threshold=6.0,\n",
        "        load_in_8bit_skip_modules=load_in_8bit_skip_modules,\n",
        "        bnb_4bit_compute_dtype=compute_dtype,\n",
        "        bnb_4bit_use_double_quant=training_args.double_quant,\n",
        "        bnb_4bit_quant_type=training_args.quant_type,  # {'fp4', 'nf4'}\n",
        "    )\n",
        "else:\n",
        "    load_in_4bit = False\n",
        "    load_in_8bit = False\n",
        "    quantization_config = None\n",
        "\n",
        "if quantization_config is not None:\n",
        "    logger.info(f\"quantization_config:{quantization_config.to_dict()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(load_in_4bit)\n",
        "print(load_in_8bit)\n",
        "print(quantization_config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rFbf4TVkDDd",
        "outputId": "88e5fed9-41bd-4268-f169-69153dadefe7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "False\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIA3cr55RYUH"
      },
      "source": [
        "# Pretrained Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_args.model_name_or_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "_ZGNvIQbpdW-",
        "outputId": "6448baed-e5d4-4a06-d2a5-2a6b7b84d68d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Projects/bangla-llama/data/output/checkpoint-11000/pt_lora_model'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/Projects/bangla-llama/data/output/checkpoint-11000/pt_lora_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8W6kJnIfsbhw",
        "outputId": "205d5454-5128-4f12-b719-e16f92b917bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "adapter_config.json\t   config.json\t      README.md\t\t       tokenizer_config.json\n",
            "adapter_model.safetensors  pytorch_model.bin  special_tokens_map.json  tokenizer.model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 777,
          "referenced_widgets": [
            "5d9acf29aa654fb7ab5e6629989df8ea",
            "37cfb693d6614a6991c975067530fa7a",
            "5b28fa0c7335401ab698da88bac33384",
            "a8a2f69d60624e00a6dd1567a5c4b128",
            "c7e6ed40002c45c7bc0c26fa52ce198c",
            "b9df4a0ca72046758171363ffa439043",
            "ccd33b9a0b604cb997f5057cb51d597a",
            "9310aa54335e423fb423ad9444ad3c39",
            "11b8540ca5914676ac8ac29bd80a71d3",
            "e949e0192cf24a9e9a3bb5e7e58103b6",
            "45615d39596e42ecb1a18746c34445d9",
            "7dda6cb20c9045e2b147501dcccd0690",
            "da6dc7ab0dcb4e87837e64bad527335b",
            "bdfcb6eee4aa482393f4815967825447",
            "3c9ffaa8ed0947a8af122e2cfe19a32a",
            "f3c6e755540c40b7972d14c29b2fd148",
            "9a6f079800b94656a1e3dece7d927e37",
            "5723692e81af446badee7b0a03a2041d",
            "89d2e6627194448c8c07967c7ab387d1",
            "db9bfd6b9e3b4f7980ceedf2452a0fe3",
            "7b0c91387b7b430793ed128f95b3265f",
            "1ad8b349b0274c7cb29529b9cea987bd",
            "94d1ce65f6704c369d1dc11c71b88164",
            "80df440de92249f39d3346226ec5059d",
            "0bd672660bfd4006bd0386305750b5fb",
            "b53981ec8cd64cab813cf77fb1a6100c",
            "3b3ad2b6d0ff4568969c662dd5318076",
            "f5554603698a4d21909dc659c2f1bd50",
            "e125147a22f145c79f5b88bb3f4fbfb2",
            "a6d9e01d3f814d57b4aa64c402a1b798",
            "97faafca9f064f5697b946f535a35b5d",
            "f6a29dacf3954006a468498b489aeabe",
            "a05fd883e5704c31a388fdc3776a183d",
            "2020bd34ef3b4266889bcc11e409b1bd",
            "31770e24def0423c9dc96a3a53c3081f",
            "ae813d2c157c4b8b9cf2917257f1b49b",
            "8afc4a6853384d859d942469bc42e141",
            "c0d8a2c26dcc431d8e2d34ee7034e567",
            "92e22d07e5a44a748d340636014de987",
            "6c8697d7b14745d38d014f655d7742ec",
            "82d75bb0a3ef4a1eb4491b98e12684b6",
            "6ded82b0f72d482487a3d65691135edb",
            "01d6c083e9194db98835827ec1d4a149",
            "2007d1627f2847ffb874a22c41c5d6d3",
            "df156146aabb426db74ac08333a043b6",
            "4b31182c62354aceb6169e123c7fffa7",
            "88400b9b59ac4585bc7feb773fe68b6b",
            "b0337017293c42aaa4067dfb8c40e07b",
            "304c50e7e4a04832b9dd1d4095bab4c9",
            "01c8d11fe9de4fae95fc1f956284026a",
            "d8223b185fd748f39ffae376f607ab51",
            "6a278c7d9e2d47ee93a077e315b8cf99",
            "293efab632914fd0b0800c50358a40f9",
            "019cd599f7f642049a91f483d654c6fa",
            "97d056deb6b443c884e1c8ee137e76e3",
            "944e385d07d9433d9e7b879b28c7c908",
            "47121d95aa7647648a7770f18a2b4ac6",
            "7c7e6a3be61e4d6ab03da85849779aba",
            "5971c9668a3e4a13a245ef0a021219ce",
            "555b16943fe849b0b2e1511047c49818",
            "463cba8f3443452bbf51e6b9fa7e45ec",
            "9af91a104636450eb6a7fb4f924c0467",
            "82943db8ccda47af820a081983731815",
            "9228e86096eb4459bffaa75fefd07e46",
            "ef149666ae774e4aa5bd3cef01dad8bc",
            "89d85c8b0a634e45a6ba3f5b8b651fcd"
          ]
        },
        "id": "EUixK2rV7BhR",
        "outputId": "1ee00866-8902-432a-c144-5bb3ad8fa73c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5d9acf29aa654fb7ab5e6629989df8ea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[INFO|modeling_utils.py:2603] 2024-01-22 05:55:43,344 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--brishtiteveja--bangla-llama-7b-base-v0.1/snapshots/b813d720142b5858fdfa3d4da89cbe8ecc867ed4/pytorch_model.bin.index.json\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7dda6cb20c9045e2b147501dcccd0690",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "94d1ce65f6704c369d1dc11c71b88164",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model-00001-of-00002.bin:   0%|          | 0.00/9.95G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2020bd34ef3b4266889bcc11e409b1bd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model-00002-of-00002.bin:   0%|          | 0.00/3.83G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[INFO|configuration_utils.py:599] 2024-01-22 06:08:22,349 >> Generate config GenerationConfig {\n",
            "  \"_from_model_config\": true,\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.31.0\",\n",
            "  \"use_cache\": false\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "df156146aabb426db74ac08333a043b6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[INFO|modeling_utils.py:3329] 2024-01-22 06:08:43,592 >> All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
            "\n",
            "[INFO|modeling_utils.py:3337] 2024-01-22 06:08:43,594 >> All the weights of LlamaForCausalLM were initialized from the model checkpoint at brishtiteveja/bangla-llama-7b-base-v0.1.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/183 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "944e385d07d9433d9e7b879b28c7c908"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[INFO|configuration_utils.py:561] 2024-01-22 06:08:44,231 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--brishtiteveja--bangla-llama-7b-base-v0.1/snapshots/b813d720142b5858fdfa3d4da89cbe8ecc867ed4/generation_config.json\n",
            "[INFO|configuration_utils.py:599] 2024-01-22 06:08:44,233 >> Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 1,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"max_length\": 4096,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"temperature\": 0.6,\n",
            "  \"top_p\": 0.9,\n",
            "  \"transformers_version\": \"4.31.0\"\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "if model_args.model_name_or_path:\n",
        "    torch_dtype = (\n",
        "        model_args.torch_dtype\n",
        "        if model_args.torch_dtype in [\"auto\", None]\n",
        "        else getattr(torch, model_args.torch_dtype)\n",
        "    )\n",
        "    device_map = {\"\": int(os.environ.get(\"LOCAL_RANK\") or 0)}\n",
        "    model = LlamaForCausalLM.from_pretrained(\n",
        "        model_args.model_name_or_path,\n",
        "        from_tf=bool(\".ckpt\" in model_args.model_name_or_path),\n",
        "        config=config,\n",
        "        cache_dir=model_args.cache_dir,\n",
        "        revision=model_args.model_revision,\n",
        "        use_auth_token=True if model_args.use_auth_token else None,\n",
        "        torch_dtype=torch_dtype,\n",
        "        low_cpu_mem_usage=True,\n",
        "        device_map=device_map,\n",
        "        load_in_4bit=load_in_4bit,\n",
        "        load_in_8bit=load_in_8bit,\n",
        "        quantization_config=quantization_config,\n",
        "    )\n",
        "else:\n",
        "    model = AutoModelForCausalLM.from_config(config)\n",
        "    n_params = sum({p.data_ptr(): p.numel() for p in model.parameters()}.values())\n",
        "    logger.info(\n",
        "        f\"Training new model from scratch - Total size={n_params/2**20:.2f}M params\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/Projects/bangla-llama/data/output/checkpoint-11000/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_d8vNmtnkiNX",
        "outputId": "d90cbef7-8fc5-4034-ab8c-c48e92ed2cf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "adapter_config.json  pt_lora_model  scheduler.pt\t     tokenizer.model\n",
            "adapter_model.bin    README.md\t    special_tokens_map.json  trainer_state.json\n",
            "optimizer.pt\t     rng_state.pth  tokenizer_config.json    training_args.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGzhFv7u7I2y",
        "outputId": "5244599e-ab88-498e-e1a5-cfccde641907"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:Model vocab size: 50437\n",
            "INFO:__main__:Tokenizer vocab size: 50437\n"
          ]
        }
      ],
      "source": [
        "if training_args.load_in_kbits in [4, 8]:\n",
        "    model = prepare_model_for_kbit_training(\n",
        "        model, use_gradient_checkpointing=training_args.gradient_checkpointing\n",
        "    )\n",
        "model.config.use_cache = False\n",
        "model_vocab_size = model.get_output_embeddings().weight.size(0)\n",
        "tokenizer_vocab_size = len(tokenizer)\n",
        "\n",
        "logger.info(f\"Model vocab size: {model_vocab_size}\")\n",
        "logger.info(f\"Tokenizer vocab size: {tokenizer_vocab_size}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if model_vocab_size != tokenizer_vocab_size:\n",
        "    logger.info(f\"Resize model vocab size to {tokenizer_vocab_size}\")\n",
        "    model.resize_token_embeddings(len(tokenizer))"
      ],
      "metadata": {
        "id": "lLsht_NLzyQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eT8pGCpK7Ord",
        "outputId": "23fc134f-f581-4d4c-a543-8ad2d29a9c5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:Init new peft model\n",
            "INFO:__main__:target_modules: ['q_proj', 'v_proj', 'k_proj', 'o_proj', 'gate_proj', 'down_proj', 'up_proj']\n",
            "INFO:__main__:lora_rank: 64\n"
          ]
        }
      ],
      "source": [
        "if training_args.peft_path is not None:\n",
        "    logger.info(\"Peft from pre-trained model\")\n",
        "    model = PeftModel.from_pretrained(\n",
        "        model, training_args.peft_path, device_map=device_map\n",
        "    )\n",
        "else:\n",
        "    logger.info(\"Init new peft model\")\n",
        "    target_modules = training_args.trainable.split(\",\")\n",
        "    modules_to_save = training_args.modules_to_save\n",
        "    if modules_to_save is not None:\n",
        "        modules_to_save = modules_to_save.split(\",\")\n",
        "    lora_rank = training_args.lora_rank\n",
        "    lora_dropout = training_args.lora_dropout\n",
        "    lora_alpha = training_args.lora_alpha\n",
        "    logger.info(f\"target_modules: {target_modules}\")\n",
        "    logger.info(f\"lora_rank: {lora_rank}\")\n",
        "    peft_config = LoraConfig(\n",
        "        task_type=TaskType.CAUSAL_LM,\n",
        "        target_modules=target_modules,\n",
        "        inference_mode=False,\n",
        "        r=lora_rank,\n",
        "        lora_alpha=lora_alpha,\n",
        "        lora_dropout=lora_dropout,\n",
        "        modules_to_save=modules_to_save,\n",
        "    )\n",
        "    model = get_peft_model(model, peft_config)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UMc8Q6Sh7RP5"
      },
      "outputs": [],
      "source": [
        "if training_args.gradient_checkpointing and (\n",
        "    not model.modules_to_save or \"embed_tokens\" not in model.modules_to_save\n",
        "):\n",
        "    # enable requires_grad to avoid exception during backward pass when using gradient_checkpoint without tuning embed.\n",
        "    if hasattr(model.base_model, \"enable_input_require_grads\"):\n",
        "        model.base_model.enable_input_require_grads()\n",
        "    elif hasattr(model.base_model, \"get_input_embeddings\"):\n",
        "\n",
        "        def make_inputs_require_grad(_module, _input, _output):\n",
        "            _output.requires_grad_(True)\n",
        "\n",
        "        model.base_model.get_input_embeddings().register_forward_hook(\n",
        "            make_inputs_require_grad\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "So5uOdow7TNz",
        "outputId": "f21785ef-2cce-4b78-b63b-af75e3f5826b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:model.modules_to_save: {'embed_tokens', 'lm_head'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 422,051,840 || all params: 7,160,467,456 || trainable%: 5.894193955819858\n"
          ]
        }
      ],
      "source": [
        "for name, module in model.named_modules():\n",
        "    if isinstance(module, LoraLayer):\n",
        "        if training_args.bf16:\n",
        "            module = module.to(torch.bfloat16)\n",
        "        if training_args.fp16:\n",
        "            module = module.to(torch.float16)\n",
        "    if \"norm\" in name:\n",
        "        module = module.to(torch.float16)\n",
        "    if \"lm_head\" in name or \"embed_tokens\" in name:\n",
        "        if hasattr(module, \"weight\"):\n",
        "            if training_args.bf16 and module.weight.dtype == torch.float32:\n",
        "                module = module.to(torch.bfloat16)\n",
        "            if training_args.fp16 and module.weight.dtype == torch.float32:\n",
        "                module = module.to(torch.float16)\n",
        "model.print_trainable_parameters()\n",
        "logger.info(f\"model.modules_to_save: {model.modules_to_save}\")\n",
        "old_state_dict = model.state_dict\n",
        "model.state_dict = (\n",
        "    lambda self, *_, **__: get_peft_model_state_dict(self, old_state_dict())\n",
        ").__get__(model, type(model))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training_args.push_to_hub = \"True\"\n",
        "# training_args.hub_model_id = \"brishtiteveja/bangla-llama-7b-base-v0.1\"\n",
        "# training_args.output_dir='/content/drive/MyDrive/Projects/bangla-llama/data/output2'"
      ],
      "metadata": {
        "id": "KrJqYZbr20uZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "pprint(training_args)"
      ],
      "metadata": {
        "id": "S46lsD7S35x0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -R /content/drive/MyDrive/Projects/bangla-llama/data/output/checkpoint-11000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4K3fexX-KY1",
        "outputId": "d7804dbe-ce20-4c7f-ff1b-e707d2bb5a19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Projects/bangla-llama/data/output/checkpoint-11000:\n",
            "adapter_config.json  pt_lora_model  special_tokens_map.json  training_args.bin\n",
            "adapter_model.bin    README.md\t    tokenizer_config.json\n",
            "config.json\t     rng_state.pth  tokenizer.model\n",
            "optimizer.pt\t     scheduler.pt   trainer_state.json\n",
            "\n",
            "/content/drive/MyDrive/Projects/bangla-llama/data/output/checkpoint-11000/pt_lora_model:\n",
            "adapter_config.json\t   config.json\tspecial_tokens_map.json  tokenizer.model\n",
            "adapter_model.safetensors  README.md\ttokenizer_config.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model.save_pretrained(training_args.output_dir, push_to_hub=False)\n",
        "#"
      ],
      "metadata": {
        "id": "ilHlTA2k-119"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#trainer.save_model('/content/drive/MyDrive/Projects/bangla-llama/data/output3')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lifpKb1A_vYE",
        "outputId": "3b22c977-11de-4fd4-b829-421825bed3ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[INFO|trainer.py:2807] 2024-01-19 23:16:03,529 >> Saving model checkpoint to /content/drive/MyDrive/Projects/bangla-llama/data/output3\n",
            "[INFO|tokenization_utils_base.py:2210] 2024-01-19 23:16:03,569 >> tokenizer config file saved in /content/drive/MyDrive/Projects/bangla-llama/data/output3/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2217] 2024-01-19 23:16:03,574 >> Special tokens file saved in /content/drive/MyDrive/Projects/bangla-llama/data/output3/special_tokens_map.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -R /content/drive/MyDrive/Projects/bangla-llama/data/output3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZP8OtbgBI6j",
        "outputId": "128ac43e-c1d3-433b-ab82-f22d907961b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Projects/bangla-llama/data/output3:\n",
            "adapter_config.json  README.md                tokenizer_config.json  training_args.bin\n",
            "adapter_model.bin    special_tokens_map.json  tokenizer.model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#torch.save(model.state_dict(), '/content/drive/MyDrive/Projects/bangla-llama/data/output/checkpoint-11000/pytorch_model.bin')"
      ],
      "metadata": {
        "id": "pxdCiuDaBBff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!du -h /content/drive/MyDrive/Projects/bangla-llama/data/output/checkpoint-11000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ofnt5mzoAsc2",
        "outputId": "d22105b1-bfa9-4e37-c1dc-e6b34cca2254"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "926K\t/content/drive/MyDrive/Projects/bangla-llama/data/output/checkpoint-11000/pt_lora_model\n",
            "3.3G\t/content/drive/MyDrive/Projects/bangla-llama/data/output/checkpoint-11000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/Projects/bangla-llama/data/output2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8jXRZct-_sf",
        "outputId": "5d6448d1-e1ba-4690-eb59-ef29408ca8f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "adapter_config.json  adapter_model.safetensors\tspecial_tokens_map.json  tokenizer.model\n",
            "adapter_model.bin    README.md\t\t\ttokenizer_config.json\t training_args.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQlLT_7RGRWI",
        "outputId": "a8b4f427-04e3-4f8f-b15d-e7a429ef8189"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'peft.peft_model.PeftModelForCausalLM'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merged_model = model.merge_and_unload()"
      ],
      "metadata": {
        "id": "vp9BWKAqGe0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(merged_model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FFMHfK1GvGo",
        "outputId": "6aaa5068-3390-4cb1-f83d-297a87ac5fc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merged_model.save_pretrained('/content/drive/MyDrive/Projects/bangla-llama/data/output_merged/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "go5enyC9GxPG",
        "outputId": "f725365f-934d-4677-d994-5f5b33905f81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[INFO|configuration_utils.py:458] 2024-01-19 23:43:18,942 >> Configuration saved in /content/drive/MyDrive/Projects/bangla-llama/data/output_merged/config.json\n",
            "[INFO|configuration_utils.py:375] 2024-01-19 23:43:18,948 >> Configuration saved in /content/drive/MyDrive/Projects/bangla-llama/data/output_merged/generation_config.json\n",
            "[INFO|modeling_utils.py:1859] 2024-01-19 23:44:06,336 >> The model is bigger than the maximum size per checkpoint (10GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at /content/drive/MyDrive/Projects/bangla-llama/data/output_merged/pytorch_model.bin.index.json.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/Projects/bangla-llama/data/output_merged"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3P0D0-wPHE1h",
        "outputId": "64683611-1c86-4a53-9174-11cc34fc693e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "config.json\t\tpytorch_model-00001-of-00002.bin  pytorch_model.bin.index.json\n",
            "generation_config.json\tpytorch_model-00002-of-00002.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5H1edIBRdHt"
      },
      "source": [
        "# Trainer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsnwd2ZYsM7o",
        "outputId": "99341110-50cb-4df3-b3fa-f5fff681ad4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[INFO|trainer.py:386] 2024-01-19 23:15:33,576 >> You have loaded a model on multiple GPUs. `is_model_parallel` attribute will be force-set to `True` to avoid any unexpected behavior such as device placement mismatching.\n",
            "[codecarbon INFO @ 23:15:33] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 23:15:33] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 23:15:33] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 23:15:33] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 23:15:33] No CPU tracking mode found. Falling back on CPU constant mode.\n",
            "[codecarbon WARNING @ 23:15:35] We saw that you have a Intel(R) Xeon(R) CPU @ 2.20GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 23:15:35] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon INFO @ 23:15:35] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 23:15:35]   Platform system: Linux-6.1.58+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 23:15:35]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 23:15:35]   CodeCarbon version: 2.2.3\n",
            "[codecarbon INFO @ 23:15:35]   Available RAM : 83.477 GB\n",
            "[codecarbon INFO @ 23:15:35]   CPU count: 12\n",
            "[codecarbon INFO @ 23:15:35]   CPU model: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon INFO @ 23:15:35]   GPU count: 1\n",
            "[codecarbon INFO @ 23:15:35]   GPU model: 1 x NVIDIA A100-SXM4-40GB\n"
          ]
        }
      ],
      "source": [
        "# Initialize our Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset if training_args.do_train else None,\n",
        "    eval_dataset=eval_dataset if training_args.do_eval else None,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=fault_tolerance_data_collator,\n",
        "    compute_metrics=compute_metrics\n",
        "    if training_args.do_eval and not is_torch_tpu_available()\n",
        "    else None,\n",
        "    preprocess_logits_for_metrics=preprocess_logits_for_metrics\n",
        "    if training_args.do_eval and not is_torch_tpu_available()\n",
        "    else None,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54fKn04pAXqH",
        "outputId": "e2926c0a-98c7-46f8-cf85-a7d3b0a323b7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "training_args.per_device_train_batch_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-vjdZigRg1b"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        },
        "id": "vaTOF4X_7mhe",
        "outputId": "f220f4c8-1d3b-4a2b-e28c-a4794ce7b540"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[INFO|trainer.py:763] 2024-01-19 20:59:25,172 >> The following columns in the training set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: url, timestamp, source. If url, timestamp, source are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "[INFO|trainer.py:1686] 2024-01-19 20:59:25,227 >> ***** Running training *****\n",
            "[INFO|trainer.py:1687] 2024-01-19 20:59:25,228 >>   Num examples = 393,071\n",
            "[INFO|trainer.py:1688] 2024-01-19 20:59:25,229 >>   Num Epochs = 1\n",
            "[INFO|trainer.py:1689] 2024-01-19 20:59:25,229 >>   Instantaneous batch size per device = 8\n",
            "[INFO|trainer.py:1692] 2024-01-19 20:59:25,230 >>   Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "[INFO|trainer.py:1693] 2024-01-19 20:59:25,231 >>   Gradient Accumulation steps = 4\n",
            "[INFO|trainer.py:1694] 2024-01-19 20:59:25,232 >>   Total optimization steps = 12,283\n",
            "[INFO|trainer.py:1695] 2024-01-19 20:59:25,238 >>   Number of trainable parameters = 573,087,744\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2' max='12283' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [    2/12283 : < :, Epoch 0.00/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-112adeee3333>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mlast_checkpoint\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlast_checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtrain_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1537\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1538\u001b[0m         )\n\u001b[0;32m-> 1539\u001b[0;31m         return inner_training_loop(\n\u001b[0m\u001b[1;32m   1540\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1541\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1812\u001b[0m                     \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging_nan_inf_filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1813\u001b[0m                     \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_torch_tpu_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1814\u001b[0;31m                     \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1815\u001b[0m                 ):\n\u001b[1;32m   1816\u001b[0m                     \u001b[0;31m# if loss is nan or inf simply add the average of previous logged losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "trainer.add_callback(SavePeftModelCallback)\n",
        "# Training\n",
        "if training_args.do_train:\n",
        "    print(\"Starting training\")\n",
        "\n",
        "    checkpoint = None\n",
        "    if training_args.resume_from_checkpoint is not None:\n",
        "        checkpoint = training_args.resume_from_checkpoint\n",
        "    elif last_checkpoint is not None:\n",
        "        checkpoint = last_checkpoint\n",
        "    train_result = trainer.train(resume_from_checkpoint=checkpoint)\n",
        "\n",
        "    metrics = train_result.metrics\n",
        "\n",
        "    max_train_samples = (\n",
        "        data_args.max_train_samples\n",
        "        if data_args.max_train_samples is not None\n",
        "        else len(train_dataset)\n",
        "    )\n",
        "    metrics[\"train_samples\"] = min(max_train_samples, len(train_dataset))\n",
        "\n",
        "    trainer.log_metrics(\"train\", metrics)\n",
        "    trainer.save_metrics(\"train\", metrics)\n",
        "    trainer.save_state()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23sCTyR-RkOG"
      },
      "source": [
        "# Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Il18p7Hd7oSP"
      },
      "outputs": [],
      "source": [
        "# # Evaluation\n",
        "# if training_args.do_eval:\n",
        "#     logger.info(\"*** Evaluate ***\")\n",
        "\n",
        "#     metrics = trainer.evaluate()\n",
        "\n",
        "#     max_eval_samples = (\n",
        "#         data_args.max_eval_samples\n",
        "#         if data_args.max_eval_samples is not None\n",
        "#         else len(eval_dataset)\n",
        "#     )\n",
        "#     metrics[\"eval_samples\"] = min(max_eval_samples, len(eval_dataset))\n",
        "#     try:\n",
        "#         perplexity = math.exp(metrics[\"eval_loss\"])\n",
        "#     except OverflowError:\n",
        "#         perplexity = float(\"inf\")\n",
        "#     metrics[\"perplexity\"] = perplexity\n",
        "\n",
        "#     trainer.log_metrics(\"eval\", metrics)\n",
        "#     trainer.save_metrics(\"eval\", metrics)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -R '/content/drive/MyDrive/Projects/bangla-llama/data/output/checkpoint-11000/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZB36qlu2uWuN",
        "outputId": "051c0b0d-8355-4bd1-99b5-89e5591c29b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Projects/bangla-llama/data/output/checkpoint-11000/:\n",
            "adapter_config.json  pt_lora_model  scheduler.pt\t     tokenizer.model\n",
            "adapter_model.bin    README.md\t    special_tokens_map.json  trainer_state.json\n",
            "optimizer.pt\t     rng_state.pth  tokenizer_config.json    training_args.bin\n",
            "\n",
            "/content/drive/MyDrive/Projects/bangla-llama/data/output/checkpoint-11000/pt_lora_model:\n",
            "adapter_config.json\t   README.md\t\t    tokenizer_config.json\n",
            "adapter_model.safetensors  special_tokens_map.json  tokenizer.model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "{}\n",
        "\n",
        "### Input:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\"\n",
        "\n",
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"বাংলাদেশ সম্পর্কে বল\", # instruction\n",
        "        \"\", # input\n",
        "        \"\", # output - leave this blank for generation!\n",
        "    )\n",
        "]*1, return_tensors = \"pt\").to(\"cuda\")"
      ],
      "metadata": {
        "id": "ki3u2vlkmUZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8w2Hr3a7oM7m",
        "outputId": "a58649f6-edbb-4ae6-9289-2b5999c8317c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LlamaTokenizer(name_or_path='/content/drive/MyDrive/Projects/bangla-llama/data/output/checkpoint-11000/pt_lora_model', vocab_size=50437, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'eos_token': AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True)}, clean_up_tokenization_spaces=False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHcVJnpaoKn8",
        "outputId": "a7e440cf-fd68-4fca-b816-b0d84bd6f806"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[    1, 13866,   338,   385, 15278,   393, 16612,   263,  3414, 29892,\n",
            "          3300,  2859,   411,   385,  1881,   393,  8128,  4340,  3030, 29889,\n",
            "         14350,   263,  2933,   393,  7128,  2486,  1614,  2167,   278,  2009,\n",
            "         29889,    13,    13,  2277, 29937,  2799,  4080, 29901,    13,  5618,\n",
            "           338,   278,  7483,   310,  5546, 29973,    13,    13,  2277, 29937,\n",
            "         10567, 29901,    13,    13,    13,  2277, 29937, 13291, 29901,    13,\n",
            "             2]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True)"
      ],
      "metadata": {
        "id": "_C8KGK8ZjGXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.batch_decode(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rGu-cxNoSj3",
        "outputId": "dd7c827a-33eb-42de-ae60-76001ebf85c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<s> Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nবাংলাদেশ সম্পর্কে বল\\n\\n### Input:\\n\\n\\n### Response:\\n</s><s>import রাজনৈতিকk নির্মম ্যাঙ্কিং উইথ উইথ বৃটিশ বৃটিশউই সুরকার মুজিব পরাজয়ের মুজিব মুজিব মুজিব সুরকার সুরকার জন্মস্থান মুজিব সুরকার মুজিব 8093 4471 তালিকাভুক্ত তালিকাভুক্ত বন্দি পড়ালেখা মুজিব 7531 কিশোরগঞ্জ খেলায় মুজিবະ মুজিব আল্প তালিকাভুক্ত উইথ 6541 একদম 8093 পড়ালেখা 6541 পড়ালেখা টেলিস্কোপ পড়ালেখা টেলিস্কোপ টেলিস্কোপ তালিকাভুক্ত 7531 পড়ালেখা 9063 টেলিস্কোপ অপরিচিত মহীশূর 5756 4846অপারেশন 9063 একদম কিশোরগঞ্জ 4471 জন্মস্থান']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall trl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qi1b3dHYWZhJ",
        "outputId": "2ba0a176-69e5-4403-8412-89edd14c0d28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: trl 0.4.7\n",
            "Uninstalling trl-0.4.7:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.10/dist-packages/tests/*\n",
            "    /usr/local/lib/python3.10/dist-packages/trl-0.4.7.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/trl/*\n",
            "Proceed (Y/n)? Y\n",
            "  Successfully uninstalled trl-0.4.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install trl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64PUdV9oWc9d",
        "outputId": "a3fdbb3e-b10e-4e58-cc96-fe7f6aac1f15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting trl\n",
            "  Using cached trl-0.7.10-py3-none-any.whl (150 kB)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from trl) (2.1.0+cu121)\n",
            "Requirement already satisfied: transformers>=4.31.0 in /usr/local/lib/python3.10/dist-packages (from trl) (4.31.0)\n",
            "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.10/dist-packages (from trl) (1.26.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from trl) (0.21.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from trl) (2.14.5)\n",
            "Requirement already satisfied: tyro>=0.5.11 in /usr/local/lib/python3.10/dist-packages (from trl) (0.6.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (2.1.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (0.17.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (4.65.0)\n",
            "Requirement already satisfied: docstring-parser>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (0.15)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (13.7.0)\n",
            "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (1.6.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->trl) (5.9.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (10.0.1)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (0.70.15)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (3.8.6)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (3.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (1.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->trl) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->trl) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->trl) (2023.7.22)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.16.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.4.0->trl) (2.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl) (2023.3.post1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.4.0->trl) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets->trl) (1.16.0)\n",
            "Installing collected packages: trl\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "autotrain-advanced 0.6.37 requires protobuf==4.23.4, but you have protobuf 3.20.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed trl-0.7.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine Tuning"
      ],
      "metadata": {
        "id": "1sG6CnX3GvIR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall protobuf trl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7k9ZL2xXnRt",
        "outputId": "844a5827-0e62-47b4-956e-2572ee3f7b31"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: protobuf 3.20.1\n",
            "Uninstalling protobuf-3.20.1:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.10/dist-packages/google/protobuf/*\n",
            "    /usr/local/lib/python3.10/dist-packages/protobuf-3.20.1-py3.10-nspkg.pth\n",
            "    /usr/local/lib/python3.10/dist-packages/protobuf-3.20.1.dist-info/*\n",
            "Proceed (Y/n)? "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install protobuf==4.23.4\n",
        "!pip install trl==0.7.2"
      ],
      "metadata": {
        "id": "mtftn5ZwW1dJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#########\n",
        "# Adapted From: https://towardsdatascience.com/fine-tune-your-own-llama-2-model-in-a-colab-notebook-df9823a04a32\n",
        "#########\n",
        "import os\n",
        "\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from peft import LoraConfig, PeftModel\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    LlamaTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    HfArgumentParser,\n",
        "    TrainingArguments,\n",
        "    logging,\n",
        "    pipeline,\n",
        ")\n",
        "from trl import SFTTrainer\n",
        "\n",
        "# The model that you want to train from the Hugging Face hub\n",
        "#model_name = \"abhinand/tamil-llama-7b-base-v0.1\"\n",
        "model_name = \"brishtiteveja/bangla-llama-7b-base-v0.1\"\n",
        "\n",
        "# The instruction dataset to use\n",
        "dataset_name = \"brishtiteveja/bangla-alpaca-orca\"\n",
        "\n",
        "instruction_column = \"text\"\n",
        "\n",
        "# Fine-tuned model name\n",
        "new_model = \"brishtiteveja/bangla-llama-7b-instruct-v0.1\""
      ],
      "metadata": {
        "id": "9QInBznNVvMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "use_flash_attention_2 = False\n",
        "\n",
        "################################################################################\n",
        "# QLoRA parameters\n",
        "################################################################################\n",
        "\n",
        "# LoRA attention dimension\n",
        "lora_r = 64\n",
        "\n",
        "# Alpha parameter for LoRA scaling\n",
        "lora_alpha = 128\n",
        "\n",
        "# Dropout probability for LoRA layers\n",
        "lora_dropout = 0.1\n",
        "\n",
        "lora_target_modules = [\n",
        "    \"q_proj\",\n",
        "    \"k_proj\",\n",
        "    \"v_proj\",\n",
        "    \"o_proj\",\n",
        "    \"gate_proj\",\n",
        "    \"down_proj\",\n",
        "    \"up_proj\",\n",
        "]\n",
        "\n",
        "################################################################################\n",
        "# bitsandbytes parameters\n",
        "################################################################################\n",
        "\n",
        "# Activate 4-bit precision base model loading\n",
        "use_4bit = False\n",
        "use_8_bit = False\n",
        "\n",
        "# Compute dtype for 4-bit base models\n",
        "bnb_4bit_compute_dtype = \"bfloat16\"\n",
        "\n",
        "# Quantization type (fp4 or nf4)\n",
        "bnb_4bit_quant_type = \"nf4\"\n",
        "\n",
        "# Activate nested quantization for 4-bit base models (double quantization)\n",
        "use_nested_quant = False\n",
        "\n",
        "################################################################################\n",
        "# TrainingArguments parameters\n",
        "################################################################################\n",
        "\n",
        "# Output directory where the model predictions and checkpoints will be stored\n",
        "output_dir = \"./results\"\n",
        "\n",
        "# Number of training epochs\n",
        "num_train_epochs = 2\n",
        "\n",
        "# Enable fp16/bf16 training (set bf16 to True with an A100)\n",
        "fp16 = True\n",
        "bf16 = False\n",
        "\n",
        "# Batch size per GPU for training\n",
        "per_device_train_batch_size = 8\n",
        "\n",
        "# Batch size per GPU for evaluation\n",
        "per_device_eval_batch_size = 8\n",
        "\n",
        "# Number of update steps to accumulate the gradients for\n",
        "gradient_accumulation_steps = 8\n",
        "\n",
        "# Enable gradient checkpointing\n",
        "gradient_checkpointing = True\n",
        "\n",
        "# Maximum gradient normal (gradient clipping)\n",
        "max_grad_norm = 1.0\n",
        "\n",
        "# Initial learning rate (AdamW optimizer)\n",
        "learning_rate = 2e-4\n",
        "\n",
        "# Weight decay to apply to all layers except bias/LayerNorm weights\n",
        "weight_decay = 0.001\n",
        "\n",
        "# Optimizer to use\n",
        "optim = \"paged_adamw_32bit\"\n",
        "\n",
        "# Learning rate schedule\n",
        "lr_scheduler_type = \"cosine\"\n",
        "\n",
        "# Number of training steps (overrides num_train_epochs)\n",
        "max_steps = -1\n",
        "\n",
        "# Ratio of steps for a linear warmup (from 0 to learning rate)\n",
        "warmup_ratio = 0.03\n",
        "\n",
        "# Group sequences into batches with same length\n",
        "# Saves memory and speeds up training considerably\n",
        "group_by_length = True\n",
        "\n",
        "# Save checkpoint every X updates steps\n",
        "save_steps = 0\n",
        "\n",
        "# Log every X updates steps\n",
        "logging_steps = 100\n",
        "\n",
        "################################################################################\n",
        "# SFT parameters\n",
        "################################################################################\n",
        "\n",
        "# Maximum sequence length to use\n",
        "max_seq_length = 512\n",
        "\n",
        "# Pack multiple short examples in the same input sequence to increase efficiency\n",
        "packing = False\n",
        "\n",
        "# Load the entire model on the GPU 0\n",
        "device_map = {\"\": 0}"
      ],
      "metadata": {
        "id": "lMwMkBqEV1pl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name = \"abhinand/tamil-alpaca-orca\""
      ],
      "metadata": {
        "id": "JE7rcDpCy-uD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset (you can process it here)\n",
        "print(f\"Loading Dataset...\")\n",
        "dataset = load_dataset(dataset_name, split=\"train\")\n",
        "# download_mode='force_redownload', ignore_verifications=True)\n",
        "\n",
        "print(f\"Sample Instruction: \\n{dataset[150][instruction_column]}\\n\")"
      ],
      "metadata": {
        "id": "DU51h_d2YG_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "SXRb5IYMzlur",
        "outputId": "26d30aca-0233-4f5d-ba1a-11d16d78bdd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'brishtiteveja/bangla-llama-7b-base-v0.1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load tokenizer and model with QLoRA configuration\n",
        "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=use_4bit,\n",
        "    # load_in_8bit=use_8_bit,\n",
        "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
        "    bnb_4bit_compute_dtype=compute_dtype,\n",
        "    bnb_4bit_use_double_quant=use_nested_quant,\n",
        ")\n",
        "\n",
        "# Check GPU compatibility with bfloat16\n",
        "if compute_dtype == torch.float16 and use_4bit:\n",
        "    major, _ = torch.cuda.get_device_capability()\n",
        "    if major >= 8:\n",
        "        print(\"=\" * 80)\n",
        "        print(\"Your GPU supports bfloat16: accelerate training with bf16=True\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "print(f\"Loading model...\")\n",
        "# Load base model\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    # quantization_config=bnb_config,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=device_map,\n",
        "    #use_flash_attention=use_flash_attention_2,\n",
        ")"
      ],
      "metadata": {
        "id": "_1Tf2ZKhGw41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/Projects/bangla-llama/data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LdhW8zfZoQK",
        "outputId": "c3b100c1-6886-4fe8-cb00-7d1872028db9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "config.json\t\tpytorch_model-00001-of-00002.bin  pytorch_model.bin.index.json\n",
            "generation_config.json\tpytorch_model-00002-of-00002.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_name = \"brishtiteveja/bangla-llama-7b-base-v0.1\""
      ],
      "metadata": {
        "id": "hi7VMw28zpz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = LlamaTokenizer.from_pretrained(\n",
        "            tokenizer_name\n",
        "        )"
      ],
      "metadata": {
        "id": "oQBLZKEhajqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTrX9LYk0Jw6",
        "outputId": "6dcdbfa0-6b93-4835-e0fc-b9e01cfff4e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LlamaTokenizer(name_or_path='brishtiteveja/bangla-llama-7b-base-v0.1', vocab_size=50437, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'eos_token': AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True)}, clean_up_tokenization_spaces=False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.config.use_cache = False\n",
        "model.config.pretraining_tp = 1\n",
        "\n",
        "# Load LLaMA tokenizer\n",
        "# === NORMAL SETTINGS ===\n",
        "# tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "# tokenizer.pad_token = tokenizer.eos_token\n",
        "# === EOS fixes ===\n",
        "\n",
        "#Need to fix\n",
        "\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\n",
        "#     model_name, trust_remote_code=True, add_eos_token=True\n",
        "# )\n",
        "\n",
        "\n",
        "tokenizer.pad_token_id = 18610\n",
        "# === END ===\n",
        "\n",
        "tokenizer.padding_side = \"right\"  # Fix weird overflow issue with fp16 training"
      ],
      "metadata": {
        "id": "jndZ_LcyY6xe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load LoRA configuration\n",
        "peft_config = LoraConfig(\n",
        "    lora_alpha=lora_alpha,\n",
        "    lora_dropout=lora_dropout,\n",
        "    target_modules=lora_target_modules,\n",
        "    r=lora_r,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "\n",
        "# Set training parameters\n",
        "training_arguments = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    num_train_epochs=num_train_epochs,\n",
        "    per_device_train_batch_size=per_device_train_batch_size,\n",
        "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
        "    optim=optim,\n",
        "    save_steps=save_steps,\n",
        "    logging_steps=logging_steps,\n",
        "    learning_rate=learning_rate,\n",
        "    weight_decay=weight_decay,\n",
        "    fp16=fp16,\n",
        "    bf16=bf16,\n",
        "    max_grad_norm=max_grad_norm,\n",
        "    max_steps=max_steps,\n",
        "    warmup_ratio=warmup_ratio,\n",
        "    group_by_length=group_by_length,\n",
        "    lr_scheduler_type=lr_scheduler_type,\n",
        "    report_to=\"tensorboard\",\n",
        ")"
      ],
      "metadata": {
        "id": "R7dFZ8KdGxIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set supervised fine-tuning parameters\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=dataset,\n",
        "    peft_config=peft_config,\n",
        "    dataset_text_field=instruction_column,\n",
        "    max_seq_length=max_seq_length,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_arguments,\n",
        "    packing=packing,\n",
        ")"
      ],
      "metadata": {
        "id": "PhaHpQj8ZB4z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "79c59451dfdf40558b6f3d7274fe8eab",
            "f5eac612fc644b859169edde0db5de3e",
            "3b3d23cc077d4505b0b5f1e6b4e80803",
            "b153b3275d4f4a938175737697db6c23",
            "9ee17fca02764309a767e4134008ae30",
            "82fe34b77c3f414dbe1f85fd7e933717",
            "a106a1193c524a119abb1e9a9b943cde",
            "a5ceba952f3147328597d1c253b8b8cb",
            "7da9e45c4d314dc1b7effb31f7d72e87",
            "bd34becdd6ec49dba9666431b95825e6",
            "218a31d35e4e45d489d6c26ad9131470"
          ]
        },
        "outputId": "6b2cdb1f-d0a7-4ee4-9abf-19a1a5c257ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/145181 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "79c59451dfdf40558b6f3d7274fe8eab"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Starting Training...\")\n",
        "\n",
        "# Train model\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "zM8ROfTBZJWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save trained model\n",
        "trainer.model.save_pretrained(new_model)"
      ],
      "metadata": {
        "id": "fu7quBY7ZL67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del model\n",
        "# del pipe\n",
        "del trainer\n",
        "import gc\n",
        "\n",
        "gc.collect()\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "W025oSX2ZP76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    low_cpu_mem_usage=True,\n",
        "    return_dict=True,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=device_map,\n",
        ")\n",
        "model = PeftModel.from_pretrained(base_model, new_model)\n",
        "model = model.merge_and_unload()\n",
        "\n",
        "# Reload tokenizer to save it\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\"\n",
        "\n",
        "model.push_to_hub(new_model, use_temp_dir=False, private=True)\n",
        "tokenizer.push_to_hub(new_model, use_temp_dir=False, private=True)"
      ],
      "metadata": {
        "id": "eCguq6ZvZHdc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "toc_visible": true,
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPPRUBhHFn1X0zMesPO1BAQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "04d0f620e7d54a76b88998dd1fff5bdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0779842cd9b64198ae1517da1ff8f405": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f880e16905a4be1b718273daceac680",
            "max": 18,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6a0cab4a12aa4387856747ba1b5a9c3c",
            "value": 18
          }
        },
        "0ed211bdefd748dfa14535ed99891238": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f880e16905a4be1b718273daceac680": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f192500bcd34ffd851504aa7f5ebafc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33ea235f0a85492d8f723a7dcb532b66": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36c4a3510d204df0bcf8fd8e489335b8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36c9d990123147eaa12bae188abb1fde": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fbd883cd0344882a02f5dc78041e0d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a46818fb4fc4587aca1b11e1d71eace",
            "placeholder": "​",
            "style": "IPY_MODEL_7811b700c799497486ae056ffc362fde",
            "value": "Generating train split: "
          }
        },
        "42d4a74ea6aa430bb0207309448c984f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36c4a3510d204df0bcf8fd8e489335b8",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eb8014a53cb84abcb0ace6864bd2ef96",
            "value": 1
          }
        },
        "49359dbf5f544bb3a5ba8d0d4088e2a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5c728be6054b4137a0dfdb2142c67cd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "68736d7bef8f464a9ac99bf3a37c0a61": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a0cab4a12aa4387856747ba1b5a9c3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "720e021855e143a2a27ce91adf234209": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_82b5c59d829b4b3483531678173c4ae4",
              "IPY_MODEL_0779842cd9b64198ae1517da1ff8f405",
              "IPY_MODEL_a6e9621d424340e693a301d1de7e1435"
            ],
            "layout": "IPY_MODEL_e997a293549f41be8ff8bdfa511cad54"
          }
        },
        "7811b700c799497486ae056ffc362fde": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f9b10f32ac04c909e9218a146cb0ee6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36c9d990123147eaa12bae188abb1fde",
            "placeholder": "​",
            "style": "IPY_MODEL_96cebf3d2dec4d178d4ad7030cbc91a6",
            "value": "Extracting data files: 100%"
          }
        },
        "82b5c59d829b4b3483531678173c4ae4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ed211bdefd748dfa14535ed99891238",
            "placeholder": "​",
            "style": "IPY_MODEL_f44b6f3251784c148a27042f5c982950",
            "value": "Resolving data files: 100%"
          }
        },
        "8a46818fb4fc4587aca1b11e1d71eace": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a66255895fe4a84abea2bd29b980bef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7f9b10f32ac04c909e9218a146cb0ee6",
              "IPY_MODEL_f8e736390872479dac25f52404947bda",
              "IPY_MODEL_d1da4e3908bf468c96a692edd69c06d3"
            ],
            "layout": "IPY_MODEL_fcfed57b5f2148f0b56d5857dd6056f1"
          }
        },
        "8c128584f6d94fa5826f9e51ab4dd769": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33ea235f0a85492d8f723a7dcb532b66",
            "placeholder": "​",
            "style": "IPY_MODEL_04d0f620e7d54a76b88998dd1fff5bdb",
            "value": " 1/1 [00:00&lt;00:00, 45.76it/s]"
          }
        },
        "92346b3e0d964e349a990b28b913b764": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95d0e0b8ef04423fb50cf257b5f002fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aecbf1f7d27f48da88d60589547820d1",
            "placeholder": "​",
            "style": "IPY_MODEL_5c728be6054b4137a0dfdb2142c67cd4",
            "value": " 12436596/0 [08:13&lt;00:00, 31440.88 examples/s]"
          }
        },
        "95e483355a7c41adbc8e98fa860f4c2a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96cebf3d2dec4d178d4ad7030cbc91a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "991c844cbeba4bc5a9c0c628fb9d750c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f571015852eb4df0a356f98edff00646",
              "IPY_MODEL_42d4a74ea6aa430bb0207309448c984f",
              "IPY_MODEL_8c128584f6d94fa5826f9e51ab4dd769"
            ],
            "layout": "IPY_MODEL_68736d7bef8f464a9ac99bf3a37c0a61"
          }
        },
        "a30f800461174e0993a2a60a48b2ac98": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6e9621d424340e693a301d1de7e1435": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d77d5b8bb4b04b0b9a8c1d7b7bff4082",
            "placeholder": "​",
            "style": "IPY_MODEL_a8456d230c704ab9b7264e5b815c4c12",
            "value": " 18/18 [00:00&lt;00:00, 1567.48it/s]"
          }
        },
        "a8456d230c704ab9b7264e5b815c4c12": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac4b4b923a3e45dd9e31c065aa4df0ea": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aecbf1f7d27f48da88d60589547820d1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3e390c62c2c4652ae245cd946d4dfe8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c8388c595da1420ba7fbfedb5196b09f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1da4e3908bf468c96a692edd69c06d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac4b4b923a3e45dd9e31c065aa4df0ea",
            "placeholder": "​",
            "style": "IPY_MODEL_a30f800461174e0993a2a60a48b2ac98",
            "value": " 1/1 [00:50&lt;00:00, 50.56s/it]"
          }
        },
        "d4286a71fc8544bbaad3f2a9b779e888": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "d77d5b8bb4b04b0b9a8c1d7b7bff4082": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6e9c03e9e5c45ea8ffcf43cb34b85d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3fbd883cd0344882a02f5dc78041e0d2",
              "IPY_MODEL_fb94cdd865b94ae2bde1189333412698",
              "IPY_MODEL_95d0e0b8ef04423fb50cf257b5f002fd"
            ],
            "layout": "IPY_MODEL_95e483355a7c41adbc8e98fa860f4c2a"
          }
        },
        "e997a293549f41be8ff8bdfa511cad54": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb8014a53cb84abcb0ace6864bd2ef96": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f44b6f3251784c148a27042f5c982950": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f571015852eb4df0a356f98edff00646": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f192500bcd34ffd851504aa7f5ebafc",
            "placeholder": "​",
            "style": "IPY_MODEL_92346b3e0d964e349a990b28b913b764",
            "value": "Downloading data files: 100%"
          }
        },
        "f8e736390872479dac25f52404947bda": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8388c595da1420ba7fbfedb5196b09f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_49359dbf5f544bb3a5ba8d0d4088e2a2",
            "value": 1
          }
        },
        "fb94cdd865b94ae2bde1189333412698": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4286a71fc8544bbaad3f2a9b779e888",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c3e390c62c2c4652ae245cd946d4dfe8",
            "value": 1
          }
        },
        "fcfed57b5f2148f0b56d5857dd6056f1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "182e5e30abec41609d3ec97ec728806e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d47070f2122d447c940f359d86c62ff0",
              "IPY_MODEL_b5b7914ab2314ab8ba4aef0526e9d175",
              "IPY_MODEL_f0f92ba414ab473694d03f502ccf14f6",
              "IPY_MODEL_9482e25a32774d86a999601a6aa24da7"
            ],
            "layout": "IPY_MODEL_ca28585c45f44c1ba90a935a9fd80a84"
          }
        },
        "3d5f7634c14b42a5a1f459714923e7b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4afb20af14c5486a965257f7ac37ab39",
            "placeholder": "​",
            "style": "IPY_MODEL_9c5a4f10a3b846f1a3300aa7573d6e90",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "68590b1519c343eb80cb41f6416b231d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_1f8254a537e747d59b72be8784126c91",
            "placeholder": "​",
            "style": "IPY_MODEL_19d5d64eb1434ed48c6185ac99e795c9",
            "value": ""
          }
        },
        "bbb3b0fbba5249ee8ebd02e9dcc943df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_0f544d143b17457b817e9be313bec6e5",
            "style": "IPY_MODEL_aa5f687cfe1b40088e48f9a190a6031b",
            "value": true
          }
        },
        "25b1afa3f2a04cebb3638cf5c1a0ace7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_445b7b613b134c16bb03733d11fb2fd6",
            "style": "IPY_MODEL_41b9a11e3a154c648dc974a296b3f005",
            "tooltip": ""
          }
        },
        "ba0b649dffe241839ef8c490d953b8da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0922856da2504447a45a10c62fc415b1",
            "placeholder": "​",
            "style": "IPY_MODEL_eeb506fbaa604bb28a50222ad893c0b2",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "ca28585c45f44c1ba90a935a9fd80a84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "4afb20af14c5486a965257f7ac37ab39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c5a4f10a3b846f1a3300aa7573d6e90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f8254a537e747d59b72be8784126c91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19d5d64eb1434ed48c6185ac99e795c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f544d143b17457b817e9be313bec6e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa5f687cfe1b40088e48f9a190a6031b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "445b7b613b134c16bb03733d11fb2fd6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41b9a11e3a154c648dc974a296b3f005": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "0922856da2504447a45a10c62fc415b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eeb506fbaa604bb28a50222ad893c0b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "91fc5ca585664eff9d34a1fe2f25132d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96645d05af0747df8bb0571cf5f2a847",
            "placeholder": "​",
            "style": "IPY_MODEL_21eebf3818f940f9a606ba3a3e0da5b4",
            "value": "Connecting..."
          }
        },
        "96645d05af0747df8bb0571cf5f2a847": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21eebf3818f940f9a606ba3a3e0da5b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d47070f2122d447c940f359d86c62ff0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e55980b7bd4d4137afaaf9c13a10c8a4",
            "placeholder": "​",
            "style": "IPY_MODEL_29f28473e3524f59a2b09f49501804bb",
            "value": "Token is valid (permission: write)."
          }
        },
        "b5b7914ab2314ab8ba4aef0526e9d175": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afa656cedd804bbab891cb3a3b3ccd72",
            "placeholder": "​",
            "style": "IPY_MODEL_be9b0158a2b8486584812b378f64b110",
            "value": "Your token has been saved in your configured git credential helpers (store)."
          }
        },
        "f0f92ba414ab473694d03f502ccf14f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25bada1822b949f794f0b1d6e49bf6c7",
            "placeholder": "​",
            "style": "IPY_MODEL_bcef0d60dd1e47ebb6fdaadc4955f004",
            "value": "Your token has been saved to /root/.cache/huggingface/token"
          }
        },
        "9482e25a32774d86a999601a6aa24da7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fff25c9116fb4dde827f1bba65e3910b",
            "placeholder": "​",
            "style": "IPY_MODEL_100e09c176414b8cb17b7349309ebcdf",
            "value": "Login successful"
          }
        },
        "e55980b7bd4d4137afaaf9c13a10c8a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29f28473e3524f59a2b09f49501804bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "afa656cedd804bbab891cb3a3b3ccd72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be9b0158a2b8486584812b378f64b110": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25bada1822b949f794f0b1d6e49bf6c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcef0d60dd1e47ebb6fdaadc4955f004": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fff25c9116fb4dde827f1bba65e3910b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "100e09c176414b8cb17b7349309ebcdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c52cf5c719745b8890b83315a50b949": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8cc7fbd222ed4581ab7b22b578c46bb2",
              "IPY_MODEL_2db38b2d20ea4f67883a97c6d729ae4d",
              "IPY_MODEL_fe4460a7e35942fa8ea2c72ad3da8fb2"
            ],
            "layout": "IPY_MODEL_d4f674ac94c04516b6359066ccb009b0"
          }
        },
        "8cc7fbd222ed4581ab7b22b578c46bb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7eedb206eed4c76836cd5057d81cc0c",
            "placeholder": "​",
            "style": "IPY_MODEL_f2afec77840b4958bdb17651190c5aac",
            "value": "config.json: 100%"
          }
        },
        "2db38b2d20ea4f67883a97c6d729ae4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e10d7e62f820455198f1c5ec0cf155b9",
            "max": 673,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_46bfdb92bd9b42c79316f476d0876c31",
            "value": 673
          }
        },
        "fe4460a7e35942fa8ea2c72ad3da8fb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1cf4c6587d4c421dacb75fdf5ab0a8ee",
            "placeholder": "​",
            "style": "IPY_MODEL_eef594bc4e684e86911664bcbde0d81f",
            "value": " 673/673 [00:00&lt;00:00, 56.3kB/s]"
          }
        },
        "d4f674ac94c04516b6359066ccb009b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7eedb206eed4c76836cd5057d81cc0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2afec77840b4958bdb17651190c5aac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e10d7e62f820455198f1c5ec0cf155b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46bfdb92bd9b42c79316f476d0876c31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1cf4c6587d4c421dacb75fdf5ab0a8ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eef594bc4e684e86911664bcbde0d81f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d9acf29aa654fb7ab5e6629989df8ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_37cfb693d6614a6991c975067530fa7a",
              "IPY_MODEL_5b28fa0c7335401ab698da88bac33384",
              "IPY_MODEL_a8a2f69d60624e00a6dd1567a5c4b128"
            ],
            "layout": "IPY_MODEL_c7e6ed40002c45c7bc0c26fa52ce198c"
          }
        },
        "37cfb693d6614a6991c975067530fa7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9df4a0ca72046758171363ffa439043",
            "placeholder": "​",
            "style": "IPY_MODEL_ccd33b9a0b604cb997f5057cb51d597a",
            "value": "pytorch_model.bin.index.json: 100%"
          }
        },
        "5b28fa0c7335401ab698da88bac33384": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9310aa54335e423fb423ad9444ad3c39",
            "max": 26788,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_11b8540ca5914676ac8ac29bd80a71d3",
            "value": 26788
          }
        },
        "a8a2f69d60624e00a6dd1567a5c4b128": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e949e0192cf24a9e9a3bb5e7e58103b6",
            "placeholder": "​",
            "style": "IPY_MODEL_45615d39596e42ecb1a18746c34445d9",
            "value": " 26.8k/26.8k [00:00&lt;00:00, 1.73MB/s]"
          }
        },
        "c7e6ed40002c45c7bc0c26fa52ce198c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9df4a0ca72046758171363ffa439043": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccd33b9a0b604cb997f5057cb51d597a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9310aa54335e423fb423ad9444ad3c39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11b8540ca5914676ac8ac29bd80a71d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e949e0192cf24a9e9a3bb5e7e58103b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45615d39596e42ecb1a18746c34445d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7dda6cb20c9045e2b147501dcccd0690": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_da6dc7ab0dcb4e87837e64bad527335b",
              "IPY_MODEL_bdfcb6eee4aa482393f4815967825447",
              "IPY_MODEL_3c9ffaa8ed0947a8af122e2cfe19a32a"
            ],
            "layout": "IPY_MODEL_f3c6e755540c40b7972d14c29b2fd148"
          }
        },
        "da6dc7ab0dcb4e87837e64bad527335b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a6f079800b94656a1e3dece7d927e37",
            "placeholder": "​",
            "style": "IPY_MODEL_5723692e81af446badee7b0a03a2041d",
            "value": "Downloading shards: 100%"
          }
        },
        "bdfcb6eee4aa482393f4815967825447": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89d2e6627194448c8c07967c7ab387d1",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_db9bfd6b9e3b4f7980ceedf2452a0fe3",
            "value": 2
          }
        },
        "3c9ffaa8ed0947a8af122e2cfe19a32a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b0c91387b7b430793ed128f95b3265f",
            "placeholder": "​",
            "style": "IPY_MODEL_1ad8b349b0274c7cb29529b9cea987bd",
            "value": " 2/2 [12:39&lt;00:00, 354.43s/it]"
          }
        },
        "f3c6e755540c40b7972d14c29b2fd148": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a6f079800b94656a1e3dece7d927e37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5723692e81af446badee7b0a03a2041d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "89d2e6627194448c8c07967c7ab387d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db9bfd6b9e3b4f7980ceedf2452a0fe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b0c91387b7b430793ed128f95b3265f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ad8b349b0274c7cb29529b9cea987bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "94d1ce65f6704c369d1dc11c71b88164": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_80df440de92249f39d3346226ec5059d",
              "IPY_MODEL_0bd672660bfd4006bd0386305750b5fb",
              "IPY_MODEL_b53981ec8cd64cab813cf77fb1a6100c"
            ],
            "layout": "IPY_MODEL_3b3ad2b6d0ff4568969c662dd5318076"
          }
        },
        "80df440de92249f39d3346226ec5059d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5554603698a4d21909dc659c2f1bd50",
            "placeholder": "​",
            "style": "IPY_MODEL_e125147a22f145c79f5b88bb3f4fbfb2",
            "value": "pytorch_model-00001-of-00002.bin: 100%"
          }
        },
        "0bd672660bfd4006bd0386305750b5fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6d9e01d3f814d57b4aa64c402a1b798",
            "max": 9947301441,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_97faafca9f064f5697b946f535a35b5d",
            "value": 9947301441
          }
        },
        "b53981ec8cd64cab813cf77fb1a6100c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6a29dacf3954006a468498b489aeabe",
            "placeholder": "​",
            "style": "IPY_MODEL_a05fd883e5704c31a388fdc3776a183d",
            "value": " 9.95G/9.95G [08:40&lt;00:00, 23.4MB/s]"
          }
        },
        "3b3ad2b6d0ff4568969c662dd5318076": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5554603698a4d21909dc659c2f1bd50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e125147a22f145c79f5b88bb3f4fbfb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6d9e01d3f814d57b4aa64c402a1b798": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97faafca9f064f5697b946f535a35b5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f6a29dacf3954006a468498b489aeabe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a05fd883e5704c31a388fdc3776a183d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2020bd34ef3b4266889bcc11e409b1bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_31770e24def0423c9dc96a3a53c3081f",
              "IPY_MODEL_ae813d2c157c4b8b9cf2917257f1b49b",
              "IPY_MODEL_8afc4a6853384d859d942469bc42e141"
            ],
            "layout": "IPY_MODEL_c0d8a2c26dcc431d8e2d34ee7034e567"
          }
        },
        "31770e24def0423c9dc96a3a53c3081f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92e22d07e5a44a748d340636014de987",
            "placeholder": "​",
            "style": "IPY_MODEL_6c8697d7b14745d38d014f655d7742ec",
            "value": "pytorch_model-00002-of-00002.bin: 100%"
          }
        },
        "ae813d2c157c4b8b9cf2917257f1b49b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82d75bb0a3ef4a1eb4491b98e12684b6",
            "max": 3831725942,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6ded82b0f72d482487a3d65691135edb",
            "value": 3831725942
          }
        },
        "8afc4a6853384d859d942469bc42e141": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01d6c083e9194db98835827ec1d4a149",
            "placeholder": "​",
            "style": "IPY_MODEL_2007d1627f2847ffb874a22c41c5d6d3",
            "value": " 3.83G/3.83G [03:56&lt;00:00, 21.3MB/s]"
          }
        },
        "c0d8a2c26dcc431d8e2d34ee7034e567": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92e22d07e5a44a748d340636014de987": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c8697d7b14745d38d014f655d7742ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82d75bb0a3ef4a1eb4491b98e12684b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ded82b0f72d482487a3d65691135edb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "01d6c083e9194db98835827ec1d4a149": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2007d1627f2847ffb874a22c41c5d6d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df156146aabb426db74ac08333a043b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4b31182c62354aceb6169e123c7fffa7",
              "IPY_MODEL_88400b9b59ac4585bc7feb773fe68b6b",
              "IPY_MODEL_b0337017293c42aaa4067dfb8c40e07b"
            ],
            "layout": "IPY_MODEL_304c50e7e4a04832b9dd1d4095bab4c9"
          }
        },
        "4b31182c62354aceb6169e123c7fffa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01c8d11fe9de4fae95fc1f956284026a",
            "placeholder": "​",
            "style": "IPY_MODEL_d8223b185fd748f39ffae376f607ab51",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "88400b9b59ac4585bc7feb773fe68b6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a278c7d9e2d47ee93a077e315b8cf99",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_293efab632914fd0b0800c50358a40f9",
            "value": 2
          }
        },
        "b0337017293c42aaa4067dfb8c40e07b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_019cd599f7f642049a91f483d654c6fa",
            "placeholder": "​",
            "style": "IPY_MODEL_97d056deb6b443c884e1c8ee137e76e3",
            "value": " 2/2 [00:21&lt;00:00,  9.69s/it]"
          }
        },
        "304c50e7e4a04832b9dd1d4095bab4c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01c8d11fe9de4fae95fc1f956284026a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8223b185fd748f39ffae376f607ab51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a278c7d9e2d47ee93a077e315b8cf99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "293efab632914fd0b0800c50358a40f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "019cd599f7f642049a91f483d654c6fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97d056deb6b443c884e1c8ee137e76e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "944e385d07d9433d9e7b879b28c7c908": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_47121d95aa7647648a7770f18a2b4ac6",
              "IPY_MODEL_7c7e6a3be61e4d6ab03da85849779aba",
              "IPY_MODEL_5971c9668a3e4a13a245ef0a021219ce"
            ],
            "layout": "IPY_MODEL_555b16943fe849b0b2e1511047c49818"
          }
        },
        "47121d95aa7647648a7770f18a2b4ac6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_463cba8f3443452bbf51e6b9fa7e45ec",
            "placeholder": "​",
            "style": "IPY_MODEL_9af91a104636450eb6a7fb4f924c0467",
            "value": "generation_config.json: 100%"
          }
        },
        "7c7e6a3be61e4d6ab03da85849779aba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82943db8ccda47af820a081983731815",
            "max": 183,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9228e86096eb4459bffaa75fefd07e46",
            "value": 183
          }
        },
        "5971c9668a3e4a13a245ef0a021219ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef149666ae774e4aa5bd3cef01dad8bc",
            "placeholder": "​",
            "style": "IPY_MODEL_89d85c8b0a634e45a6ba3f5b8b651fcd",
            "value": " 183/183 [00:00&lt;00:00, 16.9kB/s]"
          }
        },
        "555b16943fe849b0b2e1511047c49818": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "463cba8f3443452bbf51e6b9fa7e45ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9af91a104636450eb6a7fb4f924c0467": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82943db8ccda47af820a081983731815": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9228e86096eb4459bffaa75fefd07e46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ef149666ae774e4aa5bd3cef01dad8bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89d85c8b0a634e45a6ba3f5b8b651fcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79c59451dfdf40558b6f3d7274fe8eab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f5eac612fc644b859169edde0db5de3e",
              "IPY_MODEL_3b3d23cc077d4505b0b5f1e6b4e80803",
              "IPY_MODEL_b153b3275d4f4a938175737697db6c23"
            ],
            "layout": "IPY_MODEL_9ee17fca02764309a767e4134008ae30"
          }
        },
        "f5eac612fc644b859169edde0db5de3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82fe34b77c3f414dbe1f85fd7e933717",
            "placeholder": "​",
            "style": "IPY_MODEL_a106a1193c524a119abb1e9a9b943cde",
            "value": "Map: 100%"
          }
        },
        "3b3d23cc077d4505b0b5f1e6b4e80803": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5ceba952f3147328597d1c253b8b8cb",
            "max": 145181,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7da9e45c4d314dc1b7effb31f7d72e87",
            "value": 145181
          }
        },
        "b153b3275d4f4a938175737697db6c23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd34becdd6ec49dba9666431b95825e6",
            "placeholder": "​",
            "style": "IPY_MODEL_218a31d35e4e45d489d6c26ad9131470",
            "value": " 145181/145181 [08:36&lt;00:00, 246.93 examples/s]"
          }
        },
        "9ee17fca02764309a767e4134008ae30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82fe34b77c3f414dbe1f85fd7e933717": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a106a1193c524a119abb1e9a9b943cde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5ceba952f3147328597d1c253b8b8cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7da9e45c4d314dc1b7effb31f7d72e87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bd34becdd6ec49dba9666431b95825e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "218a31d35e4e45d489d6c26ad9131470": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}